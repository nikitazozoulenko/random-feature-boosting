{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, tensor\n",
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "from optuna_kfoldCV import evaluate_dataset_with_model, run_all_openML_with_model\n",
    "from regression_param_specs import evaluate_Ridge, evaluate_XGBoostRegressor\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the collection with ID 353\n",
    "collection = openml.study.get_suite(353)\n",
    "dataset_ids = collection.data\n",
    "metadata_list = []\n",
    "\n",
    "# Fetch and process each dataset\n",
    "for i, dataset_id in enumerate(dataset_ids):\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        target=dataset.default_target_attribute\n",
    "    )\n",
    "\n",
    "    #count missing values in X\n",
    "    missing_values_count = X.isnull().sum().sum()\n",
    "    print(f\"Missing values in X: {missing_values_count}\")\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)[..., None]\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    # Determine if the dataset has categorical features\n",
    "    has_categorical = any(categorical_indicator)\n",
    "    \n",
    "    # Extract the required metadata\n",
    "    metadata = {\n",
    "        'dataset_id': dataset.id,\n",
    "        'name': dataset.name,\n",
    "        'n_obs': int(dataset.qualities['NumberOfInstances']),\n",
    "        'n_features': int(dataset.qualities['NumberOfFeatures']),\n",
    "        '%_unique_y': len(np.unique(y))/len(y),\n",
    "        'n_unique_y': len(np.unique(y)),\n",
    "        'has_categorical': has_categorical,\n",
    "        'n_missing_values': missing_values_count,\n",
    "    }\n",
    "    \n",
    "    metadata_list.append(metadata)\n",
    "    print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset.id}: {dataset.name}\")\n",
    "\n",
    "# Create a DataFrame from the metadata list\n",
    "df_metadata = pd.DataFrame(metadata_list).sort_values('%_unique_y', ascending=False).set_index(\"dataset_id\").sort_index()\n",
    "df_metadata.sort_values('%_unique_y', ascending=True)\n",
    "\n",
    "# Display the metadata DataFrame\n",
    "df_metadata.loc[44962, \"has_categorical\"] = True\n",
    "df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids_no_categorical = list(df_metadata.query(\"has_categorical == False\").index.values)\n",
    "dataset_ids_no_categorical = sorted([int(x) for x in dataset_ids_no_categorical])\n",
    "len(dataset_ids_no_categorical)\n",
    "dataset_ids_no_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments (just for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_all_openML_with_model(\n",
    "#     dataset_ids_no_categorical[0:2], \n",
    "#     evaluate_Ridge,\n",
    "#     name_model=\"Ridge\",\n",
    "#     k_folds=5,\n",
    "#     cv_seed=42,\n",
    "#     regression_or_classification=\"regression\",\n",
    "#     n_optuna_trials=2,\n",
    "#     device=\"cuda\",\n",
    "#     save_dir = \"/home/nikita/Code/zephyrox/pytorch_based/SWIM/save/\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- models:::: End2End Ridge RidgeCV XGBoostRegressor GradientRFBoost GradientRFBoostID GreedyRFBoostDense GreedyRFBoostDiag GreedyRFBoostScalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models End2End --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 50 --device cuda --k_folds 5 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models Ridge --dataset_indices 0  --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 100 --device cuda --k_folds 5 --cv_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models RidgeCV --dataset_indices 17 18 19  --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 100 --device cuda --k_folds 5 --cv_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py \\\n",
    "    --models XGBoostRegressor \\\n",
    "    --dataset_indices 0 \\\n",
    "    --save_dir /rds/general/user/nz423/home/random-feature-boosting/save/OpenMLRegression/ \\\n",
    "    --n_optuna_trials 100 \\\n",
    "    --device cpu \\\n",
    "    --k_folds 5 \\\n",
    "    --cv_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models GradientRFBoost --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 100 --device cuda --k_folds 5 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models GradientRFBoostID --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cuda --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models GreedyRFBoostDense --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 100 --device gpu --k_folds 5 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models GreedyRFBoostDiag --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cuda --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models GreedyRFBoostScalar --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cuda --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join json results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic.v1.utils import deep_update\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from optuna_kfoldCV import openML_reg_ids_noCat\n",
    "\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "def custom_deep_update(original, update):\n",
    "    for key, value in update.items():\n",
    "        if isinstance(value, dict) and key in original:\n",
    "            custom_deep_update(original[key], value)\n",
    "        else:\n",
    "            original[key] = value\n",
    "\n",
    "\n",
    "\n",
    "def get_joined_results_json(\n",
    "        models = [\"End2End\", \"Ridge\", \"RidgeCV\", \"XGBoostRegressor\", \n",
    "                  \"GradientRFBoost\", \"GradientRFBoostID\", \n",
    "                  \"GreedyRFBoostDense\", \"GreedyRFBoostDiag\", \"GreedyRFBoostScalar\"],\n",
    "        datasets = openML_reg_ids_noCat,\n",
    "        save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLRegression/\",\n",
    "        ):\n",
    "    results_json = {}\n",
    "    for model in models:\n",
    "        for dataset in datasets:\n",
    "            path = os.path.join(save_dir, f\"regression_{dataset}_{model}.json\")\n",
    "            res = read_json(path)\n",
    "            if results_json == {}:\n",
    "                results_json = res\n",
    "            else:\n",
    "                custom_deep_update(results_json, res)\n",
    "    return results_json\n",
    "\n",
    "\n",
    "\n",
    "def join_jsons_into_array(\n",
    "        results_json,\n",
    "        ):\n",
    "    results = []\n",
    "    for dataset, dataset_results in results_json.items():\n",
    "        res = []\n",
    "        for model_name, model_results in dataset_results.items():\n",
    "            model_res = np.stack([model_results[\"score_train\"], model_results[\"score_test\"], model_results[\"t_fit\"], model_results[\"t_inference\"]])\n",
    "            res.append(model_res)\n",
    "        results.append(res)\n",
    "    return np.stack(results) # (n_datasets, n_models, 4, n_folds)\n",
    "\n",
    "\n",
    "def results_to_df(\n",
    "        models = [\"End2End\", \"Ridge\", \"RidgeCV\", \"XGBoostRegressor\", \n",
    "                  \"GradientRFBoost\", \"GradientRFBoostID\", \n",
    "                  \"GreedyRFBoostDense\", \"GreedyRFBoostDiag\", \"GreedyRFBoostScalar\"],\n",
    "        datasets = openML_reg_ids_noCat[[0,1,2,3,4,5,6,7,8,9,10,      13,14,15,16,17,18,19]],\n",
    "        save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLRegression/\",\n",
    "        ):\n",
    "    # Load and join the JSON data\n",
    "    results_json = get_joined_results_json(models, datasets, save_dir)\n",
    "    results = join_jsons_into_array(results_json) # (n_datasets, n_models, 4, n_folds)\n",
    "    \n",
    "    # Calculate means and stds across folds\n",
    "    results_mean = np.mean(results, axis=-1)  # (n_datasets, n_models, 4)\n",
    "    results_std = np.std(results, axis=-1)    # (n_datasets, n_models, 4)\n",
    "    \n",
    "    # Create a dictionary to hold both mean and std DataFrames\n",
    "    metrics = [\"score_train\", \"score_test\", \"t_fit\", \"t_inference\"]\n",
    "    metric_dfs = {}\n",
    "    \n",
    "    # Initialize DataFrames for both mean and std metrics\n",
    "    for metric in metrics:\n",
    "        metric_dfs[metric] = pd.DataFrame(index=datasets, columns=models)\n",
    "        metric_dfs[f\"{metric}_std\"] = pd.DataFrame(index=datasets, columns=models)\n",
    "    \n",
    "    # Populate the DataFrames for each metric\n",
    "    for dataset_idx, dataset in enumerate(datasets):\n",
    "        for model_idx, model in enumerate(models):\n",
    "            for metric_idx, metric in enumerate(metrics):\n",
    "                # Set mean value\n",
    "                metric_dfs[metric].loc[dataset, model] = results_mean[dataset_idx, model_idx, metric_idx]\n",
    "                # Set std value\n",
    "                metric_dfs[f\"{metric}_std\"].loc[dataset, model] = results_std[dataset_idx, model_idx, metric_idx]\n",
    "    \n",
    "    return metric_dfs\n",
    "\n",
    "df = results_to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_train\"].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].rank(axis=1).mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at distribution of params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_param_distribution(\n",
    "        models = [\"End2End\", \"Ridge\", \"RidgeCV\", \"XGBoostRegressor\", \n",
    "                  \"GradientRFBoost\", \"GradientRFBoostID\", \n",
    "                  \"GreedyRFBoostDense\", \"GreedyRFBoostDiag\", \"GreedyRFBoostScalar\"],\n",
    "        datasets = openML_reg_ids_noCat[[0,1,2,3,4,5,6,7,8,9,10,      13,14,15,16,17,18,19]],\n",
    "        save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLRegression/\",\n",
    "        ):\n",
    "    # Load and join the JSON data\n",
    "    results_json = get_joined_results_json(models, datasets, save_dir)\n",
    "\n",
    "    # model: list_of_param_names\n",
    "    modelwise_param_names = {model: list(results_json[str(datasets[0])][model]['hyperparams'][0])\n",
    "                            for model in models} \n",
    "\n",
    "    # model: param_name: list_of_param_values\n",
    "    param_distribution = { model: {param: [] for param in param_names}\n",
    "                          for model, param_names in modelwise_param_names.items()}\n",
    "\n",
    "    #populate teh param_districution nested dict\n",
    "    for dataset, dataset_results in results_json.items():\n",
    "        for model_name, model_results in dataset_results.items():\n",
    "            for fold in model_results[\"hyperparams\"]:\n",
    "                for param_name, param_val in fold.items():\n",
    "                    param_distribution[model_name][param_name].append(param_val)\n",
    "\n",
    "    # For each model, plot the distribution of each parameter\n",
    "    for model, param_dict in param_distribution.items():\n",
    "        print(f\"Model: {model}\")\n",
    "        for param_name, param_values in param_dict.items():\n",
    "            if param_name not in [\n",
    "                \"out_dim\", \"loss\", \"objective\", \"feature_type\",\n",
    "                \"upscale\", \"sandwich_solver\"\n",
    "                ]:\n",
    "                # Create figure with two subplots side by side\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "                \n",
    "                # Linear scale plot\n",
    "                ax1.hist(param_values, bins=20)\n",
    "                ax1.set_title(f\"{model} {param_name}\\n(linear scale)\")\n",
    "                ax1.set_xlabel(param_name)\n",
    "                ax1.set_ylabel(\"Count\")\n",
    "                \n",
    "                # Log scale plot\n",
    "                min_val = np.min(param_values)  # Avoid log(0)\n",
    "                max_val = np.max(param_values)\n",
    "                bins = np.logspace(np.log10(min_val), np.log10(max_val), 20)\n",
    "                ax2.hist(param_values, bins=bins)\n",
    "                ax2.set_xscale('log')\n",
    "                ax2.set_title(f\"{model} {param_name}\\n(log scale)\")\n",
    "                ax2.set_xlabel(param_name)\n",
    "                ax2.set_ylabel(\"Count\")\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "plot_param_distribution()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
