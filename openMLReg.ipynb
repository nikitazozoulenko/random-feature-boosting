{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, tensor\n",
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "from optuna_kfoldCV import evaluate_dataset_with_model, run_all_openML_with_model\n",
    "from regression_param_specs import evaluate_Ridge, evaluate_XGBoostRegressor\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the collection with ID 353\n",
    "collection = openml.study.get_suite(353)\n",
    "dataset_ids = collection.data\n",
    "metadata_list = []\n",
    "\n",
    "# Fetch and process each dataset\n",
    "for i, dataset_id in enumerate(dataset_ids):\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        target=dataset.default_target_attribute\n",
    "    )\n",
    "\n",
    "    #count missing values in X\n",
    "    missing_values_count = X.isnull().sum().sum()\n",
    "    print(f\"Missing values in X: {missing_values_count}\")\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)[..., None]\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    # Determine if the dataset has categorical features\n",
    "    has_categorical = any(categorical_indicator)\n",
    "    \n",
    "    # Extract the required metadata\n",
    "    metadata = {\n",
    "        'dataset_id': dataset.id,\n",
    "        'name': dataset.name,\n",
    "        'n_obs': int(dataset.qualities['NumberOfInstances']),\n",
    "        'n_features': int(dataset.qualities['NumberOfFeatures']),\n",
    "        '%_unique_y': len(np.unique(y))/len(y),\n",
    "        'n_unique_y': len(np.unique(y)),\n",
    "        'has_categorical': has_categorical,\n",
    "        'n_missing_values': missing_values_count,\n",
    "    }\n",
    "    \n",
    "    metadata_list.append(metadata)\n",
    "    print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset.id}: {dataset.name}\")\n",
    "\n",
    "# Create a DataFrame from the metadata list\n",
    "df_metadata = pd.DataFrame(metadata_list).sort_values('%_unique_y', ascending=False).set_index(\"dataset_id\").sort_index()\n",
    "df_metadata.sort_values('%_unique_y', ascending=True)\n",
    "\n",
    "# Display the metadata DataFrame\n",
    "df_metadata.loc[44962, \"has_categorical\"] = True\n",
    "df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids_no_categorical = list(df_metadata.query(\"has_categorical == False\").index.values)\n",
    "dataset_ids_no_categorical = sorted([int(x) for x in dataset_ids_no_categorical])\n",
    "len(dataset_ids_no_categorical)\n",
    "dataset_ids_no_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments (just for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_all_openML_with_model(\n",
    "#     dataset_ids_no_categorical[0:2], \n",
    "#     evaluate_Ridge,\n",
    "#     name_model=\"Ridge\",\n",
    "#     k_folds=5,\n",
    "#     cv_seed=42,\n",
    "#     regression_or_classification=\"regression\",\n",
    "#     n_optuna_trials=2,\n",
    "#     device=\"cuda\",\n",
    "#     save_dir = \"/home/nikita/Code/zephyrox/pytorch_based/SWIM/save/\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- models:::: End2End Ridge RidgeCV XGBoostRegressor GradientRFBoost GradientRFBoostID GreedyRFBoostDense GreedyRFBoostDiag GreedyRFBoostScalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models End2End --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 50 --device cuda --k_folds 5 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models Ridge RidgeCV --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cuda --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models XGBoostRegressor --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cpu --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models GradientRFBoost --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 100 --device cuda --k_folds 5 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models GradientRFBoostID --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cuda --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "\u001b[32m[I 2024-12-02 13:27:44,867]\u001b[0m A new study created in memory with name: no-name-3f310f69-f6da-4c60-a047-be5492f13c59\u001b[0m\n",
      "/home/nikita/Code/zephyrox/.conda/lib/python3.10/site-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.3, 1.001] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.3, 1.0].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-12-02 13:27:50,063]\u001b[0m Trial 0 finished with value: 0.26844761967659 and parameters: {'feature_type': 'SWIM', 'upscale': 'dense', 'n_layers': 9, 'hidden_dim': 16, 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'boost_lr': 0.4, 'l2_reg_sandwich': 0.00091514319271452}. Best is trial 0 with value: 0.26844761967659.\u001b[0m\n",
      "\u001b[32m[I 2024-12-02 13:27:50,196]\u001b[0m Trial 1 finished with value: 0.6937397360801697 and parameters: {'feature_type': 'SWIM', 'upscale': 'dense', 'n_layers': 2, 'hidden_dim': 80, 'randfeat_xt_dim': 128, 'randfeat_x0_dim': 128, 'boost_lr': 0.4, 'l2_reg_sandwich': 0.6474505661697866}. Best is trial 0 with value: 0.26844761967659.\u001b[0m\n",
      "\u001b[32m[I 2024-12-02 13:27:50,735]\u001b[0m Trial 2 finished with value: 0.6949697852134704 and parameters: {'feature_type': 'SWIM', 'upscale': 'dense', 'n_layers': 4, 'hidden_dim': 80, 'randfeat_xt_dim': 256, 'randfeat_x0_dim': 256, 'boost_lr': 0.8, 'l2_reg_sandwich': 76.86164488129447}. Best is trial 0 with value: 0.26844761967659.\u001b[0m\n",
      "\u001b[32m[I 2024-12-02 13:27:50,915]\u001b[0m Trial 3 finished with value: 0.5915249943733215 and parameters: {'feature_type': 'SWIM', 'upscale': 'dense', 'n_layers': 1, 'hidden_dim': 48, 'randfeat_xt_dim': 256, 'randfeat_x0_dim': 384, 'boost_lr': 1.0, 'l2_reg_sandwich': 0.022632685570370507}. Best is trial 0 with value: 0.26844761967659.\u001b[0m\n",
      "\u001b[32m[I 2024-12-02 13:27:52,173]\u001b[0m Trial 4 finished with value: 0.3535104334354401 and parameters: {'feature_type': 'SWIM', 'upscale': 'dense', 'n_layers': 10, 'hidden_dim': 48, 'randfeat_xt_dim': 384, 'randfeat_x0_dim': 128, 'boost_lr': 0.6000000000000001, 'l2_reg_sandwich': 0.227833340594446}. Best is trial 0 with value: 0.26844761967659.\u001b[0m\n",
      "\u001b[32m[I 2024-12-02 13:27:52,308]\u001b[0m Trial 5 finished with value: 0.6935198187828064 and parameters: {'feature_type': 'SWIM', 'upscale': 'dense', 'n_layers': 2, 'hidden_dim': 80, 'randfeat_xt_dim': 128, 'randfeat_x0_dim': 128, 'boost_lr': 0.6000000000000001, 'l2_reg_sandwich': 0.8446019727349724}. Best is trial 0 with value: 0.26844761967659.\u001b[0m\n",
      "\u001b[32m[I 2024-12-02 13:27:56,110]\u001b[0m Trial 6 finished with value: 0.30362528562545776 and parameters: {'feature_type': 'SWIM', 'upscale': 'dense', 'n_layers': 10, 'hidden_dim': 112, 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 384, 'boost_lr': 0.4, 'l2_reg_sandwich': 0.02164038261476024}. Best is trial 0 with value: 0.26844761967659.\u001b[0m\n",
      "\u001b[32m[I 2024-12-02 13:27:57,810]\u001b[0m Trial 7 finished with value: 0.32416145205497743 and parameters: {'feature_type': 'SWIM', 'upscale': 'dense', 'n_layers': 5, 'hidden_dim': 16, 'randfeat_xt_dim': 384, 'randfeat_x0_dim': 512, 'boost_lr': 0.7, 'l2_reg_sandwich': 0.008535060158131227}. Best is trial 0 with value: 0.26844761967659.\u001b[0m\n",
      "\u001b[32m[I 2024-12-02 13:27:59,230]\u001b[0m Trial 8 finished with value: 0.34172284603118896 and parameters: {'feature_type': 'SWIM', 'upscale': 'dense', 'n_layers': 10, 'hidden_dim': 112, 'randfeat_xt_dim': 256, 'randfeat_x0_dim': 256, 'boost_lr': 0.3, 'l2_reg_sandwich': 0.026150331836973472}. Best is trial 0 with value: 0.26844761967659.\u001b[0m\n",
      "\u001b[32m[I 2024-12-02 13:28:00,947]\u001b[0m Trial 9 finished with value: 0.6941716313362122 and parameters: {'feature_type': 'SWIM', 'upscale': 'dense', 'n_layers': 9, 'hidden_dim': 80, 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 128, 'boost_lr': 0.8, 'l2_reg_sandwich': 22.391890165357385}. Best is trial 0 with value: 0.26844761967659.\u001b[0m\n",
      "\u001b[32m[I 2024-12-02 13:28:05,085]\u001b[0m Trial 10 finished with value: 0.2676708072423935 and parameters: {'feature_type': 'SWIM', 'upscale': 'dense', 'n_layers': 7, 'hidden_dim': 16, 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'boost_lr': 0.5, 'l2_reg_sandwich': 0.0003669773952268797}. Best is trial 10 with value: 0.2676708072423935.\u001b[0m\n",
      "^C\n",
      "\u001b[33m[W 2024-12-02 13:28:07,398]\u001b[0m Trial 11 failed with parameters: {'feature_type': 'SWIM', 'upscale': 'dense', 'n_layers': 7, 'hidden_dim': 16, 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'boost_lr': 0.5, 'l2_reg_sandwich': 0.00010625685478476958} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nikita/Code/zephyrox/.conda/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/nikita/Code/random-feature-boosting/optuna_kfoldCV.py\", line 161, in <lambda>\n",
      "    objective = lambda trial: get_pytorch_optuna_cv_objective(\n",
      "  File \"/home/nikita/Code/random-feature-boosting/optuna_kfoldCV.py\", line 124, in get_pytorch_optuna_cv_objective\n",
      "    model.fit(X_inner_train, y_inner_train)\n",
      "  File \"/home/nikita/Code/random-feature-boosting/models/models.py\", line 44, in fit\n",
      "    self.fit_transform(X, y)\n",
      "  File \"/home/nikita/Code/random-feature-boosting/models/models.py\", line 758, in fit_transform\n",
      "    Delta = sandwiched_LS_dense(R, W, F, self.l2_reg_sandwich)\n",
      "  File \"/home/nikita/Code/random-feature-boosting/models/sandwiched_least_squares.py\", line 83, in sandwiched_LS_dense\n",
      "    V, SX, _ = torch.linalg.svd(X.T @ X, full_matrices=False) # shape (p, p), (p,)\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2024-12-02 13:28:07,399]\u001b[0m Trial 11 failed with value None.\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nikita/Code/random-feature-boosting/regression_param_specs.py\", line 336, in <module>\n",
      "    run_all_openML_with_model(\n",
      "  File \"/home/nikita/Code/random-feature-boosting/optuna_kfoldCV.py\", line 362, in run_all_openML_with_model\n",
      "    json = evaluate_dataset_with_model(\n",
      "  File \"/home/nikita/Code/random-feature-boosting/optuna_kfoldCV.py\", line 301, in evaluate_dataset_with_model\n",
      "    results = evaluate_model_func(\n",
      "  File \"/home/nikita/Code/random-feature-boosting/regression_param_specs.py\", line 93, in evaluate_GreedyRFBoost\n",
      "    return evaluate_pytorch_model_kfoldcv(\n",
      "  File \"/home/nikita/Code/random-feature-boosting/optuna_kfoldCV.py\", line 236, in evaluate_pytorch_model_kfoldcv\n",
      "    score_train, score_test, t_fit, t_inference, best_params = evaluate_pytorch_model_single_fold(\n",
      "  File \"/home/nikita/Code/random-feature-boosting/optuna_kfoldCV.py\", line 165, in evaluate_pytorch_model_single_fold\n",
      "    study.optimize(objective, n_trials=n_optuna_trials)\n",
      "  File \"/home/nikita/Code/zephyrox/.conda/lib/python3.10/site-packages/optuna/study/study.py\", line 475, in optimize\n",
      "    _optimize(\n",
      "  File \"/home/nikita/Code/zephyrox/.conda/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 63, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"/home/nikita/Code/zephyrox/.conda/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 160, in _optimize_sequential\n",
      "    frozen_trial = _run_trial(study, func, catch)\n",
      "  File \"/home/nikita/Code/zephyrox/.conda/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 248, in _run_trial\n",
      "    raise func_err\n",
      "  File \"/home/nikita/Code/zephyrox/.conda/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/nikita/Code/random-feature-boosting/optuna_kfoldCV.py\", line 161, in <lambda>\n",
      "    objective = lambda trial: get_pytorch_optuna_cv_objective(\n",
      "  File \"/home/nikita/Code/random-feature-boosting/optuna_kfoldCV.py\", line 124, in get_pytorch_optuna_cv_objective\n",
      "    model.fit(X_inner_train, y_inner_train)\n",
      "  File \"/home/nikita/Code/random-feature-boosting/models/models.py\", line 44, in fit\n",
      "    self.fit_transform(X, y)\n",
      "  File \"/home/nikita/Code/random-feature-boosting/models/models.py\", line 758, in fit_transform\n",
      "    Delta = sandwiched_LS_dense(R, W, F, self.l2_reg_sandwich)\n",
      "  File \"/home/nikita/Code/random-feature-boosting/models/sandwiched_least_squares.py\", line 83, in sandwiched_LS_dense\n",
      "    V, SX, _ = torch.linalg.svd(X.T @ X, full_matrices=False) # shape (p, p), (p,)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python regression_param_specs.py --models GreedyRFBoostDense --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 100 --device gpu --k_folds 5 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models GreedyRFBoostDiag --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cuda --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models GreedyRFBoostScalar --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cuda --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join json results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic.v1.utils import deep_update\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "def custom_deep_update(original, update):\n",
    "    for key, value in update.items():\n",
    "        if isinstance(value, dict) and key in original:\n",
    "            custom_deep_update(original[key], value)\n",
    "        else:\n",
    "            original[key] = value\n",
    "\n",
    "\n",
    "\n",
    "def get_joined_results_json(\n",
    "        models = [\"End2End\", \"Ridge\", \"RidgeCV\", \"XGBoostRegressor\", \n",
    "                  \"GradientRFBoost\", \"GradientRFBoostID\", \n",
    "                  \"GreedyRFBoostDense\", \"GreedyRFBoostDiag\", \"GreedyRFBoostScalar\"],\n",
    "        save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLRegression/\",\n",
    "        ):\n",
    "    results_json = {}\n",
    "    for model in models:\n",
    "        path = os.path.join(save_dir, f\"regression_{model}.json\")\n",
    "        res = read_json(path)\n",
    "        if results_json == {}:\n",
    "            results_json = res\n",
    "        else:\n",
    "            custom_deep_update(results_json, res)\n",
    "    return results_json\n",
    "\n",
    "\n",
    "\n",
    "def join_jsons_into_array(\n",
    "        results_json,\n",
    "        ):\n",
    "    results = []\n",
    "    for dataset, dataset_results in results_json.items():\n",
    "        res = []\n",
    "        for model_name, model_results in dataset_results.items():\n",
    "            model_res = np.stack([model_results[\"score_train\"], model_results[\"score_test\"], model_results[\"t_fit\"], model_results[\"t_inference\"]])\n",
    "            res.append(model_res)\n",
    "        results.append(res)\n",
    "    return np.stack(results) # (n_datasets, n_models, 4, n_folds)\n",
    "\n",
    "\n",
    "\n",
    "def results_to_df(\n",
    "        models = [\"End2End\", \"Ridge\", \"RidgeCV\", \"XGBoostRegressor\", \n",
    "                  \"GradientRFBoost\", \"GradientRFBoostID\", \n",
    "                  \"GreedyRFBoostDense\", \"GreedyRFBoostDiag\", \"GreedyRFBoostScalar\"],\n",
    "        save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLRegression/\",\n",
    "        ):\n",
    "    # Load and join the JSON data\n",
    "    results_json = get_joined_results_json(models, save_dir)\n",
    "    results = join_jsons_into_array(results_json) # (n_datasets, n_models, 4, n_folds)\n",
    "    #TODO for now just average. later, add stds too\n",
    "    results = np.mean(results, axis=-1)\n",
    "    \n",
    "    # Extract dataset names and prepare metrics\n",
    "    datasets = list(results_json.keys())\n",
    "    models = list(results_json[datasets[0]].keys())\n",
    "    metrics = [\"score_train\", \"score_test\", \"t_fit\", \"t_inference\"]\n",
    "    \n",
    "    # Create a dictionary to hold metric-specific DataFrames\n",
    "    metric_dfs = {metric: pd.DataFrame(index=datasets, columns=models) for metric in metrics}\n",
    "    \n",
    "    # Populate the DataFrames for each metric\n",
    "    for dataset_idx, dataset in enumerate(datasets):\n",
    "        for model_idx, model in enumerate(models):\n",
    "            for metric_idx, metric in enumerate(metrics):\n",
    "                # Average across folds for each metric\n",
    "                metric_dfs[metric].loc[dataset, model] = results[dataset_idx, model_idx, metric_idx]\n",
    "    \n",
    "    return metric_dfs  # Return a dictionary of metric-specific DataFrames\n",
    "\n",
    "\n",
    "df = results_to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_train\"].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].rank(axis=1).mean().sort_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
