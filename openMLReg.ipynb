{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, tensor\n",
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "from optuna_kfoldCV import evaluate_dataset_with_model, run_all_openML_with_model\n",
    "from regression_param_specs import evaluate_Ridge, evaluate_XGBoostRegressor\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the collection with ID 353\n",
    "collection = openml.study.get_suite(353)\n",
    "dataset_ids = collection.data\n",
    "metadata_list = []\n",
    "\n",
    "# Fetch and process each dataset\n",
    "for i, dataset_id in enumerate(dataset_ids):\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        target=dataset.default_target_attribute\n",
    "    )\n",
    "\n",
    "    #count missing values in X\n",
    "    missing_values_count = X.isnull().sum().sum()\n",
    "    print(f\"Missing values in X: {missing_values_count}\")\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)[..., None]\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    # Determine if the dataset has categorical features\n",
    "    has_categorical = any(categorical_indicator)\n",
    "    \n",
    "    # Extract the required metadata\n",
    "    metadata = {\n",
    "        'dataset_id': dataset.id,\n",
    "        'name': dataset.name,\n",
    "        'n_obs': int(dataset.qualities['NumberOfInstances']),\n",
    "        'n_features': int(dataset.qualities['NumberOfFeatures']),\n",
    "        '%_unique_y': len(np.unique(y))/len(y),\n",
    "        'n_unique_y': len(np.unique(y)),\n",
    "        'has_categorical': has_categorical,\n",
    "        'n_missing_values': missing_values_count,\n",
    "    }\n",
    "    \n",
    "    metadata_list.append(metadata)\n",
    "    print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset.id}: {dataset.name}\")\n",
    "\n",
    "# Create a DataFrame from the metadata list\n",
    "df_metadata = pd.DataFrame(metadata_list).sort_values('%_unique_y', ascending=False).set_index(\"dataset_id\").sort_index()\n",
    "df_metadata.sort_values('%_unique_y', ascending=True)\n",
    "\n",
    "# Display the metadata DataFrame\n",
    "df_metadata.loc[44962, \"has_categorical\"] = True\n",
    "df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx 0 id 41021 X (1232, 72) y (1232, 1) 0 0\n",
      "idx 1 id 44956 X (4177, 10) y (4177, 1) 0 0\n",
      "idx 2 id 44957 X (1503, 5) y (1503, 1) 0 0\n",
      "idx 3 id 44958 X (2043, 16) y (2043, 1) 0 0\n",
      "idx 4 id 44959 X (1030, 8) y (1030, 1) 0 0\n",
      "idx 5 id 44960 X (768, 8) y (768, 1) 0 0\n",
      "idx 6 id 44962 X (517, 29) y (517, 1) 0 0\n",
      "idx 7 id 44963 X (5000, 9) y (5000, 1) 0 0\n",
      "idx 8 id 44964 X (5000, 81) y (5000, 1) 0 0\n",
      "idx 9 id 44965 X (1059, 116) y (1059, 1) 0 0\n",
      "idx 10 id 44966 X (1066, 29) y (1066, 1) 0 0\n",
      "idx 11 id 44967 X (649, 56) y (649, 1) 0 0\n",
      "idx 12 id 44969 X (5000, 14) y (5000, 1) 0 0\n",
      "idx 13 id 44970 X (908, 6) y (908, 1) 0 0\n",
      "idx 14 id 44971 X (4898, 11) y (4898, 1) 0 0\n",
      "idx 15 id 44972 X (1599, 11) y (1599, 1) 0 0\n",
      "idx 16 id 44973 X (5000, 12) y (5000, 1) 0 0\n",
      "idx 17 id 44974 X (5000, 24) y (5000, 1) 0 0\n",
      "idx 18 id 44975 X (5000, 48) y (5000, 1) 0 0\n",
      "idx 19 id 44976 X (5000, 21) y (5000, 1) 0 0\n",
      "idx 20 id 44977 X (5000, 8) y (5000, 1) 0 0\n",
      "idx 21 id 44978 X (5000, 21) y (5000, 1) 0 0\n",
      "idx 22 id 44979 X (5000, 26) y (5000, 1) 0 0\n",
      "idx 23 id 44980 X (5000, 8) y (5000, 1) 0 0\n",
      "idx 24 id 44981 X (5000, 32) y (5000, 1) 0 0\n",
      "idx 25 id 44983 X (5000, 15) y (5000, 1) 0 0\n",
      "idx 26 id 44984 X (5000, 12) y (5000, 1) 0 0\n",
      "idx 27 id 44987 X (1156, 39) y (1156, 1) 0 0\n",
      "idx 28 id 44989 X (5000, 132) y (5000, 1) 0 0\n",
      "idx 29 id 44990 X (5000, 49) y (5000, 1) 0 0\n",
      "idx 30 id 44993 X (5000, 25) y (5000, 1) 0 0\n",
      "idx 31 id 44994 X (804, 17) y (804, 1) 0 0\n",
      "idx 32 id 45012 X (5000, 190) y (5000, 1) 0 0\n",
      "idx 33 id 45402 X (3107, 6) y (3107, 1) 0 0\n"
     ]
    }
   ],
   "source": [
    "from optuna_kfoldCV import np_load_openml_dataset, openML_reg_ids\n",
    "import numpy as np\n",
    "\n",
    "for idx, id in enumerate(openML_reg_ids):\n",
    "    X,y = np_load_openml_dataset(id, \"regression\")\n",
    "    print(\"idx\", idx, \"id\", id, \"X\", X.shape, \"y\", y.shape, np.isnan(X).sum(), np.isnan(y).sum())\n",
    "\n",
    "# for id in df_metadata.index:\n",
    "#     X,y = np_load_openml_dataset(id, \"regression\")\n",
    "#     print(\"id\", id, \"X\", X.shape, \"y\", y.shape, np.isnan(X).sum(), np.isnan(y).sum())\n",
    "\n",
    "\n",
    "## TODO TODO TODO NEXT: investigate nans, and \"Mean of empty slice\". also look at less than 200 features and check performance on reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments (just for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python regression_param_specs.py \\\n",
    "#     --models End2End \\\n",
    "#     --dataset_indices 0 \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ \\\n",
    "#     --n_optuna_trials 2 \\\n",
    "#     --device cuda \\\n",
    "#     --k_folds 2 \\\n",
    "#     --cv_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-01-13 17:04:40,307]\u001b[0m A new study created in memory with name: no-name-82933992-5a54-4816-a290-ee82a1d077d8\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:04:40,377]\u001b[0m Trial 0 finished with value: 0.69959357380867 and parameters: {'l2_reg': 0.0074593432857265485}. Best is trial 0 with value: 0.69959357380867.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:04:40,380]\u001b[0m Trial 1 finished with value: 0.6974271237850189 and parameters: {'l2_reg': 5.669849511478847}. Best is trial 1 with value: 0.6974271237850189.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:04:40,383]\u001b[0m A new study created in memory with name: no-name-d3b0f327-ac67-4aa7-b7e5-830b10cf6ce1\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:04:40,385]\u001b[0m Trial 0 finished with value: 0.788824588060379 and parameters: {'l2_reg': 0.0074593432857265485}. Best is trial 0 with value: 0.788824588060379.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:04:40,388]\u001b[0m Trial 1 finished with value: 0.7878963053226471 and parameters: {'l2_reg': 5.669849511478847}. Best is trial 1 with value: 0.7878963053226471.\u001b[0m\n",
      " 1/1 Processed dataset 44966\n"
     ]
    }
   ],
   "source": [
    "!python regression_param_specs.py \\\n",
    "    --models Ridge \\\n",
    "    --dataset_indices 10 \\\n",
    "    --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ \\\n",
    "    --n_optuna_trials 2 \\\n",
    "    --device cuda \\\n",
    "    --k_folds 2 \\\n",
    "    --cv_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-01-13 17:04:49,281]\u001b[0m A new study created in memory with name: no-name-5ccd98cc-7727-4429-8f29-303bbfc99b0d\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:04:49,511]\u001b[0m Trial 0 finished with value: 0.2789393663406372 and parameters: {'objective': 'reg:squarederror', 'alpha': 0.0001329291894316216, 'lambda': 56.69849511478853, 'learning_rate': 0.17524101118128144, 'n_estimators': 299, 'max_depth': 4}. Best is trial 0 with value: 0.2789393663406372.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:04:49,640]\u001b[0m Trial 1 finished with value: 0.32875896990299225 and parameters: {'objective': 'reg:squarederror', 'alpha': 2.9375384576328295e-05, 'lambda': 0.0019517224641449498, 'learning_rate': 0.29621516588303487, 'n_estimators': 302, 'max_depth': 8}. Best is trial 0 with value: 0.2789393663406372.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:04:49,766]\u001b[0m A new study created in memory with name: no-name-fe742c46-14bf-4b0c-9645-3e02eb93c578\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:04:49,953]\u001b[0m Trial 0 finished with value: 0.2985759973526001 and parameters: {'objective': 'reg:squarederror', 'alpha': 0.0001329291894316216, 'lambda': 56.69849511478853, 'learning_rate': 0.17524101118128144, 'n_estimators': 299, 'max_depth': 4}. Best is trial 0 with value: 0.2985759973526001.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:04:50,128]\u001b[0m Trial 1 finished with value: 0.35015538334846497 and parameters: {'objective': 'reg:squarederror', 'alpha': 2.9375384576328295e-05, 'lambda': 0.0019517224641449498, 'learning_rate': 0.29621516588303487, 'n_estimators': 302, 'max_depth': 8}. Best is trial 0 with value: 0.2985759973526001.\u001b[0m\n",
      " 1/1 Processed dataset 41021\n"
     ]
    }
   ],
   "source": [
    "!python regression_param_specs.py \\\n",
    "    --models XGBoostRegressor \\\n",
    "    --dataset_indices 0 \\\n",
    "    --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ \\\n",
    "    --n_optuna_trials 2 \\\n",
    "    --device cpu \\\n",
    "    --k_folds 2 \\\n",
    "    --cv_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-01-13 17:06:07,193]\u001b[0m A new study created in memory with name: no-name-cbbad435-22cb-4f63-9ca1-80ef72c7508d\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:06:07,318]\u001b[0m Trial 0 finished with value: 0.3492553383111954 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'iid', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 2, 'l2_reg': 5.669849511478847, 'l2_ghat': 0.0717714192799201, 'boost_lr': 0.3968793330444371, 'hidden_dim': 27, 'SWIM_scale': 0.5229904105883546}. Best is trial 0 with value: 0.3492553383111954.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:06:07,367]\u001b[0m Trial 1 finished with value: 0.323387548327446 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'iid', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 1, 'l2_reg': 2.1423021757741068, 'l2_ghat': 0.006440507553993709, 'boost_lr': 0.5105903209394755, 'hidden_dim': 17, 'SWIM_scale': 1.94734224128349}. Best is trial 1 with value: 0.323387548327446.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:06:07,408]\u001b[0m A new study created in memory with name: no-name-85f44253-7931-4a8a-b468-d898d662a5e8\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:06:07,496]\u001b[0m Trial 0 finished with value: 0.3971528112888336 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'iid', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 2, 'l2_reg': 5.669849511478847, 'l2_ghat': 0.0717714192799201, 'boost_lr': 0.3968793330444371, 'hidden_dim': 27, 'SWIM_scale': 0.5229904105883546}. Best is trial 0 with value: 0.3971528112888336.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:06:07,538]\u001b[0m Trial 1 finished with value: 0.3700651526451111 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'iid', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 1, 'l2_reg': 2.1423021757741068, 'l2_ghat': 0.006440507553993709, 'boost_lr': 0.5105903209394755, 'hidden_dim': 17, 'SWIM_scale': 1.94734224128349}. Best is trial 1 with value: 0.3700651526451111.\u001b[0m\n",
      " 1/1 Processed dataset 41021\n"
     ]
    }
   ],
   "source": [
    "!python regression_param_specs.py \\\n",
    "    --models GradientRFRBoost_upscaleiid \\\n",
    "    --dataset_indices 0 \\\n",
    "    --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ \\\n",
    "    --n_optuna_trials 2 \\\n",
    "    --device cpu \\\n",
    "    --k_folds 2 \\\n",
    "    --cv_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python regression_param_specs.py \\\n",
    "#     --models GradientRFRBoost_upscaleiid \\\n",
    "#     --dataset_indices 0 \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ \\\n",
    "#     --n_optuna_trials 2 \\\n",
    "#     --device cpu \\\n",
    "#     --k_folds 2 \\\n",
    "#     --cv_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-01-13 17:08:50,822]\u001b[0m A new study created in memory with name: no-name-157fc735-f1bf-4917-add8-0c5b7c97ade4\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:08:51,123]\u001b[0m Trial 0 finished with value: 0.3902551233768463 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'SWIM', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'sandwich_solver': 'dense', 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 2, 'l2_reg': 5.669849511478847, 'l2_ghat': 0.0717714192799201, 'boost_lr': 0.3968793330444371, 'hidden_dim': 27, 'SWIM_scale': 0.5229904105883546}. Best is trial 0 with value: 0.3902551233768463.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:08:51,272]\u001b[0m Trial 1 finished with value: 0.3447978347539902 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'SWIM', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'sandwich_solver': 'dense', 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 1, 'l2_reg': 2.1423021757741068, 'l2_ghat': 0.006440507553993709, 'boost_lr': 0.5105903209394755, 'hidden_dim': 17, 'SWIM_scale': 1.94734224128349}. Best is trial 1 with value: 0.3447978347539902.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:08:51,365]\u001b[0m A new study created in memory with name: no-name-268f8cb3-f91b-4c97-9d26-b055cb0d3ad6\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:08:51,635]\u001b[0m Trial 0 finished with value: 0.4404947757720947 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'SWIM', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'sandwich_solver': 'dense', 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 2, 'l2_reg': 5.669849511478847, 'l2_ghat': 0.0717714192799201, 'boost_lr': 0.3968793330444371, 'hidden_dim': 27, 'SWIM_scale': 0.5229904105883546}. Best is trial 0 with value: 0.4404947757720947.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:08:51,746]\u001b[0m Trial 1 finished with value: 0.38714973628520966 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'SWIM', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'sandwich_solver': 'dense', 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 1, 'l2_reg': 2.1423021757741068, 'l2_ghat': 0.006440507553993709, 'boost_lr': 0.5105903209394755, 'hidden_dim': 17, 'SWIM_scale': 1.94734224128349}. Best is trial 1 with value: 0.38714973628520966.\u001b[0m\n",
      " 1/1 Processed dataset 41021\n"
     ]
    }
   ],
   "source": [
    "!python regression_param_specs.py \\\n",
    "    --models GreedyRFRBoostDense \\\n",
    "    --dataset_indices 0 \\\n",
    "    --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ \\\n",
    "    --n_optuna_trials 2 \\\n",
    "    --device cpu \\\n",
    "    --k_folds 2 \\\n",
    "    --cv_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-01-13 17:08:56,047]\u001b[0m A new study created in memory with name: no-name-c2d649a2-af7f-4344-8cba-2e637827ce21\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:08:56,061]\u001b[0m Trial 0 finished with value: 0.4694204479455948 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'SWIM', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'sandwich_solver': 'diag', 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 2, 'l2_reg': 5.669849511478847, 'l2_ghat': 0.0717714192799201, 'boost_lr': 0.3968793330444371, 'hidden_dim': 27, 'SWIM_scale': 0.5229904105883546}. Best is trial 0 with value: 0.4694204479455948.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:08:56,071]\u001b[0m Trial 1 finished with value: 0.482323095202446 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'SWIM', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'sandwich_solver': 'diag', 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 1, 'l2_reg': 2.1423021757741068, 'l2_ghat': 0.006440507553993709, 'boost_lr': 0.5105903209394755, 'hidden_dim': 17, 'SWIM_scale': 1.94734224128349}. Best is trial 0 with value: 0.4694204479455948.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:08:56,080]\u001b[0m A new study created in memory with name: no-name-d3f9f128-6994-44b1-88f3-33099a8a0957\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:08:56,092]\u001b[0m Trial 0 finished with value: 0.49316568672657013 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'SWIM', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'sandwich_solver': 'diag', 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 2, 'l2_reg': 5.669849511478847, 'l2_ghat': 0.0717714192799201, 'boost_lr': 0.3968793330444371, 'hidden_dim': 27, 'SWIM_scale': 0.5229904105883546}. Best is trial 0 with value: 0.49316568672657013.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:08:56,104]\u001b[0m Trial 1 finished with value: 0.45853061974048615 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'SWIM', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'sandwich_solver': 'diag', 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 1, 'l2_reg': 2.1423021757741068, 'l2_ghat': 0.006440507553993709, 'boost_lr': 0.5105903209394755, 'hidden_dim': 17, 'SWIM_scale': 1.94734224128349}. Best is trial 1 with value: 0.45853061974048615.\u001b[0m\n",
      " 1/1 Processed dataset 41021\n"
     ]
    }
   ],
   "source": [
    "!python regression_param_specs.py \\\n",
    "    --models GreedyRFRBoostDiag \\\n",
    "    --dataset_indices 0 \\\n",
    "    --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ \\\n",
    "    --n_optuna_trials 2 \\\n",
    "    --device cpu \\\n",
    "    --k_folds 2 \\\n",
    "    --cv_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-01-13 17:09:00,157]\u001b[0m A new study created in memory with name: no-name-5ce5c2b8-3767-4961-853a-ebec89a94f46\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:09:00,172]\u001b[0m Trial 0 finished with value: 0.4558122158050537 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'SWIM', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'sandwich_solver': 'scalar', 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 2, 'l2_reg': 5.669849511478847, 'l2_ghat': 0.0717714192799201, 'boost_lr': 0.3968793330444371, 'hidden_dim': 27, 'SWIM_scale': 0.5229904105883546}. Best is trial 0 with value: 0.4558122158050537.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:09:00,181]\u001b[0m Trial 1 finished with value: 0.4943731874227524 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'SWIM', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'sandwich_solver': 'scalar', 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 1, 'l2_reg': 2.1423021757741068, 'l2_ghat': 0.006440507553993709, 'boost_lr': 0.5105903209394755, 'hidden_dim': 17, 'SWIM_scale': 1.94734224128349}. Best is trial 0 with value: 0.4558122158050537.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:09:00,191]\u001b[0m A new study created in memory with name: no-name-5b1287ea-4831-4df8-a23e-d505a5ea72b7\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:09:00,204]\u001b[0m Trial 0 finished with value: 0.4977233409881592 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'SWIM', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'sandwich_solver': 'scalar', 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 2, 'l2_reg': 5.669849511478847, 'l2_ghat': 0.0717714192799201, 'boost_lr': 0.3968793330444371, 'hidden_dim': 27, 'SWIM_scale': 0.5229904105883546}. Best is trial 0 with value: 0.4977233409881592.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:09:00,212]\u001b[0m Trial 1 finished with value: 0.4708356708288193 and parameters: {'in_dim': 72, 'out_dim': 1, 'feature_type': 'SWIM', 'upscale_type': 'SWIM', 'randfeat_xt_dim': 512, 'randfeat_x0_dim': 512, 'sandwich_solver': 'scalar', 'activation': 'tanh', 'use_batchnorm': True, 'n_layers': 1, 'l2_reg': 2.1423021757741068, 'l2_ghat': 0.006440507553993709, 'boost_lr': 0.5105903209394755, 'hidden_dim': 17, 'SWIM_scale': 1.94734224128349}. Best is trial 1 with value: 0.4708356708288193.\u001b[0m\n",
      " 1/1 Processed dataset 41021\n"
     ]
    }
   ],
   "source": [
    "!python regression_param_specs.py \\\n",
    "    --models GreedyRFRBoostScalar \\\n",
    "    --dataset_indices 0 \\\n",
    "    --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ \\\n",
    "    --n_optuna_trials 2 \\\n",
    "    --device cpu \\\n",
    "    --k_folds 2 \\\n",
    "    --cv_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-01-13 17:09:04,055]\u001b[0m A new study created in memory with name: no-name-41dd190f-374c-4e35-a4a4-1bdebe31e98a\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:09:04,070]\u001b[0m Trial 0 finished with value: 0.25173622369766235 and parameters: {'n_layers': 0, 'in_dim': 72, 'out_dim': 1, 'upscale_type': 'SWIM', 'activation': 'tanh', 'use_batchnorm': False, 'l2_reg': 0.0074593432857265485, 'hidden_dim': 431, 'SWIM_scale': 1.530989398169959}. Best is trial 0 with value: 0.25173622369766235.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:09:04,076]\u001b[0m Trial 1 finished with value: 0.39663705229759216 and parameters: {'n_layers': 0, 'in_dim': 72, 'out_dim': 1, 'upscale_type': 'SWIM', 'activation': 'tanh', 'use_batchnorm': False, 'l2_reg': 0.09846738873614563, 'hidden_dim': 27, 'SWIM_scale': 0.5229904105883546}. Best is trial 0 with value: 0.25173622369766235.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:09:04,088]\u001b[0m A new study created in memory with name: no-name-8870aa32-a0d6-4138-bf0f-29b4d16c79cc\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:09:04,101]\u001b[0m Trial 0 finished with value: 0.2614549845457077 and parameters: {'n_layers': 0, 'in_dim': 72, 'out_dim': 1, 'upscale_type': 'SWIM', 'activation': 'tanh', 'use_batchnorm': False, 'l2_reg': 0.0074593432857265485, 'hidden_dim': 431, 'SWIM_scale': 1.530989398169959}. Best is trial 0 with value: 0.2614549845457077.\u001b[0m\n",
      "\u001b[32m[I 2025-01-13 17:09:04,110]\u001b[0m Trial 1 finished with value: 0.3951198160648346 and parameters: {'n_layers': 0, 'in_dim': 72, 'out_dim': 1, 'upscale_type': 'SWIM', 'activation': 'tanh', 'use_batchnorm': False, 'l2_reg': 0.09846738873614563, 'hidden_dim': 27, 'SWIM_scale': 0.5229904105883546}. Best is trial 0 with value: 0.2614549845457077.\u001b[0m\n",
      " 1/1 Processed dataset 41021\n"
     ]
    }
   ],
   "source": [
    "!python regression_param_specs.py \\\n",
    "    --models RFNN \\\n",
    "    --dataset_indices 0 \\\n",
    "    --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ \\\n",
    "    --n_optuna_trials 2 \\\n",
    "    --device cpu \\\n",
    "    --k_folds 2 \\\n",
    "    --cv_seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join json results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic.v1.utils import deep_update\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from optuna_kfoldCV import openML_reg_ids\n",
    "\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "def custom_deep_update(original, update):\n",
    "    for key, value in update.items():\n",
    "        if isinstance(value, dict) and key in original:\n",
    "            custom_deep_update(original[key], value)\n",
    "        else:\n",
    "            original[key] = value\n",
    "\n",
    "\n",
    "\n",
    "def get_joined_results_json(\n",
    "        models = [\"End2End\", \"Ridge\", \"XGBoostRegressor\",\n",
    "                  \"GradientRFRBoost\", \"GradientRFRBoostID\", \n",
    "                  \"GreedyRFRBoostDense\", \"GreedyRFRBoostDiag\", \"GreedyRFRBoostScalar\",\n",
    "                  \"RandomFeatureNetwork\"],\n",
    "        datasets = openML_reg_ids,\n",
    "        save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLRegression/\",\n",
    "        ):\n",
    "    results_json = {}\n",
    "    for model in models:\n",
    "        for dataset in datasets:\n",
    "            path = os.path.join(save_dir, f\"regression_{dataset}_{model}.json\")\n",
    "            res = read_json(path)\n",
    "            if results_json == {}:\n",
    "                results_json = res\n",
    "            else:\n",
    "                custom_deep_update(results_json, res)\n",
    "    return results_json\n",
    "\n",
    "\n",
    "\n",
    "def join_jsons_into_array(\n",
    "        results_json,\n",
    "        ):\n",
    "    results = []\n",
    "    for dataset, dataset_results in results_json.items():\n",
    "        res = []\n",
    "        for model_name, model_results in dataset_results.items():\n",
    "            model_res = np.stack([model_results[\"score_train\"], model_results[\"score_test\"], model_results[\"t_fit\"], model_results[\"t_inference\"]])\n",
    "            res.append(model_res)\n",
    "        results.append(res)\n",
    "    return np.stack(results) # (n_datasets, n_models, 4, n_folds)\n",
    "\n",
    "\n",
    "def results_to_df(\n",
    "        models = [\"End2End\", \"Ridge\", \"XGBoostRegressor\", \n",
    "                  \"GradientRFRBoost\", \"GradientRFRBoostID\", \n",
    "                  \"GradientRFRBoost_relu\",\n",
    "                  \"GreedyRFRBoostDense\", \"GreedyRFRBoostDiag\", \"GreedyRFRBoostScalar\",\n",
    "                  \"GreedyRFRBoostDense_relu\", \"GreedyRFRBoostDiag_relu\", \"GreedyRFRBoostScalar_relu\",\n",
    "                  \"RandomFeatureNetwork\", \"RandomFeatureNetwork_iid\",\n",
    "                  \"RandomFeatureNetwork_relu\", \"RandomFeatureNetwork_iid_relu\",\n",
    "                  ],\n",
    "        datasets = openML_reg_ids[:],\n",
    "        save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLRegression/\",\n",
    "        ):\n",
    "    # Load and join the JSON data\n",
    "    results_json = get_joined_results_json(models, datasets, save_dir)\n",
    "    results = join_jsons_into_array(results_json) # (n_datasets, n_models, 4, n_folds)\n",
    "    \n",
    "    # Calculate means and stds across folds\n",
    "    results_mean = np.mean(results, axis=-1)  # (n_datasets, n_models, 4)\n",
    "    results_std = np.std(results, axis=-1)    # (n_datasets, n_models, 4)\n",
    "    \n",
    "    # Create a dictionary to hold both mean and std DataFrames\n",
    "    metrics = [\"score_train\", \"score_test\", \"t_fit\", \"t_inference\"]\n",
    "    metric_dfs = {}\n",
    "    \n",
    "    # Initialize DataFrames for both mean and std metrics\n",
    "    for metric in metrics:\n",
    "        metric_dfs[metric] = pd.DataFrame(index=datasets, columns=models)\n",
    "        metric_dfs[f\"{metric}_std\"] = pd.DataFrame(index=datasets, columns=models)\n",
    "    \n",
    "    # Populate the DataFrames for each metric\n",
    "    for dataset_idx, dataset in enumerate(datasets):\n",
    "        for model_idx, model in enumerate(models):\n",
    "            for metric_idx, metric in enumerate(metrics):\n",
    "                # Set mean value\n",
    "                metric_dfs[metric].loc[dataset, model] = results_mean[dataset_idx, model_idx, metric_idx]\n",
    "                # Set* std value\n",
    "                metric_dfs[f\"{metric}_std\"].loc[dataset, model] = results_std[dataset_idx, model_idx, metric_idx]\n",
    "    \n",
    "    return metric_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(35):\n",
    "    for model in [\"End2End\", \n",
    "                  \"Ridge\", \"XGBoostRegressor\", \n",
    "                  \"GRFRBoostedXGBoostRegressor\",\n",
    "                  \"GradientRFRBoost\", #\"GradientRFRBoostID\", \n",
    "                  #\"GradientRFRBoost_relu\",\n",
    "                  \"GreedyRFRBoostDense\", \"GreedyRFRBoostDiag\", \"GreedyRFRBoostScalar\",\n",
    "                  #\"GreedyRFRBoostDense_relu\", \"GreedyRFRBoostDiag_relu\", \"GreedyRFRBoostScalar_relu\",\n",
    "                  \"RandomFeatureNetwork\", \n",
    "                  \"RandomFeatureNetwork_iid\",\n",
    "                  #\"RandomFeatureNetwork_relu\", \"RandomFeatureNetwork_iid_relu\",\n",
    "                  ]:\n",
    "        try:\n",
    "            results = results_to_df(models=[model], datasets=[openML_reg_ids[i]])\n",
    "            # print(results)\n",
    "        except:\n",
    "            print(f\"Failed for {model} on {i}, ie {openML_reg_ids[i]}\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = results_to_df(        \n",
    "#     datasets = openML_reg_ids_noCat[[0,1,2,3,4,5,6,7,8,9,10,     13,14,15,16,17,18,19]],\n",
    "#     save_dir = \"/home/nikita/Code/random-feature-boosting/save/regv2_added40nlayers/OpenMLRegression/\",\n",
    "#     )\n",
    "df = results_to_df(        \n",
    "    models = [\"End2End\", \n",
    "              \"Ridge\", \"XGBoostRegressor\", \n",
    "              \"GRFRBoostedXGBoostRegressor\",\n",
    "                  \"GradientRFRBoost\", \n",
    "                  #\"GradientRFRBoostID\", \n",
    "                  #\"GradientRFRBoost_relu\",\n",
    "                  \"GreedyRFRBoostDense\", \"GreedyRFRBoostDiag\", \"GreedyRFRBoostScalar\",\n",
    "                  #\"GreedyRFRBoostDense_relu\", \"GreedyRFRBoostDiag_relu\", \"GreedyRFRBoostScalar_relu\",\n",
    "                  \"RandomFeatureNetwork\", \n",
    "                  \"RandomFeatureNetwork_iid\",\n",
    "                  #\"RandomFeatureNetwork_relu\", \"RandomFeatureNetwork_iid_relu\",\n",
    "                  ],\n",
    "    datasets = openML_reg_ids[[i for i in range(35) if i not in []]], #[9, 28, 30, 33]]],\n",
    "    #datasets = openML_reg_ids[:],\n",
    "    save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLRegression/\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].mean().sort_values(ascending=True)\n",
    "# GradientRFRBoost_upscaleiid        0.409032\n",
    "# End2End                              0.4101\n",
    "# GreedyRFRBoostDense_upscaleiid     0.411854\n",
    "# GreedyRFRBoostDiag_upscaleiid       0.43373\n",
    "# GreedyRFRBoostScalar_upscaleiid    0.456377\n",
    "# RandomFeatureNetwork_iid           0.494089\n",
    "# Ridge                              0.529513\n",
    "# dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_train\"].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].rank(axis=1).mean().sort_values()\n",
    "# GradientRFRBoost_upscaleiid        2.400000\n",
    "# GreedyRFRBoostDense_upscaleiid     2.400000\n",
    "# End2End                            3.542857\n",
    "# GreedyRFRBoostDiag_upscaleiid      3.685714\n",
    "# GreedyRFRBoostScalar_upscaleiid    4.657143\n",
    "# RandomFeatureNetwork_iid           5.371429\n",
    "# Ridge                              5.942857\n",
    "# dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].rank(axis=1).mean().sort_values()\n",
    "# GradientRFRBoost_upscaleiid        2.400000\n",
    "# GreedyRFRBoostDense_upscaleiid     2.400000\n",
    "# End2End                            3.542857\n",
    "# GreedyRFRBoostDiag_upscaleiid      3.685714\n",
    "# GreedyRFRBoostScalar_upscaleiid    4.657143\n",
    "# RandomFeatureNetwork_iid           5.371429\n",
    "# Ridge                              5.942857\n",
    "# dtype: float64\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# XGBoostRegressor               2.882353\n",
    "# GRFRBoostedXGBoostRegressor    3.588235\n",
    "# GradientRFRBoost               4.147059\n",
    "# GreedyRFRBoostDense            4.352941\n",
    "# GreedyRFRBoostDiag             5.441176\n",
    "# End2End                        5.794118\n",
    "# RandomFeatureNetwork_iid       5.794118\n",
    "# RandomFeatureNetwork           6.176471\n",
    "# GreedyRFRBoostScalar           8.147059\n",
    "# Ridge                          8.676471\n",
    "# dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_old = results_to_df(        \n",
    "#     models = [\"End2End_cpu\", \n",
    "#               \"Ridge\", \"XGBoostRegressor\", \n",
    "#                   \"GradientRFRBoost\", \n",
    "#                   #\"GradientRFRBoostID\", \n",
    "#                   #\"GradientRFRBoost_relu\",\n",
    "#                   \"GreedyRFRBoostDense\", \"GreedyRFRBoostDiag\", \"GreedyRFRBoostScalar\",\n",
    "#                   #\"GreedyRFRBoostDense_relu\", \"GreedyRFRBoostDiag_relu\", \"GreedyRFRBoostScalar_relu\",\n",
    "#                   \"RandomFeatureNetwork\", \n",
    "#                   \"RandomFeatureNetwork_iid\",\n",
    "#                   #\"RandomFeatureNetwork_relu\", \"RandomFeatureNetwork_iid_relu\",\n",
    "#                   ],\n",
    "#     #datasets = openML_reg_ids[[i for i in range(35) if i != 8]],\n",
    "#     datasets = openML_reg_ids[:],\n",
    "#     #save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLRegression_swimvariable_hiddendimvariable/\",\n",
    "#     save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLRegression/\",\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.visualisation import plot_critical_difference, plot_significance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the plot\n",
    "plot = plot_critical_difference(df[\"score_test\"].values,\n",
    "                                df[\"score_test\"].columns.tolist(), \n",
    "                                alpha=0.05, \n",
    "                                lower_better=True)\n",
    "\n",
    "# Retrieve the figure and axes from the plot\n",
    "fig = plot[0].figure\n",
    "ax = plot[0]\n",
    "\n",
    "# Adjust figure size\n",
    "fig.set_size_inches(6, 3)\n",
    "\n",
    "# Adjust layout\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the figures\n",
    "plot[0].savefig(\"results/OpenMLRegression/OpenMLReg_critical_difference.eps\", bbox_inches='tight')\n",
    "plot[0].savefig(\"results/OpenMLRegression/OpenMLReg_critical_difference.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_latex_table(df):\n",
    "    table = \"\"\"\n",
    "\\\\begin{table}[t]\n",
    "\\\\caption{Test accuracies on the concentric circles task.}\n",
    "\\\\label{tab:concentric-circles}\n",
    "\\\\vskip 0.15in\n",
    "\\\\begin{center}\n",
    "\\\\begin{small}\n",
    "\\\\begin{sc}\n",
    "\\\\begin{tabular}{lcc}\n",
    "\\\\toprule\n",
    "Model & Mean Acc & Std Dev \\\\\\\\\n",
    "\\\\midrule\n",
    "\"\"\"\n",
    "    for model_name in df.columns:\n",
    "        accs = df[model_name]\n",
    "        mean_acc = np.mean(accs)\n",
    "        std_acc = np.std(accs)\n",
    "        table += f\"{model_name} & {mean_acc:.4f} & {std_acc:.4f} \\\\\\\\\\n\"\n",
    "    \n",
    "    table += \"\"\"\n",
    "\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "\\\\end{sc}\n",
    "\\\\end{small}\n",
    "\\\\end{center}\n",
    "\\\\vskip -0.1in\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "    return table\n",
    "\n",
    "# Example usage\n",
    "# Assuming `results_df` is your pandas DataFrame\n",
    "latex_table = create_latex_table(df_old[\"score_test\"])\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = results_to_df(        \n",
    "#     datasets = openML_reg_ids_noCat[[0,1,2  ,4,5,6,7,8,9,10,     13,14,15,16,17,18,19]],\n",
    "#     save_dir = \"/home/nikita/Code/random-feature-boosting/save/regv2_added40nlayers/OpenMLRegression/\",\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2[\"score_test\"].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2[\"score_train\"].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2[\"score_test\"].rank(axis=1).mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of first places\n",
    "# (df2[\"score_test\"].rank(axis=1) == 1).sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoostRegressor       0.389427\n",
    "# End2End                0.408184\n",
    "# GreedyRFBoostDense      0.43249\n",
    "# GradientRFBoost        0.434696\n",
    "# GradientRFBoostID      0.436364\n",
    "# GreedyRFBoostDiag      0.445675\n",
    "# GreedyRFBoostScalar    0.528314\n",
    "# Ridge                  0.606384\n",
    "# RidgeCV                0.606385\n",
    "# dtype: object\n",
    "\n",
    "\n",
    "# XGBoostRegressor       0.170585\n",
    "# End2End                0.345058\n",
    "# GreedyRFBoostDense     0.387421\n",
    "# GradientRFBoost        0.400575\n",
    "# GradientRFBoostID      0.405132\n",
    "# GreedyRFBoostDiag       0.41455\n",
    "# GreedyRFBoostScalar    0.510962\n",
    "# RidgeCV                0.600331\n",
    "# Ridge                   0.60034\n",
    "# dtype: object\n",
    "\n",
    "\n",
    "# XGBoostRegressor       2.666667\n",
    "# End2End                3.333333\n",
    "# GreedyRFBoostDense     3.500000\n",
    "# GradientRFBoost        3.611111\n",
    "# GradientRFBoostID      4.111111\n",
    "# GreedyRFBoostDiag      4.777778\n",
    "# GreedyRFBoostScalar    6.722222\n",
    "# Ridge                  8.055556\n",
    "# RidgeCV                8.222222\n",
    "# dtype: float64\n",
    "\n",
    "\n",
    "# Ridge                   0\n",
    "# RidgeCV                 0\n",
    "# GradientRFBoostID       0\n",
    "# GreedyRFBoostScalar     0\n",
    "# GradientRFBoost         1\n",
    "# GreedyRFBoostDense      1\n",
    "# GreedyRFBoostDiag       1\n",
    "# End2End                 4\n",
    "# XGBoostRegressor       11\n",
    "# dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at small datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less5000 = df_metadata.query(\"n_obs < 5000\").index\n",
    "less1000 = df_metadata.query(\"n_obs < 1000\").index\n",
    "less5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].loc[less5000].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].loc[less5000].rank(axis=1).mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].loc[less5000].rank(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].loc[less1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at distribution of params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_param_distribution(\n",
    "        models = [\"End2End\", \"Ridge\", #\"XGBoostRegressor\", \n",
    "                  \"GradientRFRBoost\", \n",
    "                  #\"GradientRFRBoostID\", \n",
    "                  #\"GradientRFRBoost_relu\",\n",
    "                  \"GreedyRFRBoostDense\", \"GreedyRFRBoostDiag\", \"GreedyRFRBoostScalar\",\n",
    "                  #\"GreedyRFRBoostDense_relu\", \"GreedyRFRBoostDiag_relu\", \"GreedyRFRBoostScalar_relu\",\n",
    "                  \"RandomFeatureNetwork\", \n",
    "                  #\"RandomFeatureNetwork_iid\",\n",
    "                  #\"RandomFeatureNetwork_relu\", \"RandomFeatureNetwork_iid_relu\",\n",
    "                  ],\n",
    "        datasets = openML_reg_ids[:],\n",
    "        save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLRegression/\",\n",
    "        # save_dir = \"/home/nikita/Code/random-feature-boosting/save/regv2_added40nlayers/OpenMLRegression/\",\n",
    "        ):\n",
    "    # Load and join the JSON data\n",
    "    results_json = get_joined_results_json(models, datasets, save_dir)\n",
    "\n",
    "    # model: list_of_param_names\n",
    "    modelwise_param_names = {model: list(results_json[str(datasets[0])][model]['hyperparams'][0])\n",
    "                            for model in models} \n",
    "\n",
    "    # model: param_name: list_of_param_values\n",
    "    param_distribution = { model: {param: [] for param in param_names}\n",
    "                          for model, param_names in modelwise_param_names.items()}\n",
    "\n",
    "    #populate teh param_districution nested dict\n",
    "    for dataset, dataset_results in results_json.items():\n",
    "        for model_name, model_results in dataset_results.items():\n",
    "            for fold in model_results[\"hyperparams\"]:\n",
    "                for param_name, param_val in fold.items():\n",
    "                    param_distribution[model_name][param_name].append(param_val)\n",
    "\n",
    "    # For each model, plot the distribution of each parameter\n",
    "    for model, param_dict in param_distribution.items():\n",
    "        print(f\"Model: {model}\")\n",
    "        for param_name, param_values in param_dict.items():\n",
    "            if param_name not in [\n",
    "                \"out_dim\", \"loss\", \"objective\", \"feature_type\",\n",
    "                \"upscale_type\", \"sandwich_solver\"\n",
    "                ]:\n",
    "                # Create figure with two subplots side by side\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "                \n",
    "                # Linear scale plot\n",
    "                ax1.hist(param_values, bins=20)\n",
    "                ax1.set_title(f\"{model} {param_name}\\n(linear scale)\")\n",
    "                ax1.set_xlabel(param_name)\n",
    "                ax1.set_ylabel(\"Count\")\n",
    "                \n",
    "                # Log scale plot\n",
    "                min_val = np.min(param_values)  # Avoid log(0)\n",
    "                max_val = np.max(param_values)\n",
    "                bins = np.logspace(np.log10(min_val), np.log10(max_val), 20)\n",
    "                ax2.hist(param_values, bins=bins)\n",
    "                ax2.set_xscale('log')\n",
    "                ax2.set_title(f\"{model} {param_name}\\n(log scale)\")\n",
    "                ax2.set_xlabel(param_name)\n",
    "                ax2.set_ylabel(\"Count\")\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "plot_param_distribution()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
