{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, tensor\n",
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "from optuna_kfoldCV import evaluate_dataset_with_model, run_all_openML_with_model\n",
    "from regression_param_specs import evaluate_Ridge, evaluate_XGBoostRegressor\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the collection with ID 353\n",
    "collection = openml.study.get_suite(353)\n",
    "dataset_ids = collection.data\n",
    "metadata_list = []\n",
    "\n",
    "# Fetch and process each dataset\n",
    "for i, dataset_id in enumerate(dataset_ids):\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        target=dataset.default_target_attribute\n",
    "    )\n",
    "\n",
    "    #count missing values in X\n",
    "    missing_values_count = X.isnull().sum().sum()\n",
    "    print(f\"Missing values in X: {missing_values_count}\")\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)[..., None]\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    # Determine if the dataset has categorical features\n",
    "    has_categorical = any(categorical_indicator)\n",
    "    \n",
    "    # Extract the required metadata\n",
    "    metadata = {\n",
    "        'dataset_id': dataset.id,\n",
    "        'name': dataset.name,\n",
    "        'n_obs': int(dataset.qualities['NumberOfInstances']),\n",
    "        'n_features': int(dataset.qualities['NumberOfFeatures']),\n",
    "        '%_unique_y': len(np.unique(y))/len(y),\n",
    "        'n_unique_y': len(np.unique(y)),\n",
    "        'has_categorical': has_categorical,\n",
    "        'n_missing_values': missing_values_count,\n",
    "    }\n",
    "    \n",
    "    metadata_list.append(metadata)\n",
    "    print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset.id}: {dataset.name}\")\n",
    "\n",
    "# Create a DataFrame from the metadata list\n",
    "df_metadata = pd.DataFrame(metadata_list).sort_values('%_unique_y', ascending=False).set_index(\"dataset_id\").sort_index()\n",
    "df_metadata.sort_values('%_unique_y', ascending=True)\n",
    "\n",
    "# Display the metadata DataFrame\n",
    "df_metadata.loc[44962, \"has_categorical\"] = True\n",
    "df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids_no_categorical = list(df_metadata.query(\"has_categorical == False\").index.values)\n",
    "dataset_ids_no_categorical = sorted([int(x) for x in dataset_ids_no_categorical])\n",
    "len(dataset_ids_no_categorical)\n",
    "dataset_ids_no_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments (just for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_all_openML_with_model(\n",
    "#     dataset_ids_no_categorical[0:2], \n",
    "#     evaluate_Ridge,\n",
    "#     name_model=\"Ridge\",\n",
    "#     k_folds=5,\n",
    "#     cv_seed=42,\n",
    "#     regression_or_classification=\"regression\",\n",
    "#     n_optuna_trials=2,\n",
    "#     device=\"cuda\",\n",
    "#     save_dir = \"/home/nikita/Code/zephyrox/pytorch_based/SWIM/save/\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- models:::: End2End Ridge RidgeCV XGBoostRegressor GradientRFBoost GradientRFBoostID GreedyRFBoostDense GreedyRFBoostDiag GreedyRFBoostScalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models End2End --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cuda --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models Ridge RidgeCV --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cuda --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models XGBoostRegressor --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cpu --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models GradientRFBoost --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cuda --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models GradientRFBoostID --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cuda --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models GreedyRFBoostDense --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cuda --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models GreedyRFBoostDiag --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cuda --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python regression_param_specs.py --models GreedyRFBoostScalar --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLRegression/ --n_optuna_trials 1 --device cuda --k_folds 2 --cv_seed 42 --save_experiments_individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join json results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic.v1.utils import deep_update\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "def custom_deep_update(original, update):\n",
    "    for key, value in update.items():\n",
    "        if isinstance(value, dict) and key in original:\n",
    "            custom_deep_update(original[key], value)\n",
    "        else:\n",
    "            original[key] = value\n",
    "\n",
    "\n",
    "\n",
    "def get_joined_results_json(\n",
    "        models = [\"End2End\", \"Ridge\", \"RidgeCV\", \"XGBoostRegressor\", \n",
    "                  \"GradientRFBoost\", \"GradientRFBoostID\", \n",
    "                  \"GreedyRFBoostDense\", \"GreedyRFBoostDiag\", \"GreedyRFBoostScalar\"],\n",
    "        save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLRegression/\",\n",
    "        ):\n",
    "    results_json = {}\n",
    "    for model in models:\n",
    "        path = os.path.join(save_dir, f\"regression_{model}.json\")\n",
    "        res = read_json(path)\n",
    "        if results_json == {}:\n",
    "            results_json = res\n",
    "        else:\n",
    "            custom_deep_update(results_json, res)\n",
    "    return results_json\n",
    "\n",
    "\n",
    "\n",
    "def join_jsons_into_array(\n",
    "        results_json,\n",
    "        ):\n",
    "    results = []\n",
    "    for dataset, dataset_results in results_json.items():\n",
    "        res = []\n",
    "        for model_name, model_results in dataset_results.items():\n",
    "            model_res = np.stack([model_results[\"score_train\"], model_results[\"score_test\"], model_results[\"t_fit\"], model_results[\"t_inference\"]])\n",
    "            res.append(model_res)\n",
    "        results.append(res)\n",
    "    return np.stack(results) # (n_datasets, n_models, 4, n_folds)\n",
    "\n",
    "\n",
    "\n",
    "def results_to_df(\n",
    "        models = [\"End2End\", \"Ridge\", \"RidgeCV\", \"XGBoostRegressor\", \n",
    "                  \"GradientRFBoost\", \"GradientRFBoostID\", \n",
    "                  \"GreedyRFBoostDense\", \"GreedyRFBoostDiag\", \"GreedyRFBoostScalar\"],\n",
    "        save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLRegression/\",\n",
    "        ):\n",
    "    # Load and join the JSON data\n",
    "    results_json = get_joined_results_json(models, save_dir)\n",
    "    results = join_jsons_into_array(results_json) # (n_datasets, n_models, 4, n_folds)\n",
    "    #TODO for now just average. later, add stds too\n",
    "    results = np.mean(results, axis=-1)\n",
    "    \n",
    "    # Extract dataset names and prepare metrics\n",
    "    datasets = list(results_json.keys())\n",
    "    models = list(results_json[datasets[0]].keys())\n",
    "    metrics = [\"score_train\", \"score_test\", \"t_fit\", \"t_inference\"]\n",
    "    \n",
    "    # Create a dictionary to hold metric-specific DataFrames\n",
    "    metric_dfs = {metric: pd.DataFrame(index=datasets, columns=models) for metric in metrics}\n",
    "    \n",
    "    # Populate the DataFrames for each metric\n",
    "    for dataset_idx, dataset in enumerate(datasets):\n",
    "        for model_idx, model in enumerate(models):\n",
    "            for metric_idx, metric in enumerate(metrics):\n",
    "                # Average across folds for each metric\n",
    "                metric_dfs[metric].loc[dataset, model] = results[dataset_idx, model_idx, metric_idx]\n",
    "    \n",
    "    return metric_dfs  # Return a dictionary of metric-specific DataFrames\n",
    "\n",
    "\n",
    "df = results_to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientRFBoostID      0.433133\n",
       "GradientRFBoost        0.438567\n",
       "End2End                0.450735\n",
       "XGBoostRegressor       0.459009\n",
       "GreedyRFBoostDiag      0.506386\n",
       "GreedyRFBoostDense     0.508602\n",
       "GreedyRFBoostScalar    0.557621\n",
       "RidgeCV                0.567655\n",
       "Ridge                  0.582112\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"score_test\"].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBoostRegressor       0.193177\n",
       "End2End                0.368294\n",
       "GradientRFBoostID      0.394319\n",
       "GradientRFBoost        0.394922\n",
       "GreedyRFBoostDense     0.461875\n",
       "GreedyRFBoostDiag       0.47948\n",
       "GreedyRFBoostScalar     0.54309\n",
       "RidgeCV                0.555603\n",
       "Ridge                  0.568748\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"score_train\"].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientRFBoostID      2.750\n",
       "GradientRFBoost        2.950\n",
       "XGBoostRegressor       3.700\n",
       "End2End                4.150\n",
       "GreedyRFBoostDiag      4.650\n",
       "GreedyRFBoostDense     5.100\n",
       "GreedyRFBoostScalar    6.300\n",
       "RidgeCV                7.475\n",
       "Ridge                  7.925\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"score_test\"].rank(axis=1).mean().sort_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
