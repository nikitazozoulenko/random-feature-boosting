{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMLBmini experiments\n",
    "\n",
    "This notebook runs the PMLBmini experiments, and compares RANDOM FEATURE BOOSTING and END2END to the saved PMLBmini models\n",
    "\n",
    "NOTE that we assume tabmini is installed in the cwd https://github.com/RicardoKnauer/TabMini \n",
    "\n",
    "Should take no more than 30 minutes to run this notebook, ie run all models and datasets sequentially on a single CPU core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, tensor\n",
    "import pandas as pd\n",
    "import tabmini\n",
    "import aeon\n",
    "from aeon.visualisation import plot_critical_difference, plot_significance\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "from models.gridsearch_wrapper import SKLearnWrapper\n",
    "from models.random_feature_representation_boosting import GradientRFRBoostClassifier\n",
    "from models.end2end import End2EndMLPResNet\n",
    "from PMLBmini import test_on_PMLBmini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#####      Equal/Random Guessing        ######\n",
    "##############################################\n",
    "\n",
    "\n",
    "class EqualGuessing(BaseEstimator, ClassifierMixin):\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Guess probabilty 0.5 for each class\"\"\"\n",
    "        # Guess [0.5, 0.5]\n",
    "        return np.ones((X.shape[0], 2)) * 0.5\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        # Get the probabilities from predict_proba\n",
    "        proba = self.predict_proba(X)\n",
    "        # Calculate the log of ratios for binary classification\n",
    "        decision = np.log((proba[:, 1] + 1e-10) / (proba[:, 0] + 1e-10))\n",
    "        return decision\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/home/nikita/Code/random-feature-boosting/results/PMLBmini/\"\n",
    "\n",
    "# train_guessing_and_xgboost, test_guessing_and_xgboost = test_on_PMLBmini(\n",
    "#     EqualGuessing(),\n",
    "#     'EqualGuessing',\n",
    "#     [i for i in range(44)],\n",
    "#     save_dir, \n",
    "#     other_saved_methods={\"XGBoost\"},\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python PMLBmini.py \\\n",
    "#     --models E2E_MLP_ResNet \\\n",
    "#     --dataset_indices 0 \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/results/PMLBmini/ \\\n",
    "#     --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python PMLBmini.py \\\n",
    "#     --models \"Logistic(ours)\" \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/results/PMLBmini/ \\\n",
    "#     --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO wrong results for both built in rocauc and neglogloss\n",
    "# for i in range(44):\n",
    "#     !python PMLBmini.py \\\n",
    "#         --models \"Logistic(ours)\" \\\n",
    "#         --dataset_indices {i} \\\n",
    "#         --save_dir /home/nikita/Code/random-feature-boosting/results/PMLBmini/ \\\n",
    "#         --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python PMLBmini.py \\\n",
    "#     --models GRFRBoost_featSWIM_upiid_linesearchTrue_freezeFalse \\\n",
    "#     --dataset_indices 0 \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/results/PMLBmini/ \\\n",
    "#     --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AutoPrognosis</th>\n",
       "      <th>AutoGluon</th>\n",
       "      <th>TabPFN</th>\n",
       "      <th>Logistic regression</th>\n",
       "      <th>HyperFast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>parity5</th>\n",
       "      <td>0.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_fraud</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_aids</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_bankruptcy</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_japansolvent</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labor</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_asbestos</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lupus</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postoperative_patient_data</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_cyyoung9302</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_cyyoung8092</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_creditscore</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appendicitis</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>molecular_biology_promoters</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_boxing1</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mux6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_boxing2</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hepatitis</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corral</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glass2</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backache</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prnn_crabs</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonar</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biomed</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prnn_synth</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_lawsuit</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spect</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_statlog</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_h</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hungarian</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleve</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_c</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haberman</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spectf</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colic</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horse_colic</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house_votes_84</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saheart</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irish</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             AutoPrognosis  AutoGluon  TabPFN  \\\n",
       "parity5                               0.27       1.00    0.02   \n",
       "analcatdata_fraud                     0.86       0.80    0.79   \n",
       "analcatdata_aids                      0.73       0.77    0.63   \n",
       "analcatdata_bankruptcy                0.98       0.98    0.96   \n",
       "analcatdata_japansolvent              0.85       0.88    0.91   \n",
       "labor                                 0.88       0.94    0.99   \n",
       "analcatdata_asbestos                  0.87       0.84    0.85   \n",
       "lupus                                 0.84       0.79    0.82   \n",
       "postoperative_patient_data            0.49       0.55    0.44   \n",
       "analcatdata_cyyoung9302               0.89       0.85    0.87   \n",
       "analcatdata_cyyoung8092               0.73       0.90    0.85   \n",
       "analcatdata_creditscore               1.00       0.99    1.00   \n",
       "appendicitis                          0.78       0.84    0.82   \n",
       "molecular_biology_promoters           0.88       0.93    0.88   \n",
       "analcatdata_boxing1                   0.89       0.89    0.76   \n",
       "mux6                                  1.00       1.00    1.00   \n",
       "analcatdata_boxing2                   0.82       0.78    0.71   \n",
       "hepatitis                             0.85       0.82    0.85   \n",
       "corral                                1.00       1.00    1.00   \n",
       "glass2                                0.89       0.91    0.89   \n",
       "backache                              0.60       0.72    0.75   \n",
       "prnn_crabs                            1.00       1.00    1.00   \n",
       "sonar                                 0.88       0.93    0.92   \n",
       "biomed                                1.00       0.96    0.95   \n",
       "prnn_synth                            0.94       0.95    0.95   \n",
       "analcatdata_lawsuit                   0.99       0.99    1.00   \n",
       "spect                                 0.84       0.82    0.83   \n",
       "heart_statlog                         0.91       0.89    0.90   \n",
       "breast_cancer                         0.69       0.69    0.73   \n",
       "heart_h                               0.87       0.89    0.88   \n",
       "hungarian                             0.86       0.86    0.86   \n",
       "cleve                                 0.90       0.89    0.89   \n",
       "heart_c                               0.91       0.91    0.91   \n",
       "haberman                              0.70       0.71    0.72   \n",
       "bupa                                  0.66       0.64    0.68   \n",
       "spectf                                0.91       0.94    0.93   \n",
       "ionosphere                            0.97       0.98    0.98   \n",
       "colic                                 0.87       0.86    0.87   \n",
       "horse_colic                           0.88       0.85    0.84   \n",
       "house_votes_84                        0.99       0.99    0.99   \n",
       "vote                                  1.00       0.99    1.00   \n",
       "saheart                               0.77       0.76    0.77   \n",
       "clean1                                0.93       1.00    0.99   \n",
       "irish                                 1.00       1.00    1.00   \n",
       "\n",
       "                             Logistic regression  HyperFast  \n",
       "parity5                                     0.17       0.02  \n",
       "analcatdata_fraud                           0.77       0.73  \n",
       "analcatdata_aids                            0.61       0.53  \n",
       "analcatdata_bankruptcy                      0.97       0.88  \n",
       "analcatdata_japansolvent                    0.85       0.91  \n",
       "labor                                       0.97       0.98  \n",
       "analcatdata_asbestos                        0.86       0.87  \n",
       "lupus                                       0.85       0.79  \n",
       "postoperative_patient_data                  0.38       0.34  \n",
       "analcatdata_cyyoung9302                     0.87       0.84  \n",
       "analcatdata_cyyoung8092                     0.79       0.84  \n",
       "analcatdata_creditscore                     0.94       0.87  \n",
       "appendicitis                                0.84       0.87  \n",
       "molecular_biology_promoters                 0.88       0.89  \n",
       "analcatdata_boxing1                         0.67       0.67  \n",
       "mux6                                        0.70       0.95  \n",
       "analcatdata_boxing2                         0.68       0.70  \n",
       "hepatitis                                   0.84       0.83  \n",
       "corral                                      0.96       1.00  \n",
       "glass2                                      0.72       0.79  \n",
       "backache                                    0.72       0.78  \n",
       "prnn_crabs                                  1.00       0.81  \n",
       "sonar                                       0.85       0.89  \n",
       "biomed                                      0.94       0.93  \n",
       "prnn_synth                                  0.94       0.94  \n",
       "analcatdata_lawsuit                         1.00       0.98  \n",
       "spect                                       0.82       0.83  \n",
       "heart_statlog                               0.89       0.89  \n",
       "breast_cancer                               0.70       0.69  \n",
       "heart_h                                     0.86       0.85  \n",
       "hungarian                                   0.85       0.84  \n",
       "cleve                                       0.88       0.88  \n",
       "heart_c                                     0.91       0.89  \n",
       "haberman                                    0.66       0.58  \n",
       "bupa                                        0.67       0.66  \n",
       "spectf                                      0.88       0.87  \n",
       "ionosphere                                  0.90       0.97  \n",
       "colic                                       0.86       0.86  \n",
       "horse_colic                                 0.82       0.83  \n",
       "house_votes_84                              0.99       0.98  \n",
       "vote                                        0.99       0.99  \n",
       "saheart                                     0.77       0.76  \n",
       "clean1                                      1.00       0.96  \n",
       "irish                                       0.83       0.97  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV and set the index\n",
    "saved_results = pd.read_csv('https://raw.githubusercontent.com/RicardoKnauer/TabMini/master/plotting/results/test_scores_wide_3600.csv', delimiter=\";\", index_col=0)\n",
    "saved_results.index.name = None\n",
    "saved_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # join all the models\n",
    "# import itertools\n",
    "# model_names = [\"E2E_MLP_ResNet\", \"RFNN\", \"RFNN_iid\", \"Logistic(ours)\"]\n",
    "# for feat, up, linesearch, freeze, relu in itertools.product([\"SWIM\", \"iid\"], [\"identity\", \"SWIM\", \"iid\"], [True, False], [True, False], [\"\", \"_relu\"]):\n",
    "#     name = f\"GRFRBoost_feat{feat}_up{up}_linesearch{linesearch}_freeze{freeze}{relu}\"\n",
    "#     model_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all the models\n",
    "import itertools\n",
    "model_names = [\"E2E_MLP_ResNet\", \"RFNN\", #\"RFNN_relu\",\n",
    "               \"GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeFalse\",\n",
    "               #\"GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeFalse_relu\",\n",
    "               #\"GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_relu\",\n",
    "               ]\n",
    "# for feat, up, linesearch, freeze, relu in itertools.product([\"SWIM\"], [\"SWIM\"], [False], [False], [\"_relu\"]):\n",
    "#     name = f\"GRFRBoost_feat{feat}_up{up}_linesearch{linesearch}_freeze{freeze}{relu}\"\n",
    "#     model_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"SWIM\"] # feat\n",
    "[\"SWIM\", \"iid\", \"identity\"] # up\n",
    "[False, True] # linesearch\n",
    "[False, True] # freeze\n",
    "[\"\", \"relu\"] # relu\n",
    "[\"auc\", \"crossentropy\", \"acc\"] # scoring\n",
    "[\"ridge\", \"ridgecv\"] # ghat module        \n",
    "2*3*2*2*2*3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/nikita/Code/random-feature-boosting/results/PMLBmini/E2E_MLP_ResNet/test_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m combined_results \u001b[38;5;241m=\u001b[39m saved_results\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_names:\n\u001b[0;32m----> 3\u001b[0m     results_one_model \u001b[38;5;241m=\u001b[39m [pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m44\u001b[39m)]\n\u001b[1;32m      5\u001b[0m     df_one_model \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(results_one_model, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m     combined_results \u001b[38;5;241m=\u001b[39m combined_results\u001b[38;5;241m.\u001b[39mjoin(df_one_model)\n",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m combined_results \u001b[38;5;241m=\u001b[39m saved_results\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_names:\n\u001b[0;32m----> 3\u001b[0m     results_one_model \u001b[38;5;241m=\u001b[39m [\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msave_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/test_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m44\u001b[39m)]\n\u001b[1;32m      5\u001b[0m     df_one_model \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(results_one_model, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m     combined_results \u001b[38;5;241m=\u001b[39m combined_results\u001b[38;5;241m.\u001b[39mjoin(df_one_model)\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/nikita/Code/random-feature-boosting/results/PMLBmini/E2E_MLP_ResNet/test_0.csv'"
     ]
    }
   ],
   "source": [
    "combined_results = saved_results.copy()\n",
    "for model_name in model_names:\n",
    "    results_one_model = [pd.read_csv(f\"{save_dir}{model_name}/test_{i}.csv\", index_col=0)\n",
    "                         for i in range(44)]\n",
    "    df_one_model = pd.concat(results_one_model, axis=0)\n",
    "    combined_results = combined_results.join(df_one_model)\n",
    "combined_results = combined_results.round(2)\n",
    "combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_columns = combined_results.columns[combined_results.isna().any()].tolist()\n",
    "print(nan_columns)\n",
    "combined_results[nan_columns]\n",
    "combined_results = combined_results.drop(columns=nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results.query(\"RFNN > GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeFalse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the plot\n",
    "plot = plot_critical_difference(combined_results.values,\n",
    "                                combined_results.columns.tolist(), \n",
    "                                alpha=0.10, \n",
    "                                lower_better=False)\n",
    "\n",
    "# Retrieve the figure and axes from the plot\n",
    "fig = plot[0].figure\n",
    "ax = plot[0]\n",
    "\n",
    "# Adjust figure size\n",
    "fig.set_size_inches(6, 3)\n",
    "\n",
    "# Adjust layout\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the figures\n",
    "fig.savefig(f\"{save_dir}PMLBmini_critical_difference.eps\", bbox_inches='tight')\n",
    "fig.savefig(f\"{save_dir}PMLBmini_critical_difference.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_latex_table(df):\n",
    "    table = \"\"\"\n",
    "\\\\begin{table}[t]\n",
    "\\\\caption{Test accuracies on the concentric circles task.}\n",
    "\\\\label{tab:concentric-circles}\n",
    "\\\\vskip 0.15in\n",
    "\\\\begin{center}\n",
    "\\\\begin{small}\n",
    "\\\\begin{sc}\n",
    "\\\\begin{tabular}{lcc}\n",
    "\\\\toprule\n",
    "Model & Mean Acc & Std Dev \\\\\\\\\n",
    "\\\\midrule\n",
    "\"\"\"\n",
    "    for model_name in df.columns:\n",
    "        accs = df[model_name]\n",
    "        mean_acc = np.mean(accs)\n",
    "        std_acc = np.std(accs)\n",
    "        table += f\"{model_name} & {mean_acc:.4f} & {std_acc:.4f} \\\\\\\\\\n\"\n",
    "    \n",
    "    table += \"\"\"\n",
    "\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "\\\\end{sc}\n",
    "\\\\end{small}\n",
    "\\\\end{center}\n",
    "\\\\vskip -0.1in\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "    return table\n",
    "\n",
    "# Example usage\n",
    "# Assuming `results_df` is your pandas DataFrame\n",
    "latex_table = create_latex_table(combined_results)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiment on single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, tensor\n",
    "import pandas as pd\n",
    "import tabmini\n",
    "import aeon\n",
    "from aeon.visualisation import plot_critical_difference, plot_significance\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "from models.base import LogisticRegression\n",
    "from models.gridsearch_wrapper import SKLearnWrapper\n",
    "from models.random_feature_representation_boosting import GradientRFRBoostClassifier\n",
    "from models.end2end import End2EndMLPResNet\n",
    "\n",
    "class Config:\n",
    "    save_dir = Path.cwd() / \"results\" / \"PMLBmini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment on a single dataset\n",
    "\n",
    "#download dataset, cache it\n",
    "dataset_save_path = Config.save_dir / 'PMLBmini_dataset.pkl'\n",
    "if not os.path.exists(dataset_save_path):\n",
    "    print(\"Dataset not found, downloading\")\n",
    "    dataset = tabmini.load_dataset(reduced=False)\n",
    "    os.makedirs(Config.save_dir, exist_ok=True)\n",
    "    with open(dataset_save_path, 'wb') as f:\n",
    "        pickle.dump(dataset, f)\n",
    "else:\n",
    "    print(\"Dataset found, loading\")\n",
    "    with open(dataset_save_path, 'rb') as f:\n",
    "        dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 10: parity5\n",
    "X, y = dataset[\"analcatdata_fraud\"]\n",
    "# X, y = dataset[\"parity5\"]\n",
    "scaler = MinMaxScaler()\n",
    "#scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = torch.tensor(X).float()\n",
    "y = torch.tensor(y.values)[..., None].float()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression(\n",
    "#     n_classes=2,\n",
    "#     l2_lambda=0.0001,\n",
    "#     max_iter = 300,\n",
    "# )\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = GradientRFRBoostClassifier(\n",
    "    in_dim=X.shape[1],\n",
    "    n_classes=2,\n",
    "    l2_cls=1,\n",
    "    l2_ghat=0.0001,\n",
    "    n_layers=2,\n",
    "    randfeat_xt_dim=512,\n",
    "    randfeat_x0_dim=512,\n",
    "    hidden_dim=512,\n",
    "    upscale_type=\"SWIM\",\n",
    "    feature_type=\"SWIM\",\n",
    "    use_batchnorm=False,\n",
    "    boost_lr=10,\n",
    "    activation=\"tanh\",\n",
    "    do_linesearch=False,\n",
    "    freeze_top_at_t=2,\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "logits = model(X_test)\n",
    "print(\"logits\", logits)\n",
    "probs = nn.functional.sigmoid(logits)\n",
    "# print(\"out and y\", torch.cat([logits, y_test], dim=1))\n",
    "# print(\"binary class pred and y\", torch.cat([probs > 0.5, y_test], dim=1))\n",
    "auc = roc_auc_score(y_test.numpy(), probs.detach().numpy())\n",
    "print(\"test AUC:\", auc)\n",
    "print(\"test accuracy:\", (probs > 0.5).eq(y_test).float().mean().item())\n",
    "print(\"test cross-entropy:\", nn.functional.binary_cross_entropy_with_logits(logits, y_test).item())\n",
    "\n",
    "#train\n",
    "model.eval()\n",
    "logits = model(X_train)\n",
    "probs = nn.functional.sigmoid(logits)\n",
    "auc = roc_auc_score(y_train.numpy(), probs.detach().numpy())\n",
    "print(\"train AUC:\", auc)\n",
    "print(\"train accuracy:\", (probs > 0.5).eq(y_train).float().mean().item())\n",
    "print(\"train cross-entropy:\", nn.functional.binary_cross_entropy_with_logits(logits, y_train).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO cross entropy loss\n",
    "# TODO ridgeCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bugfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 10: parity5\n",
    "X, y = dataset[\"analcatdata_fraud\"]\n",
    "# X, y = dataset[\"parity5\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PMLBmini import WrapperGridSearch\n",
    "\n",
    "model = WrapperGridSearch(\n",
    "    param_grid={\n",
    "        \"modelClass\": [GradientRFRBoostClassifier],\n",
    "        \"l2_cls\": [1, 0.1, 0.01],\n",
    "        \"l2_ghat\": [0.0001],\n",
    "        \"n_layers\": [2],\n",
    "        \"randfeat_xt_dim\": [512],\n",
    "        \"randfeat_x0_dim\": [512],\n",
    "        \"hidden_dim\": [512],\n",
    "        \"upscale_type\": [\"SWIM\"],\n",
    "        \"feature_type\": [\"SWIM\"],\n",
    "        \"use_batchnorm\": [False],\n",
    "        \"boost_lr\": [10],\n",
    "        \"activation\": [\"tanh\"],\n",
    "        \"do_linesearch\": [False],\n",
    "        \"freeze_top_at_t\": [2],\n",
    "    },\n",
    "    verbose=3,\n",
    "    scaler=MinMaxScaler(),\n",
    "    seed=42,\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "pred_test = model.predict_proba(X_test)\n",
    "pred_train = model.predict_proba(X_train)\n",
    "print(\"test AUC:\", roc_auc_score(y_test, pred_test[:, 1]))\n",
    "print(\"train AUC:\", roc_auc_score(y_train, pred_train[:, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
