{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMLBmini experiments\n",
    "\n",
    "This notebook runs the PMLBmini experiments, and compares RANDOM FEATURE BOOSTING and END2END to the saved PMLBmini models\n",
    "\n",
    "NOTE that we assume tabmini is installed in the cwd https://github.com/RicardoKnauer/TabMini \n",
    "\n",
    "Should take no more than 30 minutes to run this notebook, ie run all models and datasets sequentially on a single CPU core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, tensor\n",
    "import pandas as pd\n",
    "import tabmini\n",
    "import aeon\n",
    "from aeon.visualisation import plot_critical_difference, plot_significance\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "from models.gridsearch_wrapper import SKLearnWrapper\n",
    "from models.random_feature_representation_boosting import GradientRFRBoostClassifier\n",
    "from models.end2end import End2EndMLPResNet\n",
    "from PMLBmini import test_on_PMLBmini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#####      Equal/Random Guessing        ######\n",
    "##############################################\n",
    "\n",
    "\n",
    "class EqualGuessing(BaseEstimator, ClassifierMixin):\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Guess probabilty 0.5 for each class\"\"\"\n",
    "        # Guess [0.5, 0.5]\n",
    "        return np.ones((X.shape[0], 2)) * 0.5\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        # Get the probabilities from predict_proba\n",
    "        proba = self.predict_proba(X)\n",
    "        # Calculate the log of ratios for binary classification\n",
    "        decision = np.log((proba[:, 1] + 1e-10) / (proba[:, 0] + 1e-10))\n",
    "        return decision\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dir = \"/home/nikita/Code/random-feature-boosting/results/PMLBmini_rocauc/\"\n",
    "# save_dir = \"/home/nikita/Code/random-feature-boosting/results/PMLBmini_ghat_cv3accidentally/\"\n",
    "save_dir = \"/home/nikita/Code/random-feature-boosting/results/PMLBmini/\"\n",
    "            \n",
    "# train_guessing_and_xgboost, test_guessing_and_xgboost = test_on_PMLBmini(\n",
    "#     EqualGuessing(),\n",
    "#     'EqualGuessing',\n",
    "#     [i for i in range(44)],\n",
    "#     save_dir, \n",
    "#     other_saved_methods={\"XGBoost\"},\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python PMLBmini.py \\\n",
    "#     --models E2E_MLP_ResNet \\\n",
    "#     --dataset_indices 0 \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/results/PMLBmini/ \\\n",
    "#     --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python PMLBmini.py \\\n",
    "#     --models \"Logistic(ours)\" \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/results/PMLBmini/ \\\n",
    "#     --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO wrong results for both built in rocauc and neglogloss\n",
    "# for i in range(44):\n",
    "#     !python PMLBmini.py \\\n",
    "#         --models \"Logistic(ours)\" \\\n",
    "#         --dataset_indices {i} \\\n",
    "#         --save_dir /home/nikita/Code/random-feature-boosting/results/PMLBmini/ \\\n",
    "#         --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python PMLBmini.py \\\n",
    "#     --models GRFRBoost_featSWIM_upiid_linesearchTrue_freezeFalse \\\n",
    "#     --dataset_indices 0 \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/results/PMLBmini/ \\\n",
    "#     --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AutoPrognosis</th>\n",
       "      <th>AutoGluon</th>\n",
       "      <th>TabPFN</th>\n",
       "      <th>Logistic regression</th>\n",
       "      <th>HyperFast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>parity5</th>\n",
       "      <td>0.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_fraud</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_aids</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_bankruptcy</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_japansolvent</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labor</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_asbestos</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lupus</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postoperative_patient_data</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_cyyoung9302</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_cyyoung8092</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_creditscore</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appendicitis</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>molecular_biology_promoters</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_boxing1</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mux6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_boxing2</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hepatitis</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corral</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glass2</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backache</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prnn_crabs</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonar</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biomed</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prnn_synth</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_lawsuit</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spect</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_statlog</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_h</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hungarian</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleve</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_c</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haberman</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spectf</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colic</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horse_colic</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house_votes_84</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saheart</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irish</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             AutoPrognosis  AutoGluon  TabPFN  \\\n",
       "parity5                               0.27       1.00    0.02   \n",
       "analcatdata_fraud                     0.86       0.80    0.79   \n",
       "analcatdata_aids                      0.73       0.77    0.63   \n",
       "analcatdata_bankruptcy                0.98       0.98    0.96   \n",
       "analcatdata_japansolvent              0.85       0.88    0.91   \n",
       "labor                                 0.88       0.94    0.99   \n",
       "analcatdata_asbestos                  0.87       0.84    0.85   \n",
       "lupus                                 0.84       0.79    0.82   \n",
       "postoperative_patient_data            0.49       0.55    0.44   \n",
       "analcatdata_cyyoung9302               0.89       0.85    0.87   \n",
       "analcatdata_cyyoung8092               0.73       0.90    0.85   \n",
       "analcatdata_creditscore               1.00       0.99    1.00   \n",
       "appendicitis                          0.78       0.84    0.82   \n",
       "molecular_biology_promoters           0.88       0.93    0.88   \n",
       "analcatdata_boxing1                   0.89       0.89    0.76   \n",
       "mux6                                  1.00       1.00    1.00   \n",
       "analcatdata_boxing2                   0.82       0.78    0.71   \n",
       "hepatitis                             0.85       0.82    0.85   \n",
       "corral                                1.00       1.00    1.00   \n",
       "glass2                                0.89       0.91    0.89   \n",
       "backache                              0.60       0.72    0.75   \n",
       "prnn_crabs                            1.00       1.00    1.00   \n",
       "sonar                                 0.88       0.93    0.92   \n",
       "biomed                                1.00       0.96    0.95   \n",
       "prnn_synth                            0.94       0.95    0.95   \n",
       "analcatdata_lawsuit                   0.99       0.99    1.00   \n",
       "spect                                 0.84       0.82    0.83   \n",
       "heart_statlog                         0.91       0.89    0.90   \n",
       "breast_cancer                         0.69       0.69    0.73   \n",
       "heart_h                               0.87       0.89    0.88   \n",
       "hungarian                             0.86       0.86    0.86   \n",
       "cleve                                 0.90       0.89    0.89   \n",
       "heart_c                               0.91       0.91    0.91   \n",
       "haberman                              0.70       0.71    0.72   \n",
       "bupa                                  0.66       0.64    0.68   \n",
       "spectf                                0.91       0.94    0.93   \n",
       "ionosphere                            0.97       0.98    0.98   \n",
       "colic                                 0.87       0.86    0.87   \n",
       "horse_colic                           0.88       0.85    0.84   \n",
       "house_votes_84                        0.99       0.99    0.99   \n",
       "vote                                  1.00       0.99    1.00   \n",
       "saheart                               0.77       0.76    0.77   \n",
       "clean1                                0.93       1.00    0.99   \n",
       "irish                                 1.00       1.00    1.00   \n",
       "\n",
       "                             Logistic regression  HyperFast  \n",
       "parity5                                     0.17       0.02  \n",
       "analcatdata_fraud                           0.77       0.73  \n",
       "analcatdata_aids                            0.61       0.53  \n",
       "analcatdata_bankruptcy                      0.97       0.88  \n",
       "analcatdata_japansolvent                    0.85       0.91  \n",
       "labor                                       0.97       0.98  \n",
       "analcatdata_asbestos                        0.86       0.87  \n",
       "lupus                                       0.85       0.79  \n",
       "postoperative_patient_data                  0.38       0.34  \n",
       "analcatdata_cyyoung9302                     0.87       0.84  \n",
       "analcatdata_cyyoung8092                     0.79       0.84  \n",
       "analcatdata_creditscore                     0.94       0.87  \n",
       "appendicitis                                0.84       0.87  \n",
       "molecular_biology_promoters                 0.88       0.89  \n",
       "analcatdata_boxing1                         0.67       0.67  \n",
       "mux6                                        0.70       0.95  \n",
       "analcatdata_boxing2                         0.68       0.70  \n",
       "hepatitis                                   0.84       0.83  \n",
       "corral                                      0.96       1.00  \n",
       "glass2                                      0.72       0.79  \n",
       "backache                                    0.72       0.78  \n",
       "prnn_crabs                                  1.00       0.81  \n",
       "sonar                                       0.85       0.89  \n",
       "biomed                                      0.94       0.93  \n",
       "prnn_synth                                  0.94       0.94  \n",
       "analcatdata_lawsuit                         1.00       0.98  \n",
       "spect                                       0.82       0.83  \n",
       "heart_statlog                               0.89       0.89  \n",
       "breast_cancer                               0.70       0.69  \n",
       "heart_h                                     0.86       0.85  \n",
       "hungarian                                   0.85       0.84  \n",
       "cleve                                       0.88       0.88  \n",
       "heart_c                                     0.91       0.89  \n",
       "haberman                                    0.66       0.58  \n",
       "bupa                                        0.67       0.66  \n",
       "spectf                                      0.88       0.87  \n",
       "ionosphere                                  0.90       0.97  \n",
       "colic                                       0.86       0.86  \n",
       "horse_colic                                 0.82       0.83  \n",
       "house_votes_84                              0.99       0.98  \n",
       "vote                                        0.99       0.99  \n",
       "saheart                                     0.77       0.76  \n",
       "clean1                                      1.00       0.96  \n",
       "irish                                       0.83       0.97  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV and set the index\n",
    "saved_results = pd.read_csv('https://raw.githubusercontent.com/RicardoKnauer/TabMini/master/plotting/results/test_scores_wide_3600.csv', delimiter=\";\", index_col=0)\n",
    "saved_results.index.name = None\n",
    "saved_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all the models\n",
    "import itertools\n",
    "model_names = []\n",
    "for scoring in [\"crossentropy\", \"auc\"]:#[\"auc\", \"crossentropy\"]:\n",
    "    model_names.append(f\"E2E_MLP_ResNet_{scoring}\")\n",
    "    model_names.append(f\"RFNN_{scoring}\")\n",
    "    for feat in [\"SWIM\"]:\n",
    "        for up in [\"identity\", \"SWIM\", \"iid\"]:\n",
    "            for linesearch in [True, False]:\n",
    "                for freeze in [True, False]:\n",
    "                    for activation in [\"tanh\", \"relu\"]:\n",
    "                        name = f\"GRFRBoost_feat{feat}_up{up}_linesearch{linesearch}_freeze{freeze}_{activation}_{scoring}\"\n",
    "                        model_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all the models\n",
    "import itertools\n",
    "model_names = []\n",
    "for scoring in [\"crossentropy\"]: # [\"auc\", \"acc\", \"crossentropy\"]:\n",
    "    model_names.append(f\"E2E_MLP_ResNet_{scoring}\")\n",
    "    model_names.append(f\"RFNN_{scoring}\")\n",
    "    # for feat in [\"SWIM\"]:\n",
    "    #     for up in [\"identity\", \"SWIM\", \"iid\"]:\n",
    "    #         for linesearch in [True, False]:\n",
    "    #             for freeze in [False]:\n",
    "    #                 for activation in [\"tanh\", \"relu\"]:\n",
    "    #                         name = f\"GRFRBoost_feat{feat}_up{up}_linesearch{linesearch}_freeze{freeze}_{activation}_{scoring}\"\n",
    "    #                         model_names.append(name)\n",
    "# model_names.append(\"GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeFalse_tanh_crossentropy\")\n",
    "model_names.append(\"GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_tanh_crossentropy\")\n",
    "model_names.append(\"GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_relu_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # join all the models\n",
    "# import itertools\n",
    "# model_names = [\"E2E_MLP_ResNet\", \"RFNN\", #\"RFNN_relu\",\n",
    "#                 \"GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_relu\",  \n",
    "#                 #\"GRFRBoost_featSWIM_upiid_linesearchFalse_freezeFalse\",    \n",
    "#                 #\"GRFRBoost_featSWIM_upidentity_linesearchFalse_freezeFalse_relu\", \n",
    "#                 #\"GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeFalse\",           \n",
    "#                 #\"GRFRBoost_featSWIM_upiid_linesearchFalse_freezeFalse_relu\",  \n",
    "#                 #\"GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeTrue\",\n",
    "#                ]\n",
    "# # for feat, up, linesearch, freeze, relu in itertools.product([\"SWIM\"], [\"SWIM\"], [False], [False], [\"_relu\"]):\n",
    "# #     name = f\"GRFRBoost_feat{feat}_up{up}_linesearch{linesearch}_freeze{freeze}{relu}\"\n",
    "# #     model_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [\"SWIM\"] # feat\n",
    "# [\"SWIM\", \"iid\", \"identity\"] # up\n",
    "# [False, True] # linesearch\n",
    "# [False] # freeze\n",
    "# [\"\", \"relu\"] # relu\n",
    "# [\"auc\", \"crossentropy\", \"acc\"] # scoring\n",
    "# #[\"ridge\", \"ridgecv\"] # ghat module        \n",
    "# 1*3*2*1*2*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AutoPrognosis</th>\n",
       "      <th>AutoGluon</th>\n",
       "      <th>TabPFN</th>\n",
       "      <th>Logistic regression</th>\n",
       "      <th>HyperFast</th>\n",
       "      <th>E2E_MLP_ResNet_crossentropy</th>\n",
       "      <th>RFNN_crossentropy</th>\n",
       "      <th>GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_tanh_crossentropy</th>\n",
       "      <th>GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_relu_crossentropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>parity5</th>\n",
       "      <td>0.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_fraud</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_aids</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_bankruptcy</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_japansolvent</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labor</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_asbestos</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lupus</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postoperative_patient_data</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_cyyoung9302</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_cyyoung8092</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_creditscore</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appendicitis</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>molecular_biology_promoters</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_boxing1</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mux6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_boxing2</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hepatitis</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corral</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glass2</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backache</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prnn_crabs</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonar</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biomed</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prnn_synth</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_lawsuit</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spect</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_statlog</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_h</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hungarian</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleve</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_c</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haberman</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spectf</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colic</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horse_colic</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house_votes_84</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saheart</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irish</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             AutoPrognosis  AutoGluon  TabPFN  \\\n",
       "parity5                               0.27       1.00    0.02   \n",
       "analcatdata_fraud                     0.86       0.80    0.79   \n",
       "analcatdata_aids                      0.73       0.77    0.63   \n",
       "analcatdata_bankruptcy                0.98       0.98    0.96   \n",
       "analcatdata_japansolvent              0.85       0.88    0.91   \n",
       "labor                                 0.88       0.94    0.99   \n",
       "analcatdata_asbestos                  0.87       0.84    0.85   \n",
       "lupus                                 0.84       0.79    0.82   \n",
       "postoperative_patient_data            0.49       0.55    0.44   \n",
       "analcatdata_cyyoung9302               0.89       0.85    0.87   \n",
       "analcatdata_cyyoung8092               0.73       0.90    0.85   \n",
       "analcatdata_creditscore               1.00       0.99    1.00   \n",
       "appendicitis                          0.78       0.84    0.82   \n",
       "molecular_biology_promoters           0.88       0.93    0.88   \n",
       "analcatdata_boxing1                   0.89       0.89    0.76   \n",
       "mux6                                  1.00       1.00    1.00   \n",
       "analcatdata_boxing2                   0.82       0.78    0.71   \n",
       "hepatitis                             0.85       0.82    0.85   \n",
       "corral                                1.00       1.00    1.00   \n",
       "glass2                                0.89       0.91    0.89   \n",
       "backache                              0.60       0.72    0.75   \n",
       "prnn_crabs                            1.00       1.00    1.00   \n",
       "sonar                                 0.88       0.93    0.92   \n",
       "biomed                                1.00       0.96    0.95   \n",
       "prnn_synth                            0.94       0.95    0.95   \n",
       "analcatdata_lawsuit                   0.99       0.99    1.00   \n",
       "spect                                 0.84       0.82    0.83   \n",
       "heart_statlog                         0.91       0.89    0.90   \n",
       "breast_cancer                         0.69       0.69    0.73   \n",
       "heart_h                               0.87       0.89    0.88   \n",
       "hungarian                             0.86       0.86    0.86   \n",
       "cleve                                 0.90       0.89    0.89   \n",
       "heart_c                               0.91       0.91    0.91   \n",
       "haberman                              0.70       0.71    0.72   \n",
       "bupa                                  0.66       0.64    0.68   \n",
       "spectf                                0.91       0.94    0.93   \n",
       "ionosphere                            0.97       0.98    0.98   \n",
       "colic                                 0.87       0.86    0.87   \n",
       "horse_colic                           0.88       0.85    0.84   \n",
       "house_votes_84                        0.99       0.99    0.99   \n",
       "vote                                  1.00       0.99    1.00   \n",
       "saheart                               0.77       0.76    0.77   \n",
       "clean1                                0.93       1.00    0.99   \n",
       "irish                                 1.00       1.00    1.00   \n",
       "\n",
       "                             Logistic regression  HyperFast  \\\n",
       "parity5                                     0.17       0.02   \n",
       "analcatdata_fraud                           0.77       0.73   \n",
       "analcatdata_aids                            0.61       0.53   \n",
       "analcatdata_bankruptcy                      0.97       0.88   \n",
       "analcatdata_japansolvent                    0.85       0.91   \n",
       "labor                                       0.97       0.98   \n",
       "analcatdata_asbestos                        0.86       0.87   \n",
       "lupus                                       0.85       0.79   \n",
       "postoperative_patient_data                  0.38       0.34   \n",
       "analcatdata_cyyoung9302                     0.87       0.84   \n",
       "analcatdata_cyyoung8092                     0.79       0.84   \n",
       "analcatdata_creditscore                     0.94       0.87   \n",
       "appendicitis                                0.84       0.87   \n",
       "molecular_biology_promoters                 0.88       0.89   \n",
       "analcatdata_boxing1                         0.67       0.67   \n",
       "mux6                                        0.70       0.95   \n",
       "analcatdata_boxing2                         0.68       0.70   \n",
       "hepatitis                                   0.84       0.83   \n",
       "corral                                      0.96       1.00   \n",
       "glass2                                      0.72       0.79   \n",
       "backache                                    0.72       0.78   \n",
       "prnn_crabs                                  1.00       0.81   \n",
       "sonar                                       0.85       0.89   \n",
       "biomed                                      0.94       0.93   \n",
       "prnn_synth                                  0.94       0.94   \n",
       "analcatdata_lawsuit                         1.00       0.98   \n",
       "spect                                       0.82       0.83   \n",
       "heart_statlog                               0.89       0.89   \n",
       "breast_cancer                               0.70       0.69   \n",
       "heart_h                                     0.86       0.85   \n",
       "hungarian                                   0.85       0.84   \n",
       "cleve                                       0.88       0.88   \n",
       "heart_c                                     0.91       0.89   \n",
       "haberman                                    0.66       0.58   \n",
       "bupa                                        0.67       0.66   \n",
       "spectf                                      0.88       0.87   \n",
       "ionosphere                                  0.90       0.97   \n",
       "colic                                       0.86       0.86   \n",
       "horse_colic                                 0.82       0.83   \n",
       "house_votes_84                              0.99       0.98   \n",
       "vote                                        0.99       0.99   \n",
       "saheart                                     0.77       0.76   \n",
       "clean1                                      1.00       0.96   \n",
       "irish                                       0.83       0.97   \n",
       "\n",
       "                             E2E_MLP_ResNet_crossentropy  RFNN_crossentropy  \\\n",
       "parity5                                             0.48               0.19   \n",
       "analcatdata_fraud                                   0.64               0.80   \n",
       "analcatdata_aids                                    0.47               0.65   \n",
       "analcatdata_bankruptcy                              0.75               0.97   \n",
       "analcatdata_japansolvent                            0.53               0.84   \n",
       "labor                                               0.51               0.93   \n",
       "analcatdata_asbestos                                0.86               0.86   \n",
       "lupus                                               0.44               0.83   \n",
       "postoperative_patient_data                          0.42               0.38   \n",
       "analcatdata_cyyoung9302                             0.76               0.89   \n",
       "analcatdata_cyyoung8092                             0.75               0.80   \n",
       "analcatdata_creditscore                             0.70               0.86   \n",
       "appendicitis                                        0.79               0.82   \n",
       "molecular_biology_promoters                         0.56               0.87   \n",
       "analcatdata_boxing1                                 0.65               0.85   \n",
       "mux6                                                0.63               0.75   \n",
       "analcatdata_boxing2                                 0.70               0.73   \n",
       "hepatitis                                           0.52               0.86   \n",
       "corral                                              0.74               0.96   \n",
       "glass2                                              0.68               0.78   \n",
       "backache                                            0.66               0.76   \n",
       "prnn_crabs                                          0.73               1.00   \n",
       "sonar                                               0.66               0.85   \n",
       "biomed                                              0.78               0.95   \n",
       "prnn_synth                                          0.63               0.95   \n",
       "analcatdata_lawsuit                                 0.81               1.00   \n",
       "spect                                               0.79               0.84   \n",
       "heart_statlog                                       0.38               0.89   \n",
       "breast_cancer                                       0.60               0.71   \n",
       "heart_h                                             0.64               0.86   \n",
       "hungarian                                           0.78               0.86   \n",
       "cleve                                               0.61               0.88   \n",
       "heart_c                                             0.62               0.91   \n",
       "haberman                                            0.38               0.70   \n",
       "bupa                                                0.57               0.68   \n",
       "spectf                                              0.81               0.88   \n",
       "ionosphere                                          0.67               0.94   \n",
       "colic                                               0.74               0.86   \n",
       "horse_colic                                         0.53               0.84   \n",
       "house_votes_84                                      0.91               0.99   \n",
       "vote                                                0.95               1.00   \n",
       "saheart                                             0.52               0.78   \n",
       "clean1                                              0.71               1.00   \n",
       "irish                                               0.84               1.00   \n",
       "\n",
       "                             GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_tanh_crossentropy  \\\n",
       "parity5                                                                   0.18                            \n",
       "analcatdata_fraud                                                         0.69                            \n",
       "analcatdata_aids                                                          0.75                            \n",
       "analcatdata_bankruptcy                                                    0.98                            \n",
       "analcatdata_japansolvent                                                  0.86                            \n",
       "labor                                                                     0.97                            \n",
       "analcatdata_asbestos                                                      0.87                            \n",
       "lupus                                                                     0.86                            \n",
       "postoperative_patient_data                                                0.40                            \n",
       "analcatdata_cyyoung9302                                                   0.86                            \n",
       "analcatdata_cyyoung8092                                                   0.83                            \n",
       "analcatdata_creditscore                                                   0.98                            \n",
       "appendicitis                                                              0.82                            \n",
       "molecular_biology_promoters                                               0.87                            \n",
       "analcatdata_boxing1                                                       0.89                            \n",
       "mux6                                                                      0.73                            \n",
       "analcatdata_boxing2                                                       0.73                            \n",
       "hepatitis                                                                 0.86                            \n",
       "corral                                                                    0.96                            \n",
       "glass2                                                                    0.78                            \n",
       "backache                                                                  0.73                            \n",
       "prnn_crabs                                                                1.00                            \n",
       "sonar                                                                     0.86                            \n",
       "biomed                                                                    0.95                            \n",
       "prnn_synth                                                                0.93                            \n",
       "analcatdata_lawsuit                                                       0.99                            \n",
       "spect                                                                     0.84                            \n",
       "heart_statlog                                                             0.90                            \n",
       "breast_cancer                                                             0.71                            \n",
       "heart_h                                                                   0.88                            \n",
       "hungarian                                                                 0.86                            \n",
       "cleve                                                                     0.89                            \n",
       "heart_c                                                                   0.91                            \n",
       "haberman                                                                  0.71                            \n",
       "bupa                                                                      0.66                            \n",
       "spectf                                                                    0.90                            \n",
       "ionosphere                                                                0.91                            \n",
       "colic                                                                     0.86                            \n",
       "horse_colic                                                               0.83                            \n",
       "house_votes_84                                                            0.99                            \n",
       "vote                                                                      1.00                            \n",
       "saheart                                                                   0.78                            \n",
       "clean1                                                                    1.00                            \n",
       "irish                                                                     1.00                            \n",
       "\n",
       "                             GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_relu_crossentropy  \n",
       "parity5                                                                   0.17                           \n",
       "analcatdata_fraud                                                         0.71                           \n",
       "analcatdata_aids                                                          0.67                           \n",
       "analcatdata_bankruptcy                                                    0.96                           \n",
       "analcatdata_japansolvent                                                  0.86                           \n",
       "labor                                                                     0.95                           \n",
       "analcatdata_asbestos                                                      0.87                           \n",
       "lupus                                                                     0.85                           \n",
       "postoperative_patient_data                                                0.40                           \n",
       "analcatdata_cyyoung9302                                                   0.85                           \n",
       "analcatdata_cyyoung8092                                                   0.81                           \n",
       "analcatdata_creditscore                                                   0.98                           \n",
       "appendicitis                                                              0.80                           \n",
       "molecular_biology_promoters                                               0.89                           \n",
       "analcatdata_boxing1                                                       0.83                           \n",
       "mux6                                                                      0.97                           \n",
       "analcatdata_boxing2                                                       0.73                           \n",
       "hepatitis                                                                 0.86                           \n",
       "corral                                                                    1.00                           \n",
       "glass2                                                                    0.80                           \n",
       "backache                                                                  0.71                           \n",
       "prnn_crabs                                                                1.00                           \n",
       "sonar                                                                     0.91                           \n",
       "biomed                                                                    0.95                           \n",
       "prnn_synth                                                                0.94                           \n",
       "analcatdata_lawsuit                                                       1.00                           \n",
       "spect                                                                     0.84                           \n",
       "heart_statlog                                                             0.90                           \n",
       "breast_cancer                                                             0.69                           \n",
       "heart_h                                                                   0.88                           \n",
       "hungarian                                                                 0.87                           \n",
       "cleve                                                                     0.88                           \n",
       "heart_c                                                                   0.91                           \n",
       "haberman                                                                  0.66                           \n",
       "bupa                                                                      0.67                           \n",
       "spectf                                                                    0.90                           \n",
       "ionosphere                                                                0.95                           \n",
       "colic                                                                     0.86                           \n",
       "horse_colic                                                               0.83                           \n",
       "house_votes_84                                                            0.98                           \n",
       "vote                                                                      0.99                           \n",
       "saheart                                                                   0.77                           \n",
       "clean1                                                                    1.00                           \n",
       "irish                                                                     1.00                           "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results = saved_results.copy()\n",
    "for model_name in model_names:\n",
    "    try:\n",
    "        path = f\"{save_dir}{model_name}/test_0.csv\"\n",
    "        results_one_model = [pd.read_csv(f\"{save_dir}{model_name}/test_{i}.csv\", index_col=0)\n",
    "                            for i in range(44)]\n",
    "        df_one_model = pd.concat(results_one_model, axis=0)\n",
    "        combined_results = combined_results.join(df_one_model)\n",
    "    except:\n",
    "        print(f\"Failed to load {path}\")\n",
    "combined_results = combined_results.round(2)\n",
    "combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoGluon                                                                     0.879091\n",
       "AutoPrognosis                                                                 0.853864\n",
       "TabPFN                                                                        0.849545\n",
       "GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_relu_crossentropy    0.842045\n",
       "GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_tanh_crossentropy    0.840000\n",
       "RFNN_crossentropy                                                             0.835227\n",
       "Logistic regression                                                           0.819318\n",
       "HyperFast                                                                     0.816591\n",
       "E2E_MLP_ResNet_crossentropy                                                   0.656818\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results.mean(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabPFN                                                                        3.590909\n",
       "AutoGluon                                                                     3.693182\n",
       "AutoPrognosis                                                                 3.840909\n",
       "GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_tanh_crossentropy    4.284091\n",
       "GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_relu_crossentropy    4.556818\n",
       "RFNN_crossentropy                                                             4.625000\n",
       "Logistic regression                                                           5.840909\n",
       "HyperFast                                                                     6.034091\n",
       "E2E_MLP_ResNet_crossentropy                                                   8.534091\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results.rank(axis=1, ascending=False).mean(axis=0).sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "nan_columns = combined_results.columns[combined_results.isna().any()].tolist()\n",
    "print(nan_columns)\n",
    "combined_results[nan_columns]\n",
    "combined_results = combined_results.drop(columns=nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AutoPrognosis</th>\n",
       "      <th>AutoGluon</th>\n",
       "      <th>TabPFN</th>\n",
       "      <th>Logistic regression</th>\n",
       "      <th>HyperFast</th>\n",
       "      <th>E2E_MLP_ResNet_crossentropy</th>\n",
       "      <th>RFNN_crossentropy</th>\n",
       "      <th>GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_tanh_crossentropy</th>\n",
       "      <th>GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_relu_crossentropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>parity5</th>\n",
       "      <td>0.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_fraud</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_cyyoung9302</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mux6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backache</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prnn_synth</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_lawsuit</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horse_colic</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         AutoPrognosis  AutoGluon  TabPFN  \\\n",
       "parity5                           0.27       1.00    0.02   \n",
       "analcatdata_fraud                 0.86       0.80    0.79   \n",
       "analcatdata_cyyoung9302           0.89       0.85    0.87   \n",
       "mux6                              1.00       1.00    1.00   \n",
       "backache                          0.60       0.72    0.75   \n",
       "prnn_synth                        0.94       0.95    0.95   \n",
       "analcatdata_lawsuit               0.99       0.99    1.00   \n",
       "bupa                              0.66       0.64    0.68   \n",
       "ionosphere                        0.97       0.98    0.98   \n",
       "horse_colic                       0.88       0.85    0.84   \n",
       "\n",
       "                         Logistic regression  HyperFast  \\\n",
       "parity5                                 0.17       0.02   \n",
       "analcatdata_fraud                       0.77       0.73   \n",
       "analcatdata_cyyoung9302                 0.87       0.84   \n",
       "mux6                                    0.70       0.95   \n",
       "backache                                0.72       0.78   \n",
       "prnn_synth                              0.94       0.94   \n",
       "analcatdata_lawsuit                     1.00       0.98   \n",
       "bupa                                    0.67       0.66   \n",
       "ionosphere                              0.90       0.97   \n",
       "horse_colic                             0.82       0.83   \n",
       "\n",
       "                         E2E_MLP_ResNet_crossentropy  RFNN_crossentropy  \\\n",
       "parity5                                         0.48               0.19   \n",
       "analcatdata_fraud                               0.64               0.80   \n",
       "analcatdata_cyyoung9302                         0.76               0.89   \n",
       "mux6                                            0.63               0.75   \n",
       "backache                                        0.66               0.76   \n",
       "prnn_synth                                      0.63               0.95   \n",
       "analcatdata_lawsuit                             0.81               1.00   \n",
       "bupa                                            0.57               0.68   \n",
       "ionosphere                                      0.67               0.94   \n",
       "horse_colic                                     0.53               0.84   \n",
       "\n",
       "                         GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_tanh_crossentropy  \\\n",
       "parity5                                                               0.18                            \n",
       "analcatdata_fraud                                                     0.69                            \n",
       "analcatdata_cyyoung9302                                               0.86                            \n",
       "mux6                                                                  0.73                            \n",
       "backache                                                              0.73                            \n",
       "prnn_synth                                                            0.93                            \n",
       "analcatdata_lawsuit                                                   0.99                            \n",
       "bupa                                                                  0.66                            \n",
       "ionosphere                                                            0.91                            \n",
       "horse_colic                                                           0.83                            \n",
       "\n",
       "                         GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_relu_crossentropy  \n",
       "parity5                                                               0.17                           \n",
       "analcatdata_fraud                                                     0.71                           \n",
       "analcatdata_cyyoung9302                                               0.85                           \n",
       "mux6                                                                  0.97                           \n",
       "backache                                                              0.71                           \n",
       "prnn_synth                                                            0.94                           \n",
       "analcatdata_lawsuit                                                   1.00                           \n",
       "bupa                                                                  0.67                           \n",
       "ionosphere                                                            0.95                           \n",
       "horse_colic                                                           0.83                           "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results.query(\"RFNN_crossentropy > GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_tanh_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedVariableError",
     "evalue": "name 'GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeFalse_tanh_crossentropy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/scope.py:233\u001b[0m, in \u001b[0;36mScope.resolve\u001b[0;34m(self, key, is_local)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_resolvers:\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolvers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# if we're here that means that we have no locals and we also have\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# no resolvers\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/collections/__init__.py:986\u001b[0m, in \u001b[0;36mChainMap.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__missing__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/collections/__init__.py:978\u001b[0m, in \u001b[0;36mChainMap.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__missing__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeFalse_tanh_crossentropy'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/scope.py:244\u001b[0m, in \u001b[0;36mScope.resolve\u001b[0;34m(self, key, is_local)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# last ditch effort we look in temporaries\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# these are created when parsing indexing expressions\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# e.g., df[df > 0]\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeFalse_tanh_crossentropy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mUndefinedVariableError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcombined_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRFNN_crossentropy < GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeFalse_tanh_crossentropy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/frame.py:4440\u001b[0m, in \u001b[0;36mDataFrame.query\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4438\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4439\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 4440\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4442\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   4443\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[res]\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/frame.py:4566\u001b[0m, in \u001b[0;36mDataFrame.eval\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4563\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   4564\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolvers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolvers\u001b[39m\u001b[38;5;124m\"\u001b[39m, ())) \u001b[38;5;241m+\u001b[39m resolvers\n\u001b[0;32m-> 4566\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/eval.py:336\u001b[0m, in \u001b[0;36meval\u001b[0;34m(expr, parser, engine, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# get our (possibly passed-in) scope\u001b[39;00m\n\u001b[1;32m    328\u001b[0m env \u001b[38;5;241m=\u001b[39m ensure_scope(\n\u001b[1;32m    329\u001b[0m     level \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    330\u001b[0m     global_dict\u001b[38;5;241m=\u001b[39mglobal_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m     target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[1;32m    334\u001b[0m )\n\u001b[0;32m--> 336\u001b[0m parsed_expr \u001b[38;5;241m=\u001b[39m \u001b[43mExpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumexpr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    339\u001b[0m     is_extension_array_dtype(parsed_expr\u001b[38;5;241m.\u001b[39mterms\u001b[38;5;241m.\u001b[39mreturn_type)\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(parsed_expr\u001b[38;5;241m.\u001b[39mterms, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moperand_types\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    344\u001b[0m     )\n\u001b[1;32m    345\u001b[0m ):\n\u001b[1;32m    346\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine has switched to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m because numexpr does not support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextension array dtypes. Please set your engine to python manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    349\u001b[0m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    350\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    351\u001b[0m     )\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/expr.py:809\u001b[0m, in \u001b[0;36mExpr.__init__\u001b[0;34m(self, expr, engine, parser, env, level)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m parser\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_visitor \u001b[38;5;241m=\u001b[39m PARSERS[parser](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser)\n\u001b[0;32m--> 809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/expr.py:828\u001b[0m, in \u001b[0;36mExpr.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    825\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;124;03m    Parse an expression.\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 828\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_visitor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/expr.py:421\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Module\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly a single expression is allowed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    420\u001b[0m expr \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mbody[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/expr.py:424\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Expr\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisit_Expr\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/expr.py:719\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Compare\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslate_In(ops[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    718\u001b[0m     binop \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mBinOp(op\u001b[38;5;241m=\u001b[39mop, left\u001b[38;5;241m=\u001b[39mnode\u001b[38;5;241m.\u001b[39mleft, right\u001b[38;5;241m=\u001b[39mcomps[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;66;03m# recursive case: we have a chained comparison, a CMP b CMP c, etc.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m left \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mleft\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/expr.py:535\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_BinOp\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisit_BinOp\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 535\u001b[0m     op, op_class, left, right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_transform_eq_ne\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m     left, right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_downcast_constants(left, right)\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_evaluate_binop(op, op_class, left, right)\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/expr.py:457\u001b[0m, in \u001b[0;36mBaseExprVisitor._maybe_transform_eq_ne\u001b[0;34m(self, node, left, right)\u001b[0m\n\u001b[1;32m    455\u001b[0m     left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisit(node\u001b[38;5;241m.\u001b[39mleft, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 457\u001b[0m     right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mright\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m op, op_class, left, right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rewrite_membership_op(node, left, right)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op, op_class, left, right\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/expr.py:548\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Name\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisit_Name\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterm_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/ops.py:86\u001b[0m, in \u001b[0;36mTerm.__init__\u001b[0;34m(self, name, env, side, encoding)\u001b[0m\n\u001b[1;32m     84\u001b[0m tname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(name)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_local \u001b[38;5;241m=\u001b[39m tname\u001b[38;5;241m.\u001b[39mstartswith(LOCAL_TAG) \u001b[38;5;129;01mor\u001b[39;00m tname \u001b[38;5;129;01min\u001b[39;00m DEFAULT_GLOBALS\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;241m=\u001b[39m encoding\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/ops.py:110\u001b[0m, in \u001b[0;36mTerm._resolve_name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mscope \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mscope[local_name], \u001b[38;5;28mtype\u001b[39m\n\u001b[1;32m    107\u001b[0m ):\n\u001b[1;32m    108\u001b[0m     is_local \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(res)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(res, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m res\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/pandas/core/computation/scope.py:246\u001b[0m, in \u001b[0;36mScope.resolve\u001b[0;34m(self, key, is_local)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemps[key]\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UndefinedVariableError(key, is_local) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mUndefinedVariableError\u001b[0m: name 'GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeFalse_tanh_crossentropy' is not defined"
     ]
    }
   ],
   "source": [
    "combined_results.query(\"RFNN_crossentropy < GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeFalse_tanh_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikita/Code/zephyrox/.conda/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:600: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  return result_to_tuple(hypotest_fun_out(*samples, **kwds))\n",
      "/tmp/ipykernel_39864/3416593325.py:17: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABpkAAAFACAYAAABHrxSqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAADy0UlEQVR4nOzdd3zN5///8efJTpAghFgRe2+1YqtNKW2V1l4ttcrXqNZutagOq9SoqmpRq1aNxApqxd57JPYoQdb794dfzidHTiInwjEe99vt3Crva7xf1/ucnlw5r/O+LpNhGIYAAAAAAAAAAAAAGzjYOwAAAAAAAAAAAAC8fEgyAQAAAAAAAAAAwGYkmQAAAAAAAAAAAGAzkkwAAAAAAAAAAACwGUkmAAAAAAAAAAAA2IwkEwAAAAAAAAAAAGxGkgkAAAAAAAAAAAA2I8kEAAAAAAAAAAAAm5FkAgAAAAAAAAAAgM1IMgEAAAAAAAAAAMBmJJkAAAAAAAAAAABgM5JMAAAAAAAAAAAAsBlJJgAAAAAAAAAAANiMJBMAAAAAAAAAAABsRpIJAAAAAAAAAAAANiPJBAAAAAAAAAAAAJuRZAIAAAAAAAAAAIDNSDIBAAAAAAAAAADAZiSZAAAAAAAAAAAAYDOSTAAAAAAAAAAAALAZSSYAAAAAAAAAAADYjCQTAAAAAAAAAAAAbEaSCQAAAAAAAAAAADYjyQQAAAAAAAAAAACbkWQCAAAAAAAAAACAzUgyAQAAAAAAAAAAwGYkmQAAAAAAAAAAAGAzkkwAAAAAAAAAAACwGUkmAAAAAAAAAAAA2IwkEwAAAAAAAAAAAGxGkgkAAAAAAAAAAAA2I8kEAAAAAAAAAAAAm5FkAgAAAAAAAAAAgM1IMgEAAAAAAAAAAMBmJJkAAAAAAAAAAABgM5JMAAAAAAAAAAAAsBlJJgAAAAAAAAAAANiMJBMAvIL+/vtvlSpVSq6ursqePbuGDBmi6Ohoe4eVJEuXLlW5cuWUJk0a+fr66t1339WpU6fsHdYTVatWTSaTyepj3rx59g7viX755ReVLFlSbm5uypAhg+rVq6f79+/bO6xEzZo1y+r1HjBggL1Ds9ndu3eVLVs2mUwm7dy5097hJGrFihWqWrWqMmbMKFdXV+XKlUt9+vTR7du37R3aE82fP19vvfWWsmXLplSpUqlEiRKaMWOGDMOwd2hPdOLECXXt2lUlSpSQk5OTihQpYu+QAAAAAACQk70DAACkrG3btumtt97S+++/r6+++koHDx7U4MGDde/ePY0dO9be4SUqKChITZs2VevWrTVq1Chdv35dX3zxhWrXrq39+/fL3d3d3iEmaNKkSbpz547Fse+++04LFy5UrVq17BRV0owaNUpff/21Bg0apAoVKujatWtat27dS5OYXLVqlby8vMw/Z82a1Y7RJM+IESMUFRVl7zCS5MaNGypXrpx69Oghb29vHThwQEOHDtWBAwf0zz//2Du8RH377bfKmTOnxo0bp4wZM2rNmjXq1KmTzp8/ryFDhtg7vEQdPHhQy5cvV7ly5RQTE6OYmBh7hwQAAAAAgEzGy/DVTQBAktWtW1dXr17Vrl27zMfGjRungQMH6vz588qUKZMdo0tc165d9c8//+jkyZMymUySpMDAQNWoUUMbN25U5cqV7RyhbXLlyqWCBQtq+fLl9g4lQUePHlWRIkW0dOlS1atXz97h2GTWrFlq166drl69qgwZMtg7nGQ7cuSIypQpo3Hjxqlr167asWOHypQpY++wbDJt2jR17txZFy9eVJYsWewdToKuXbsW77XSuXNn/fHHH7p586YcHF7cm/xjYmLM8bVt21Y7d+7UgQMH7BwVAAAAAOB19+L+JQ0ASJY9e/aodu3aFsfq1KmjyMhIrV692k5RJU1kZKTSpEljTjBJMt+h8rJ9JyI4OFinT59Wq1at7B1KombOnCl/f/+XLsH0Kvnkk0/UtWtX5c+f396hJJu3t7ckKSIiws6RJM5aMrJkyZK6c+eO7t27Z4eIku5FToABAAAAAF5f/LUKAK+YBw8eyNXV1eJY7M+HDx+2R0hJ1rZtWx06dEiTJk3S7du3derUKQ0aNEglS5ZUpUqV7B2eTebOnatUqVLprbfesncoidq2bZuKFi2qkSNHysfHRy4uLqpUqZK2b99u79CSrHDhwnJ0dFSuXLn01VdfvTTL/EnSggULtH//fn3xxRf2DsVm0dHRevDggXbv3q3hw4ercePGypkzp73DstnmzZuVNWtWpUmTxt6hAAAAAADw0iHJBACvmLx58+rff/+1OLZt2zZJj/ZSeZFVrlxZixYt0oABA5Q2bVrlzp1bly9f1sqVK+Xo6Gjv8JIsKipKf/75pxo3bqxUqVLZO5xEhYWF6Z9//tHs2bM1adIkLV68WCaTSbVr19aVK1fsHV6ifH19NWzYMM2ePVsrV65U/fr1NXjwYPXs2dPeoSVJeHi4+vTpoy+//FKenp72Dsdmfn5+cnd3V+nSpeXr66u5c+faOySbbd68WfPmzVPfvn3tHQoAAAAAAC8lkkwA8Ir5+OOPtXLlSn3//fe6ceOGNm/erM8++0yOjo4Wy9C9iIKDg/Xhhx+qU6dOWr9+vebPn6+YmBg1aNBA9+/ft3d4SbZmzRpdvXpVLVu2tHcoTxQTE6O7d+9qwYIFat68uerXr6+lS5fKMAxNmDDB3uElqk6dOvriiy9Up04d1a5dWxMmTFCfPn00ZcoUhYaG2ju8Jxo5cqQyZcqkdu3a2TuUZFmxYoWCg4M1bdo0HT58WI0aNXqp7iK7cOGC3nvvPVWvXl09evSwdzgAAAAAALyUSDIBwCumbdu26tWrl/r27Stvb2/VrFlTXbt2Vfr06eXr62vv8BLVo0cP1ahRQ+PGjVP16tXVvHlzLV++XLt379avv/5q7/CSbO7cufL29ladOnXsHcoTpUuXTt7e3ipWrJj5WPr06VWyZEkdPHjQjpElz7vvvqvo6GiFhITYO5REnT17VuPGjdOwYcN0+/Zt3bp1S3fv3pUk3b171/zvF1mxYsVUoUIFdezYUUuWLFFgYKAWLVpk77CS5NatW6pXr568vb21cOFC9jsCAAAAACCZ+IsaAF4xDg4OGj9+vK5du6a9e/fq8uXL6tSpk65evary5cvbO7xEHTp0SCVKlLA4li1bNmXIkEEnT560T1A2un//vhYvXqx33nlHzs7O9g7niQoXLpxg2YMHD55jJK+X06dPKyIiQg0aNFC6dOmULl06NWrUSJJUvXp11apVy84R2qZYsWJydnbWiRMn7B3KE92/f18NGzbU7du3tXLlSnl5edk7JAAAAAAAXlpO9g4AAPBseHl5me9O+eKLL+Tv7//Cf3Dt5+en3bt3Wxw7e/asrl27ppw5c9onKBstXbpUd+/efSmWypOkhg0baubMmQoJCTEn+K5fv67du3erd+/e9g0uGebNmydHR0eVLFnS3qEkqkSJEgoMDLQ4FhISot69e2vKlCkqW7asnSJLnu3btysyMlK5cuWydyiJioqK0rvvvqvDhw9r06ZNypo1q71DAgAAAADgpUaSCQBeMf/++682bNigEiVK6P79+1q6dKl+/fVXrVy5Uo6OjvYOL1Fdu3ZVr1691LNnTzVq1EjXr1/XyJEj5ePjo3fffdfe4SXJ3LlzlSNHDgUEBNg7lCRp0qSJypYtq+bNm2vUqFFyd3fXV199JVdXV3388cf2Di9RderUUY0aNVS0aFFJjxJ8U6dOVc+ePZU5c2Y7R5e4tGnTqlq1albLSpcurVKlSj3fgGzw9ttvq0yZMipWrJjc3d21d+9ejRkzRsWKFVOTJk3sHV6iPv74Y/39998aN26c7ty5o23btpnLSpYsKVdXVztGl7jw8HCtWLFC0qPk+507d7RgwQJJUtWqVZUxY0Z7hgcAAAAAeE2RZAKAV4yLi4sWLlyo4cOHS5LKlSunoKAgVahQwc6RPVmPHj3k6uqqyZMna/r06UqTJo0qVKig+fPny9vb297hPdHNmze1atUq9erVSyaTyd7hJImDg4NWrFih3r17q0uXLoqIiFDlypW1cePGFz5RU6BAAU2fPl0XLlxQTEyM8uXLp++++06ffPKJvUN7pb3xxhv6448/NHr0aMXExChnzpzq1KmT+vbtKxcXF3uHl6h//vlHkvTpp5/GKzt9+vQLfcfklStX9M4771gci/05MDAwwaQlAAAAAADPkskwDMPeQQAAAAAAAAAAAODl4mDvAAAAAAAAAAAAAPDyIckEAAAAAAAAAAAAm5FkAgAAAAAAAAAAgM1IMgEAAAAAAAAAAMBmJJkAAAAAAAAAAABgM5JMAAAAAAAAAAAAsBlJJgB4hZUpU0bZsmVTmTJl7B2KTV7WuCVitxditw9it4+XOXYAAAAAwKvFyd4BAACenbCwMF28eNHeYdjsZY1bInZ7IXb7IHb7eJljBwAAAAC8WriTCQAAAAAAAAAAADYjyQQAAAAAAAAAAACbkWQCAAAAAAAAAACAzUgyAQAAAAAAAAAAwGYkmQAAAAAAAAAAAGAzkkwAAAAAAAAAAACwGUkmAECylClTRtmyZVOZMmXsHYrNiN0+XtbYX9a4JWK3l5c5dgAAAAAAbOFk7wAAAC+nsLAwXbx40d5hJAux28fLGvvLGrdE7PbyMscOAAAAAIAtuJMJAAAAAAAAAAAANiPJBAAAAAAAAAAAAJuRZAIAAAAAAAAAAIDNSDIBAAAAAAAAAADAZiSZAAAAAAAAAAAAYDOSTAAAAAAAAAAAALCZyTAMw95BAACeDRcXF0VGRsrBwUG+vr4p0mfsr43Q0FAZhpGifccKDQ1VTEzMM+n7Wff/ssZuGMYTn9O4UwaTyWTzOV6G625tWmTLaz051yix2BPrz1rZ48de1tfjs+77Wff/vGJ3dnZWREREivcPAAAAAEBSkWQCgFeYo6OjYmJi7B0GAOAZcHBwUHR0tL3DAAAAAAC8xpzsHQAA4Nlxc3PTgwcP5OjoKB8fnxTp0zAMXbp0SU5OToqJiUnRvmNduXJF0dHRz6TvZ93/yxp77PNqMpnk5ORkte/YOlmyZEnWnUwvw3WPO0ZJNr/Wk3ONEos9sf6slT1+7GV9PT7rvp91/88rdjc3txTvGwAAAAAAW3AnEwDAJpGRkXJxcVFERIScnZ3tHQ5SSFKe19fhuY87Rkk2jzelr1Fi/Vkrex2eIwAAAAAA8OJwsHcAAAAAAAAAAAAAePmQZAIAAAAAAAAAAIDNSDIBAAAAAAAAAADAZiSZAAAAAAAAAAAAYDOSTAAAAAAAAAAAALAZSSYAAAAAAAAAAADYjCQTAAAAAAAAAAAAbEaSCQAAAAAAAAAAADYjyQQAAAAAAAAAAACbkWQCAAAAAAAAAACAzUgyAQAAAAAAAAAAwGYkmQAAAAAAAAAAAGAzkkwAAAAAAAAAAACwGUkmAAAAAAAAAAAA2IwkEwAAAAAAAAAAAGxGkgkAAAAAAAAAAAA2I8kEAAAAAAAAAAAAmznZOwAAAAB7uX37tvbv32/+OSoqSpK0ZcsW87EtW7bIySlpU6a47ZPaJrn9WStLqH7RokXl5eX11PEAAAAAAADEZTIMw7B3EACAl0dkZKRcXFwUEREhZ2dne4eDFJKU5/VVfO43b96sypUr2zuMZ27Tpk0KCAiwdxgAAAAAAOAVw3J5AAAAAAAAAAAAsBlJJgAAAAAAAAAAANiMPZkAAMBrq2jRotq0aZP556ioKFWvXl2BgYGSZP63LXsy2domuf1ZK0uoftGiRZ86FgAAAAAAgMexJxMAwCav4r48eH33ZHpc3DFKsnm8KX2NEuvPWtnr8BwBAAAAAIAXB8vlAQAAAAAAAAAAwGYkmQAAAAAAAAAAAGAzkkwAAAAAAAAAAACwGUkmAAAAAAAAAAAA2MzJ3gEAAIDn7/bt29q/f7/556ioKEnSli1b5ORkfXpgrU7RokXl5eX1jKMFAAAAAADAi4gkEwAAr6H9+/ercuXK8Y5Xr179iW3j1tm0aZMCAgJSNDYAAAAAAAC8HFguDwAAAAAAAAAAADYjyQQAAAAAAAAAAACbsVweAACvoaJFi2rTpk3mn6OiolS9enUFBgYmuifT43WKFi36XOIFAAAAAADAi8dkGIZh7yAAAC+PyMhIubi4KCIiQs7OzvYOBykkKc/r6/Dcxx2jJJvHm9LXKLH+rJW9Ds8RAAAAAAB4cbBcHgAAAAAAAAAAAGxGkgkAAAAAAAAAAAA2I8kEAAAAAAAAAAAAm5FkAgAAAAAAAAAAgM1IMgEAAAAAAAAAAMBmJJkAAAAAAAAAAABgM5JMAAAAAAAAAAAAsBlJJgAAAAAAAAAAANiMJBMAAAAAAAAAAABsRpIJAAAAAAAAAAAANiPJBAAAAAAAAAAAAJuRZAIAAAAAAAAAAIDNSDIBAAAAAAAAAADAZiSZAAAAAAAAAAAAYDOSTAAAAAAAAAAAALAZSSYAAAAAAAAAAADYjCQTAAAAAAAAAAAAbEaSCQAAAAAAAAAAADYjyQQAAAAAAAAAAACbkWQCAAAAAAAAAACAzUgyAQAAAAAAAAAAwGYkmQAAAAAAAAAAAGAzkkwAAAAAAAAAAACwGUkmAAAAAAAAAAAA2IwkEwAAAAAAAAAAAGxGkgkAAAAAAAAAAAA2I8kEAAAAAAAAAAAAm5FkAgAAAAAAAAAAgM1IMgEAAAAAAAAAAMBmJJkAAAAAAAAAAABgM5JMAAAAAAAAAAAAsBlJJgAAAAAAAAAAANiMJBMAAAAAAAAAAABsRpIJAAAAAAAAAAAANiPJBAAAAAAAAAAAAJuRZAIAAAAAAAAAAIDNSDIBAAAAAAAAAADAZiSZAAAAAAAAAAAAYDOSTAAAAAAAAAAAALAZSSYAAAAAAAAAAADYjCQTAAAAAAAAAAAAbEaSCQAAAAAAAAAAADYjyQQAAAAAAAAAAACbkWQCAAAAAAAAAACAzUgyAQAAAAAAAAAAwGYkmQAAAAAAAAAAAGAzkkwAAAAAAAAAAACwGUkmAAAAAAAAAAAA2IwkEwAAAAAAAAAAAGxGkgkAAAAAAAAAAAA2I8kEAAAAAAAAAAAAm5FkAgAAAAAAAAAAgM1IMgEAAAAAAAAAAMBmJJkAAAAAAAAAAABgM5JMAAAAAAAAAAAAsBlJJgAAAAAAAAAAANiMJBMAAAAAAAAAAABsRpIJAF4T0dHR+vzzz+Xv7y93d3flzp1bI0aMkGEYCbYJCgqSyWSyeLi4uFjUmTx5sooVKyZPT095enqqQoUKWrlypdX+DMNQvXr1ZDKZtHjxYouyHj16qHTp0nJ1dVWJEiWedrgAkGJseZ+TpFmzZsV773Rzc7Ooc/nyZbVt21ZZsmSRh4eH6tatq+PHj1vUefDggbp16yZvb2+lTp1azZo10+XLly3qrFu3ThUrVlSaNGmUOXNm9e/fX1FRUSk3eAAAAAAAEkGSCQBeE19//bUmT56sCRMm6PDhw/r666/1zTff6Mcff3xi26NHjyo0NFShoaE6d+6cRVm2bNk0evRo7dq1Szt37lSNGjX01ltv6eDBg/H6+e6772QymRI8T/v27fXee+/ZPjgAeIZseZ+L5enpaX7fDA0N1dmzZ81lhmGoSZMmOnXqlJYsWaI9e/bIz89PtWrV0r1798z1evfurWXLlmn+/PnasGGDLl26pLfffttcvnfvXtWvX19169bVnj179Mcff2jp0qUaMGDAs7kQAAAAAAA8xmQk9hV2AMAro2HDhsqUKZOmT59uPtasWTO5u7trzpw5VtsEBQWpevXqunnzptKmTStJioyMlIuLiyIiIuTs7Gy1Xfr06TVmzBh16NDBfCwkJEQNGzbUzp075evrq0WLFqlJkybx2g4dOlSLFy9WSEhIsscK2yXleU1KnZdd3DFKsnm8KX2NEuvPWtnr8By9KKy9z8WaNWuWevXqpVu3bllte+zYMeXPn18HDhxQ4cKFJUkxMTHKnDmzvvzyS3Xs2FG3b99WxowZNXfuXDVv3lySdOTIERUsWFBbt25V+fLlNWjQIK1Zs0Y7duww971s2TK9++67unLlitKkSZPyAwcAAAAAIA7uZAKA10TFihW1bt06HTt2TNKjb8Bv3rxZ9erVe2LbEiVKyNfXV2+++aaCg4MTrBcdHa158+bp3r17qlChgvl4eHi4WrZsqYkTJypz5sxPPxgAsJOE3uced/fuXfn5+Sl79uzx7np6+PChJFksoefg4CBXV1dt3rxZkrRr1y5FRkaqVq1a5joFChRQjhw5tHXrVnM/jy/D5+7urgcPHmjXrl1PP1gAAAAAAJ7A5iRTzpw5460xb+0xa9YsSY++Ubtu3Tr169dPZcuWVdq0aeXs7KzMmTOrcePGWr58eYLnqlatWpLONXTo0OSO3+Icb731VqJ158+fb3HeCxcuWJS3bdtWJpNJbdu2TdK5re11YjKZlCZNGhUvXlwDBgzQlStXkjs0SdafL1dXV2XLlk1vvfWW/v7776fq/2nEHX/mzJktloeJ68KFC+Z6AJJvwIABatGihQoUKCBnZ2eVLFlSvXr1UqtWrRJs4+vrqylTpmjhwoVauHChsmfPbvGBZ6z9+/crderUcnV1VdeuXbVo0SIVKlTIXN67d29VrFjxie+zAPCietL7XFz58+fXjBkztGTJEs2ZM0cxMTGqWLGiee4YmywaOHCgbt68qYiICH399de6cOGCQkNDJUlhYWFycXEx30UaK1OmTAoLC5Mk1alTR8HBwfr9998VHR2tixcvavjw4ZJk7ud5Ssq8/fFHtWrVbDpH7PzR1nYJxRe7R2G7du20b9++eG1i5/eJPR6/Kzfu/HvBggUJxlOrVi2Lv5sAAAAA4GXklNyGlSpVUp48eRIsjy3bsGGD3nzzTUlS5syZFRAQoFSpUunQoUNatmyZli1bps6dO2vKlCkJJhGKFy+e6CbwKbVB/IoVK3T58mVlypTJanncJaZSWps2bSQ9WqP/7Nmz2rZtm/bt26dZs2YpKChIBQoUeKr+4z5ft2/f1p49e7R06VItXbpUvXv31rfffvvUY3galy9f1rhx4/TFF18883OdOXNG/v7+8vPz05kzZ575+ZA81apV04YNGxQYGJisD5IQ359//qnffvtNc+fOVeHChRUSEqJevXopS5Ys5vegx+XPn1/58+c3/1yxYkWdOHFCmzZtilcvJCREt2/f1oIFC9SmTRtt2LBBhQoV0tKlS7V+/Xrt2bPnmY4PAJ6lxN7nHlehQgWLu5wqVqyoggUL6qefftKIESPk7Oysv/76Sx06dFD69Onl6OioWrVqqV69erJlJevatWtrzJgx6tq1qz788EO5urrq888/16ZNm+Tg8PwXLLD2uyQsLEyrV69OsPxp57jJUadOHfNdtVeuXNGOHTs0a9Ys/fbbb5ozZ47efffdeG1y586tgIAAq/2VKlUqwXN99tlnatKkiZyckv1nFwAAAAC80JL9107Hjh2TdMeOg4ODmjVrpp49e6py5coWZX/88YdatWqlqVOnqlKlSmrdurXVPpo0afJUdyslRZkyZbRz507Nnj1b/fr1i1d+/vx5rVmzRmXLlrVY9z6lPP4NxmPHjqlmzZq6cOGCOnfurI0bNz5V/48/X1FRUerdu7cmTJig8ePH6/3331fZsmWf6hzJFbusy9ixY/XRRx8pY8aMdokDeNX169fPfDeTJBUtWlRnz57VV199lWCSyZqyZcvGSzK5uLiYE9mlS5fWjh079P333+unn37S+vXrdfLkyXjfxm/WrJkqV66soKCgpxoXADwPib3PPUns3aMnTpwwHytdurQ5aRUREaGMGTOqXLlyKlOmjKRHX86KiIjQrVu3LN4/L1++bLHsaJ8+fdS7d2+FhoYqXbp0OnPmjAYOHKhcuXKl0MiTztodOUFBQeYk04tyx86AAQMsvsBy+/ZtvfPOO1qzZo06deqkN998U+nSpbNoExAQYHP8Hh4eOnbsmH7++Wd17do1BSIHAAAAgBfPM/+KY40aNbRgwYJ4CSZJeu+998yJj9mzZz/rUBL1wQcfyMXFRTNnzrRaPmvWLMXExKh9+/bPJZ58+fJpxIgRkqRNmzal+JInTk5OGjNmjDw9PSU92iTaXrJkyaLmzZvrv//+08iRI+0WB/CqCw8Pj/fNdkdHR8XExNjUz969e59YJyYmxrznyIABA7Rv3z6FhISYH5I0fvz4BN9zAeBFF/d97kmio6O1f/9++fr6xivz8vJSxowZdfz4ce3cudO8rGjp0qXl7OysdevWmesePXpU586di7cXlMlkUpYsWeTu7q7ff/9d2bNnT/TuGljy8vLS1KlTJUl37twxJ8WeVs+ePSVJw4cPV3h4eIr0CQAAAAAvmue/jsZjSpYsKenRnUL25O3trcaNG+vw4cPmzZRjGYahWbNmyd3dXe+///5zi6l06dLmf589ezbF+3dzc1PevHklPfpWrDXr1q3T22+/LV9fX7m4uMjHx0dNmzaNd41iHT9+XO3bt5e/v79cXV2VOnVq+fn5qUGDBol+mDxq1Cg5OTlpypQpOn36tE3jiIqK0s8//6xq1aopffr0cnV1lb+/vz766KN4r6u2bdvK399f0qNr+via+k9j165datOmjfz9/eXm5qb06dOrePHi6tevn8XzF3cvgfDwcH3xxRcqWLCgPDw8lDNnTos+582bp5o1a5rH5efnp/bt2+vYsWNWYwgNDVXPnj2VL18+ubm5ycPDQ9mzZ1fNmjU1duzYePXXrl2rRo0aKVOmTHJ2dla6dOmUN29effDBBwnePWfrayLutV24cKECAgLk6empVKlSqVKlSlqxYoVF/djrs2HDBklS9erVre73dubMGZlMJuXMmVPR0dH69ttvVbJkSaVOnTrec7l69Wo1bNhQPj4+cnFxUZYsWfTee+9p586dVmOO3astKChIGzZsUO3atZU+fXp5eHjojTfe0K+//hqvTdWqVWUymfT7779b7VOSvvnmG5lMJqvL8DwPjRo10qhRo7R8+XKdOXNGixYt0rfffqumTZua6wwcONDirtLvvvtOS5Ys0YkTJ3TgwAH16tVLgYGBFv0OHDhQGzdu1JkzZ7R//34NHDhQQUFB5r2eMmfOrCJFilg8JClHjhzm/x8l6cSJEwoJCVFYWJju379vTkhFREQ8y8sCAE/0pPe51q1ba+DAgeb6w4cP1z///KNTp05p9+7d+uCDD3T27Fl17NjRXGf+/PkKCgrSqVOntGTJEr355ptq0qSJateuLelR4qNDhw7q06ePAgMDtWvXLrVr104VKlRQ+fLlzf2MGTNG+/fv18GDBzVixAiNHj1aP/zwgxwdHZ/T1Um+Q4cOaciQIapUqZKyZs0qFxcXeXt7q1atWvrzzz+f2D48PFyDBg1Snjx55ObmpixZsqhDhw66ePGizbHkzJlT6dOnl6QUW065fv36qlq1qkJDQzV+/PgU6RMAAAAAXjR2Xxz8+PHjkmT1m53PW/v27bVgwQLNmDHD4huigYGBOnXqlFq1aiUvL6/nFs+dO3fM/3Z1dX2m57C2D1Xfvn01btw4OTg4qEyZMqpcubLOnTunJUuWaNmyZZo2bZratWtnrn/gwAFVqlRJd+7cUf78+dWwYUM5OjrqwoUL2rhxoy5evGhRP668efOqU6dOmjx5sgYPHqzffvstSfH/999/aty4sYKCgpQ6dWqVLl1aGTNm1P79+zVlyhTNnz9fa9asMSczAwICdPfuXS1cuFCpUqVS8+bNbb1kVo0ZM0YDBgxQTEyM8uXLp7feekv379/XiRMnNHbsWBUuXDje8pIPHjxQtWrVdOjQIVWpUkXFixfX9evXJT1KbLZt21azZ8+Wk5OTqlSpIh8fH+3evVszZ87UH3/8oYULF6pu3brm/sLCwlSmTBldunRJOXLkUN26deXm5qZLly4pJCREu3btUt++fc31f/nlF/Pz8cYbb6h69eq6f/++Lly4oHnz5ilDhgyqUqWKRcy2vibiGjJkiEaMGKGKFSuqfv36OnLkiIKDg9WwYUMtXLjQnOjInDmz2rRpo1WrVuny5csW+yZIircXnGEYevvtt7Vq1SpVrlxZBQsW1MGDB83ln3/+uUaOHCmTyaSKFSsqR44cOnz4sP78808tXLhQU6dOTfAOxUWLFmnChAkqUKCA6tSpo0uXLmnz5s1q3bq1QkJCNG7cOHPdnj17auPGjZowYYLVZHRMTIwmT54sSerevbvV8z1rP/74oz7//HN9/PHHunLlirJkyaIuXbpY7IUWGhqqc+fOmX+OiIjQp59+qosXL8rDw0PFihXTqlWrzB+CSo/2s2jdurVCQ0Pl5eWlYsWKafXq1eb9+JKqY8eO5uSi9L8vIZw+fTpeAhYAnqcnvc+dO3fO4k7RmzdvqlOnTgoLC1O6dOlUunRpBQcHW+zfFBoaqj59+ujy5cvy9fVV69at9fnnn1ucd/z48ealpx8+fKg6depo0qRJFnVWrlypUaNG6eHDhypevLiWLFmievXqPcOrkXK+/fZbTZ8+XQUKFFDRokWVNm1anTt3ToGBgVq3bp22bduW4L6hERERqlmzpvbt26dq1aqpVKlS2rx5s2bMmKEVK1Zo48aN5i9TJUVMTIzu3bsnKWXn3V9//bXKly+vb775Rl27dpW3t3eK9Q0AAAAALwTDRn5+foYkY+bMmbY2jSc0NNTw8vIyJBk//PBDvPKqVasakowhQ4Y89bkSEnuOX3/91YiOjjayZctmpEmTxrh37565TqtWrQxJxvr16w3DMAxJhiTj/PnzFn21adPGkGS0adMmSecODAw092VN3759DUmGm5ubER4enqzxJfZ8HTp0yHB0dDQkGTt27LAomzp1qiHJyJMnj7F3716Lsg0bNhhp0qQxXFxcjGPHjpmPt2vXzpBkjBw5Mt65wsPDjQ0bNlgcix1/7ty5DcN49HpIlSqVYTKZjD179pjrnT9/PsHr1LJlS0OS0bBhQ+Py5csWZePHjzckGXnz5jWioqLMx0+fPm1IMvz8/OL1lxxLliwxP09//PFHvPKDBw8ahw4dMv8c93kvVqyYERoaGq/N5MmTDUlGhgwZLK5FTEyMMWTIEEOSkTZtWuPKlSvmsmHDhhmSjM6dOxsxMTEW/UVERBhr1661OObv729IMjZt2hTv/JcvXzZ2795tcSw5rwnD+N//L2nTpjW2bdtmURY7lnz58sWLIfb/zcDAwHhlhvG/51GSkS1bNuPo0aPx6qxcudL83Pzzzz8WZT///LMhyXB2djYOHDhg9dySjC+//NKiLCgoyHB3dzckGatWrTIfj4qKMv//9vi1MwzDWLZsmfk5f9lFREQYkoyIiAh7h4IUlJTn9XV47uOOMTnjTelrlFh/1speh+cIL5fE5rtBQUHGyZMn4x0/cuSIkS1bNkOSsX379gT7y5Mnj3H27Flz2f37941mzZoZkozy5cvH6ze2nbW5xd9//20uj53zG4bt83vD+N/8O3aO9fbbbxuSjN69e1vUq1mzZor9XQUAAAAA9pLsJNOTHjdv3ky0n8jISPMfVkWLFjUePnwYr07cD3oTe8T9EN5WcZNMhmEYn332mSHJmDVrlmEYhnHr1i3D3d3dyJUrl/mD+2eZZIqJiTHOnj1rjBw50nBycjIkGT169Ej2+KwlmW7dumWsXr3aKFCggCHJGDx4sEWb6OhoI0uWLIYkY+fOnVb7/eabbwxJxqeffmo+Vr9+/QQ/YLfm8SSTYRjG4MGDDUlGnTp1zMcSSjIdOnTIMJlMRpYsWYw7d+5YPUdsTMuWLTMfS+kkU4kSJQxJxrhx45JUP+7zvnHjRqt1cufOnWDyNSYmxihWrJghyRg1apT5+Mcff2xIMv76668kxeHh4WF4eXklqW5yXxOG8b//X6yN5cGDB+ZE87lz5yzKbEkyzZ4922qd2PeYPn36WC1v2LChIcno1KmT1XOXLFnSartPP/3UkGS8+eabFsdjr0GHDh3italTp44hyfjpp5+s9vky4UPsVxNJpkdIMgEp60lfqkrITz/9ZEgy+vXrl2B/ixcvjtfu8uXLhoeHhyHJ2LJli0WZtSTT1atXjblz5xo+Pj6GJKNEiRJGdHS0uTx2fp/Y43GPJ5mOHDliODk5Ga6ursaZM2fM9UgyAQAAAHgVJHu5vEqVKsVbtiouFxeXRNt37dpV69atk7e3txYsWJBo/eLFi6tEiRIJlseun54S2rVrpy+//FIzZsxQmzZtNHfuXN2/f19t27Z96j17EpNQ3y1bttQ333zz1P23a9cu3jJmjo6OmjNnjnk/gVh79uzRpUuXlDt3bot9oeKqVq2aJCk4ONh87I033tCKFSv00UcfadiwYapatarc3NxsirNfv36aMmWKVq9ercDAQFWvXj3BuitWrJBhGKpXr57SpEmTYJwrVqwwL8uW0sLCwhQSEiIHBwd16NDBprY+Pj6qXLlyvOMXLlzQyZMnJUlt2rSJV24ymdSuXTv17t1bgYGBGjRokKRH13/SpEkaMGCADMNQ7dq1lTp16gTP/8YbbygoKEitW7dWz549VbJkSYulfuJK7msirkaNGsU75urqqly5cmnPnj26ePGismfPnmC8iWnWrFm8Y1FRUdqyZYskxVuqMFaHDh30999/x9tjKFbcvYniatOmjcaNG6fNmzcrOjravO9Fx44dNXToUM2dO1djxoxRunTpJD3aa+iff/5R2rRp9cEHH9g6PAAAXll3797VypUrtWfPHl27ds28D19oaKgk6ejRo1bbpU2bVo0bN4533MfHR3Xr1tVff/2loKAgVaxYMV6dhOaXpUqV0l9//WV1PpQ7d24FBAQkeVxx5c+fX+3bt9fUqVP1+eefa/bs2cnqBwAAAABeRMlOMnXs2DHBD26fpGfPnpo+fbrSpUunNWvWKF++fInWb9KkiYYOHZqsc9kqd+7cqlKlijZu3KiTJ09qxowZcnBwSPZYkyo2mWAymeTh4SF/f3/VrVtXRYoUSZH+4yYFr169qk2bNum///7TRx99pLx58+qNN94w1z116pQk6eTJk09MrF29etX87379+mnz5s1au3at6tatK2dnZxUvXlxVqlRRixYtVLZs2SfG6enpqcGDB6tXr17q37+/tm/fnmDd2DinT5+u6dOnJznOlBS7d42vr6/N+3UltMdM7GbV3t7e8vT0tFond+7cFnUl6cMPP9SaNWv022+/qVmzZnJ0dFShQoUUEBCg5s2bq0aNGhZ9TJo0SQ0bNtSvv/6qX3/9VWnSpFHZsmVVo0YNffjhh8qRI4e5bnJfE3HF7S+u2DE+ePAg0X4T4uPjIw8Pj3jHr1+/bu7T39/faltr1zGuhNrFHr9//76uX78uHx8fSVK6dOn04Ycf6qefftL06dPNe2BNmjRJhmGoXbt2VmNNKsMwFBUVlez2KSUyMtLeIQB4Av4/RUpxcnJ6Zl+0WrZsmdq1a2fek9KauHuUxpUzZ84E44r9PX3hwgWr5XH3e3R1dVWWLFlUuXJlVa9ePcE+AwICNGvWrATjfJKhQ4dqzpw5+u2339S3b18VK1Ys2X0BAAAAwIsk2Umm5Pr000/1ww8/KG3atPrnn3/MG7u/SNq3b68NGzaod+/e2rlzp2rXrp3sOyyS6mn+aE2Kx5OCt2/fVtOmTRUYGKh3331Xhw4dMn/4HRMTI0nKnDmz6tSpk2i/GTJkMP/bw8NDa9as0Y4dO7Rq1SoFBwcrODhYO3fu1LfffquPP/5YEydOfGKsH330kb777jvt2LFDCxYsUIUKFazWi42zRIkSKl68eKJ9litX7onnfd7c3d1TtD8HBwfNmTNHgwYN0vLly7VlyxZt2bJFkydP1uTJk9WoUSMtWrTIfNdNwYIFdfToUf3zzz9av369goODtWnTJq1fv17Dhw/X9OnTzXfdJPc18Xh8z0JKX0dbGYZh8XOPHj30008/afLkyerTp48ePHigmTNnymQyqVu3bk91rqioqCfeJfq8eHp6PrPnFEDyOTg4yNPTU6lSpbJ3KHhFREREyNnZOcX7vXjxot577z3dv39f//d//6dWrVopZ86cSp06tRwcHPTPP/+oTp068X7P2iKhtgMGDDDfgf28+Pr6qmfPnvrqq680cOBALV++/LmeHwAAAACeleeaZPq///s/ffvtt/Ly8tI///yjMmXKPM/TJ1nz5s31ySefaNmyZZIeJZ1eNV5eXvrjjz9UoEABnT17Vt9++60GDx4sSeaEmre3d7KSX2XLljXftRQVFaXFixerdevWmjRpkpo3b57oEnjSo6UWR4wYoQ8//FCfffaZ/vnnH6v1YuOsVKmSJkyYYHOcKSH27pzQ0FDdvn3b5ruZrMmaNaukR3fi3Llzx+rdTLF3FsXWjatQoUIqVKiQ+vXrJ8MwtH79erVs2VLLli3T7NmzLZZNdHJyUv369VW/fn1Jj74t/O2332rYsGHq0qWLmjZtqlSpUj31a8IevL295erqqocPH+rUqVNWvzGc2HWUpNOnT1s9fubMGUmSm5ubvL29LcoKFSqkWrVqae3atVq5cqUuXbqkW7duqV69euY7p5LLycnJvIyQvTk4OJgTlgBeHI6Ojrpx44b5ywHA03JyejZ/Lixbtkz3799X06ZN9fXXX8crP378eKLtY38XJ1aWLVu2pwkxxfXv319Tp07VihUrtHHjRnuHAwAAAAAp4rl9DX3AgAEaM2aMvLy8tGbNmiQtnWYvHh4eatu2rby9veXv768mTZrYO6RnImPGjObE0tixY3Xr1i1Jj5JEGTJk0KFDh3Tw4MGnOoeTk5OaN29uvvslJCQkSe1atWql4sWL6/jx45o2bZrVOvXq1ZMkLV261Kal1mLvBEmJZccyZ86s4sWLKyYmRjNmzHjq/qRHH4jEJiOsJXQMwzAff1LCzmQyqWbNmmrZsqWkJ19/T09PDR06VGnTplV4eLiOHTsmKWVfE0n1tM+Tk5OTee+EhBJjsc9ZQtdxzpw5Vo/H7qUQEBBg9cO3nj17SpImTJhgvnuve/fuSQ8+ASaTSc7Ozi/EgwQT8OJydHS0+3sEj1fn8ayWyrtx44Ykyc/PL16ZYRiaO3duou1v3bpl/kJYXFevXtWqVask6bnfrfQkXl5e5r00/+///s/O0QAAAABAynguSabBgwfr66+/Vtq0aV/4BFOs77//XteuXdOpU6fk6upq73CemY8//lg5cuTQ7du3NW7cOEmSs7OzhgwZIsMw1LRpU23evDleu+joaK1fv17btm0zH5s0aZLVzZnDwsK0c+dOSdY/SLDGZDLpq6++kiR99913VuuULFlSzZo10/nz5/X2229b/UbrvXv39Ntvv+ny5cvmYxkzZpSLi4vCwsLMH3A8jSFDhkiSPvvsMy1cuDBe+aFDh3T48GGb+ozdy2fEiBHau3ev+bhhGBo5cqRCQkKUNm1aderUyVw2e/Zs7dq1K15f//33n4KCgiT97/qHh4fr22+/tbp/0qZNm3Tr1i05OjqavwGc3NfE04g999MktT799FNJ0uTJk7Vu3TqLslmzZmnp0qVydnY2J4Uet2vXLn3zzTcWxzZv3mxOHPXu3dtqu/r16ytPnjxatWqV9u7dq9y5c5uTogAA4NGyvZK0YMEChYaGmo9HR0friy++UHBw8BP7+PTTTy32XXr48KG6deume/fu6Y033lClSpVSPvCn1K1bN+XIkUPbt2/X1q1b7R0OAAAAADy1ZK9/8fPPP5s/uLamdu3aatmypZYuXapRo0ZJkvLkyZPgnjwZMmTQ2LFjrZYtXrw40SUxSpUqpR49eiQ59mdt+fLlKl++fILlHTt2VMeOHZ9jRAlzdXXV0KFD1b59e33//ffq3bu30qdPr+7du+vcuXMaM2aMKleurMKFCytPnjxyd3dXWFiYQkJCdOvWLU2ePNk81qlTp6pbt27y9/dXkSJF5OnpqatXr2rTpk26f/++atSoocaNGyc5tnr16qlatWqJvs5mzpypW7duaeXKlcqfP7+KFy8uf39/GYahM2fOaO/evYqIiNDhw4eVKVMmSY8SJo0bN9aCBQtUokQJBQQEmPej+vnnn22+hk2bNtWoUaM0ePBgNW/eXAUKFFDx4sV1//59nThxQocOHdLMmTPNH6YkRZcuXRQcHKxff/1VZcqUUdWqVeXj46Pdu3fr6NGjcnd319y5c5UxY0Zzm7/++ktt2rRRlixZVKJECaVLl043b97Uli1bdPv2bRUpUsSclIqIiNCnn36qfv36qWjRosqbN6+cnZ115swZc5Los88+s+g/Oa+Jp9GsWTPNnDlT//d//6e1a9fKx8dHJpNJ7du3V8WKFZPUR7169TR48GCNHDlSb775pipVqqQcOXLoyJEj2r17txwdHTVlyhQVLlzYavsePXpo4MCBmj17tooVK6ZLly5p06ZNiomJUc+ePc3LDD7OwcFB3bt3V69evSQ9SuY+q2+CAwDwMmrUqJFKly6tXbt2KV++fKpatapSpUql7du369KlS+rfv7/VZfRiVahQQTExMcqfP79q1KghDw8Pbd68WZcuXZKPj4/5ruMXjaurq4YPH662bdsqPDzc3uEAAAAAwNMzbOTn52dIeuKjZ8+ehmEYxsyZM5NU38/PL965qlatmqS2b731lq3DiHeOX3/9NcltYs97/vx5i+Nt2rRJUrxDhgwxDMMwAgMDzceeldjna+bMmQnWiYqKMgoVKmRIMgYMGGBRtmXLFqNVq1aGn5+f4erqaqRJk8bIly+f0aRJE+Pnn382bty4Ya77999/Gx999JFRsmRJI2PGjIaLi4uRLVs2o1q1asYvv/xiREREWPQdO/7cuXMnGNv27dstrp010dHRxty5c4369esbmTJlMpydnQ1vb2+jSJEiRrt27YxFixbFO/f169eNLl26GDly5DCcnZ1T5HnYunWr8f777xtZs2Y1nJ2djfTp0xvFixc3/u///s84e/ZsvHFXrVr1iX3OnTvXqFatmpE2bVrD2dnZyJ49u9G2bVvjyJEj8epu3LjR6NWrl/HGG28YmTNnNlxcXIzMmTMbFSpUMH788Ufj7t275rqRkZHGlClTjPfff98oUKCA4eXlZbi7uxu5c+c2mjVrZqxbty7BmGx5TRiG8cRrG/v/YGBgYLyyadOmGaVKlTI8PDzM/cS+lk+fPp3ge8fjVq5cadSvX9/w9vY2nJycjMyZMxvvvPOOsX379ifGtG7dOqNmzZrma1SmTBlj1qxZTzzn4cOHDUmGh4eHcfPmzSfWB+wtIiLCkBTv/dLWOi+7uGNMznhT+hol1t/r8Hzg5ZfYfPe///4zBg0aZOTPn99wc3MzfHx8jCZNmhg7d+5McL4U9/jdu3eNfv36Gf7+/oaLi4uRKVMmo23btsa5c+esxhIbh7U5R0Ji5/dt2rRJcpvY+femTZuslkdHRxtFixaNN7cBAAAAgJeRyTAMI5n5KQB4JVWrVk0bNmxQYGBgsvdzGDx4sEaNGqXOnTvrp59+StkAgWcgMjJSLi4uioiIkLOzc7LrvOzijlGSzeNN6WuUWH+vw/MBAAAAAABebM9lTyYAeJ2EhoZq4sSJcnBwMC+ZBwAAAAAAAACvmmTvyQQAsDRgwABdvHhRa9eu1a1bt9S1a1eb9uICAAAAAAAAgJfJK5Nkunbtmvr27Zvk+h07dlRAQMAzjChlHTlyRKNHj05y/QEDBqhAgQLPMKJX0+jRo3XkyJEk1S1QoIAGDBjwjCPCy2TevHk6d+6cMmfOrF69etn0/ywAAAAAAAAAvGxemSTT3bt39csvvyS5frVq1V6qJFNYWJhN42vbti1JpmRYtWqVNmzYkKS6VatWJcn0igoKCkpWuzNnzqRoHAAAAAAAAADwIjMZhmHYOwgAAGBfkZGRcnFxUUREhJydnZNd52UXd4ySbB5vSl+jxPp7HZ4PAAAAAADwYnOwdwAAgOfn4sWL+uCDD+Tt7S13d3cVLVpUO3fuTLRNUFCQSpUqJVdXV+XJk0ezZs2yKJ88ebKKFSsmT09PeXp6qkKFClq5cqXVvgzDUL169WQymbR48WKLsh49eqh06dJydXVViRIlnmKUAJCybHmfi3Xr1i1169ZNvr6+cnV1Vb58+bRixQpz+X///adevXrJz89P7u7uqlixonbs2GHRx9ChQ1WgQAGlSpVK6dKlU61atbR9+3Zz+ZkzZ9ShQwf5+/vL3d1duXPn1pAhQ8xJUgAAAAAAnrVXZrk8AEDibt68qUqVKql69epauXKlMmbMqOPHjytdunQJtjl9+rQaNGigrl276rffftO6devUsWNH+fr6qk6dOpKkbNmyafTo0cqbN68Mw9Avv/yit956S3v27FHhwoUt+vvuu+9kMpkSPF/79u21fft27du3L2UGDQApwJb3OUmKiIjQm2++KR8fHy1YsEBZs2bV2bNnlTZtWnOdjh076sCBA/r111+VJUsWzZkzR7Vq1dKhQ4eUNWtWSVK+fPk0YcIE5cqVS/fv39f48eNVu3ZtnThxQhkzZtSRI0cUExOjn376SXny5NGBAwfUqVMn3bt3T2PHjn1elwcAAAAA8BpjuTwAeE0MGDBAW7Zs0aZNm5Lcpn///lq+fLkOHDhgPtaiRQvdunVLq1atSrBd+vTpNWbMGHXo0MF8LCQkRA0bNtTOnTvl6+urRYsWqUmTJvHaDh06VIsXL1ZISEiS48TTY7m8R1guD0ll7X0u1pQpUzRmzBgdOXLE6nNz//59pUmTRkuWLFGDBg3Mx0uXLq169epp5MiRVs95584deXl5ae3atapZs6bVOmPGjNHkyZN16tSpZI4MAAAAAICkY7k8AHhNLF26VGXKlNE777wjHx8flSxZUtOmTUu0zdatW1WrVi2LY3Xq1NHWrVut1o+Ojta8efN07949VahQwXw8PDxcLVu21MSJE5U5c+anHwwA2ElC73NxLV26VBUqVFC3bt2UKVMmFSlSRF9++aWio6MlSVFRUYqOjpabm5tFO3d3d23evNlqnxEREZo6daq8vLxUvHjxBOO7ffu20qdPn8zRAQAAAABgG5JMwCsiZ86cMplM8fbLeVy1atVkMpk0dOjQ5xLX83TmzBmZTKYnPl7XO2ROnTqlyZMnK2/evFq9erU++ugj9ejRQ7/88kuCbcLCwpQpUyaLY5kyZdKdO3d0//5987H9+/crderUcnV1VdeuXbVo0SIVKlTIXN67d29VrFhRb731VsoPDACegye9z8V16tQpLViwQNHR0VqxYoU+//xzjRs3znyHUpo0aVShQgWNGDFCly5dUnR0tObMmaOtW7cqNDTUoq+///5bqVOnlpubm8aPH681a9YoQ4YMVs974sQJ/fjjj+rSpUvKDv4pFS9eXCaTSa6urrp+/bq9w0mWqKgozZkzR++8845y5sxpfi1kzpxZNWrU0BdffGFx129csXO0M2fOPN+gAQAAAOA5YE8mAK+kZs2aKXXq1FbLntc3vM+cOSN/f3/5+fm9EB8sxcTEqEyZMvryyy8lSSVLltSBAwc0ZcoUtWnT5qn6zp8/v0JCQnT79m0tWLBAbdq00YYNG1SoUCEtXbpU69ev1549e1JiGABgF4m9zz0uJiZGPj4+mjp1qhwdHVW6dGldvHhRY8aM0ZAhQyRJv/76q9q3b6+sWbPK0dFRpUqV0vvvv69du3ZZ9FW9enWFhITo2rVrmjZtmt59911t375dPj4+FvUuXryounXr6p133lGnTp2e3YWw0Y4dO8z77EVERGjOnDnq2bNnip5j6NChGjZsmIYMGfJMvkSzZ88evfPOOzp58qRMJpMKFSqkkiVLyt3dXdeuXdPOnTsVGBioESNGqFevXho/fnyKxwAAAAAALyqSTABeSWPHjlXOnDntHcYLxdfXN96HoQULFtTChQsTbJM5c2ZdvnzZ4tjly5fl6ekpd3d38zEXFxflyZNH0qM9RXbs2KHvv/9eP/30k9avX6+TJ09abHgvPUoEVq5cWUFBQU83MAB4DhJ7n3ucr6+vnJ2d5ejoaD5WsGBBhYWFKSIiQi4uLsqdO7c2bNige/fu6c6dO/L19dV7772nXLlyWfSVKlUq5cmTR3ny5FH58uWVN29eTZ8+XQMHDjTXuXTpkqpXr66KFStq6tSpz+gKJM/06dMlSVmzZtXFixc1ffr0FE8yPUu7du1SlSpVFB4eroYNG+rbb79V3rx5LerExMRo3bp1+uqrr3T48GE7RQoAAAAA9sFyeQDwmqhUqZKOHj1qcezYsWPy8/NLsE2FChW0bt06i2Nr1qxJcB+SWDExMXr48KEkacCAAdq3b59CQkLMD0kaP368Zs6cmYyRAID9xX2fe1ylSpV04sQJxcTEmI8dO3ZMvr6+cnFxsaibKlUq+fr66ubNm1q9evUTlxV9/LwXL15UtWrVVLp0ac2cOVMODi/O9D48PFy///67pEd3bqVOnVr79+/Xjh077BxZ0kRGRuqdd95ReHi4mjdvriVLlsRLMEmSg4OD3nzzTa1fv14jRoywQ6QAAAAAYD8vzl+hAOxiyJAhMplMie7f8O+//8pkMilr1qyKioqSJAUFBclkMqlatWoKDw/XoEGDlCdPHrm5uSlLlizq0KGDLl68mGCfN2/e1JAhQ1SiRAmlSZNGHh4eKlq0qEaOHKnw8PB49YcOHWreS+rcuXPq0KGDsmfPLmdnZ7Vt29bmcf/333+aNm2a3n77beXNm1epUqVSqlSpVLRoUX322We6deuW1XahoaHq2bOn8uXLJzc3N3l4eCh79uyqWbOmxo4da67Xtm1b+fv7S5LOnj0bb18oe+jdu7e2bdumL7/8UidOnNDcuXM1depUdevWzVxn4MCBat26tfnnrl276tSpU/q///s/HTlyRJMmTdKff/6p3r17W7TZuHGjzpw5o/3792vgwIEKCgpSq1atJD26G6pIkSIWD0nKkSOH+RpJj/YSCQkJUVhYmO7fv29OSEVERDzrSwMAiXrS+1zr1q0t7iz66KOPdOPGDfXs2VPHjh3T8uXL9eWXX1q8365evVqrVq3S6dOntWbNGlWvXl0FChRQu3btJEn37t3ToEGDtG3bNp09e1a7du1S+/btdfHiRb3zzjuS/pdgypEjh8aOHaurV68qLCxMYWFhz/HqJGz+/Pm6c+eOihQpourVq+u9996T9L+7mx73pL2L2rZtG2//SZPJpGHDhkmShg0bZvG79vH5wY0bNzRo0CAVLlxYHh4eSpMmjUqXLq1vvvnGYp/BWL/99ptOnz4tV1dXTZo0KUkJvLJlyz6xztOMN1ZUVJSmTJmiihUrysvLS25ubsqbN6969OiR4Pwr7hxk4cKFCggIkKenp1KlSqVKlSppxYoVSY4dAAAAAGKxXB7wmvvoo480evRo/fbbb/r666/jLWkmSRMnTpQkdenSRU5Olm8bERERqlmzpvbt26dq1aqpVKlS2rx5s2bMmKEVK1Zo48aN8b71e+jQIdWtW1fnz5+Xr6+vAgIC5OzsrH///Veff/65Fi5cqKCgIHl5ecWL5fjx4ypZsqRcXFxUqVIlGYaR4Aboidm7d686d+6sjBkzKn/+/CpdurRu3rypXbt26csvv9Sff/6pbdu2ydvb29wmLCxMZcqU0aVLl5QjRw7VrVtXbm5uunTpkkJCQrRr1y717dtXkhQQEKC7d+9q4cKFSpUqlZo3b25zjCmtbNmyWrRokQYOHKjhw4fL399f3333nflDUulREu3cuXPmn/39/bV8+XL17t1b33//vbJly6aff/5ZderUMde5cuWKWrdurdDQUHl5ealYsWJavXq13nzzTZvi69ixozZs2GD+uWTJkpKk06dPs/QhALt60vvcuXPnLBIQ2bNn1+rVq9W7d28VK1ZMWbNmVc+ePdW/f39zndu3b2vgwIG6cOGC0qdPr2bNmmnUqFFydnaWJDk6OurIkSP65ZdfdO3aNXl7e6ts2bLatGmTChcuLOnRnaUnTpzQiRMnlC1bNouYDcN41pfliWKTSe3btzf/d/r06Zo3b57Gjx9vsexqcrVp00YhISHau3evihcvrhIlSpjLAgICzP8+deqUatSoobNnzypjxoyqX7++IiMjFRgYqP79++uPP/7Q2rVrlS5dOnObJUuWSJLq1KmjjBkzPnWsKeXhw4dq2LCh1q5dKzc3N1WvXl2enp4KDg7Wjz/+qN9//12rV69WqVKlrLYfMmSIRowYoYoVK6p+/fo6cuSIgoOD1bBhQy1cuFBNmzZ9ziMCAAAA8FIzALwS/Pz8DEnGzJkzE61XtWpVQ5IxZMgQ87FWrVoZkoxvv/02Xv2rV68arq6uhrOzsxEaGmo+HhgYaEgyJBl58uQxzp49ay67f/++0axZM0OSUb58eYv+wsPDjdy5cxuSjMGDBxsPHz40l927d894//33DUlGu3btLNoNGTLEfL4PPvjAePDgQbxYT58+ba5z+vTpRK/D+fPnjbVr1xrR0dEWx+/du2e0bt3akGR8/PHHFmXDhg0zJBmdO3c2YmJiLMoiIiKMtWvXWo3Hz88v0ViAF0FERIQhyYiIiHiqOi+7uGNMznhT+hol1t/r8Hzg5XX06FFDkuHs7GxcuXLFfLxAgQKGJGP27Nnx2sTOZRL6Hd6mTRurc53YOULcuc3jypUrZ0gyGjdubNy9e9d8/MqVK0apUqUMSUbLli0t2mTPnt2QZIwYMeLJA05EQuNK7nj79+9vSDJy585t0TYiIsLo0KGDIcnw9/e3mGMZhmGeI6VNm9bYtm2bRVnsNcyXL19yhwkAAADgNcVyecArpl27dvGWZov7iHunSKzYDbgnT54c75vPP//8sx4+fKjmzZsrc+bMVs85duxY5ciRw/yzm5ubJk2aJA8PD23btk3BwcHmsl9++UUnT55Uw4YNNWLECIu9KTw8PDR16lT5+Pjo119/1c2bN+OdK3369JowYYJcXV0TvQ7+/v5Wxz906FBJUrZs2VSzZs14S994eHho8uTJcnJy0vz58y3KLl++LEmqW7duvCXvnJ2dVbNmzURjAgDgdTFjxgxJUuPGjS3uAoq9qymhJfOehc2bN2v79u3meUaqVKnMZRkzZtTUqVMlSfPmzdOFCxfMZdeuXTPXseaPP/5Q27Zt4z1i2z0LDx48MN9hPn78eIs7fZ2dnfXDDz8oU6ZMOn36tBYsWGC1j+HDh6tcuXIWxwYOHCgvLy8dO3ZM58+ff2bxAwAAAHj1sFwe8IqpVKmS8uTJk2D5qlWrzMmSWGXLllWFChW0detWrV69WnXr1pX0aHPxKVOmSJK6d+9utb+0adOqcePG8Y77+Piobt26+uuvvxQUFKSKFStKkpYvXy5J5n0ZHpc6dWqVKVNGK1as0I4dO1S7dm2L8lq1alldRu9xzZo1U+rUqeMdj7uMjiQFBwdr06ZNOnfunMLDw81JNhcXF129elU3b940L53zxhtvaNKkSRowYIAMw1Dt2rWtngMAgNdZVFSUfvnlF0n/SyrFat26tQYNGqSNGzfq5MmTyp079zOPJygoSNKjL4lkypQpXnnp0qVVvHhx7d27Vxs2bLBYRjYxO3bsMI8zrqFDhyZrKd+k2Llzp+7evav06dOrUaNG8co9PDzUokULff/99woMDFTLli3j1bHWztXVVbly5dKePXt08eJFZc+e/ZnEDwAAAODVQ5IJeMV07Ngx3kbXcVWrVi1ekkmSevTooa1bt2rChAnmJNPff/+ts2fPqmTJkuYk0eNiN622xt/fX5IsvhV86tQpSdKHH36oDz/8MNGxXL161er5kmLs2LGJ1r1y5YqaNWumzZs3J9rPnTt3zEmmDz/8UGvWrNFvv/2mZs2aydHRUYUKFVJAQICaN2+uGjVqJCm25DIMQ1FRUc/0HHh9RUZG2jsEJBPPHZ4lJyenBH/PJ2T58uUKCwtT1qxZLfbwk6RMmTKpfv36Wrp0qWbMmKFRo0alZLhWXbx4UdL/5iXW5M6dW3v37jXXlaQMGTLo/PnzVucj0qO5xtixY80/Ozk5KTo6OoWiti6pY4lb93Fx7z6Py9PTU9Kju6UAAAAAIKlIMgGQJDVv3lx9+/bVypUrdfr0afn7+5uXY0noLqakirsEX0xMjKSEv00cl5+fX7xjKbFJuPQoGbd582ZVqFBBw4YNU/HixZUuXTrzhutZsmRRaGioRewODg6aM2eOBg0apOXLl2vLli3asmWLJk+erMmTJ6tRo0ZatGiRHB0dUyTGx0VFRVksLwikNE9Pz3hLSOLF5eDgIE9PT4ulv4CUFhERYf7dmFSxS+E9ePBAVatWjVcem/yYNWuWhg8fnuTfm7FziOelVKlSOn/+vHbu3PlczxvrWY2X93kAAAAAKYkkEwBJj759+9FHH2nw4MGaNGmSOnXqpDVr1ih9+vR6//33E2x35syZJ5Zly5bNfCx79uw6cuSIOnTooObNm6dU+Da5d++eVqxYIQcHB61YsUJp06aNVx4WFpZg+0KFCqlQoULq16+fDMPQ+vXr1bJlSy1btkyzZ89Wu3btnkncTk5OioiIeCZ9A9KjDx6fVZIUKc/R0VE3btx47h+84/Xi5GTbnwuhoaFasWKFJOn69evasmVLgnUvXbqkVatWqUGDBpJk/iLFf//9Z7X+2bNnbYolVtasWSX9725qa2LLYutKj/aTWrJkiVavXq1r166l+BJ4yRlvbHynT59OsF9rYwEAAACAZ4UkEwCzLl26aOTIkZoxY4bu3LkjwzDUoUOHRO8eunXrlpYtWxZvff+rV69q1apVkh4t0RerXr16WrNmjf7880+7JZlu376t6OhopU2bNl6CSZLmzJljcQdTYkwmk2rWrKmWLVvqu+++U0hIiLks9sOjlFrizmQy2fxtcgCvNkdHRxKDeKHMmjVL0dHRKleunLZt25Zgvf79++ubb77R9OnTzUmmrFmz6vjx4zp8+LCKFi1qUT8sLEy7d++22teTft/GzkNi96V8/E7qPXv2KCQkRA4ODqpSpYr5+AcffKDhw4fr7Nmz6tatm+bNm2fz0oGJSc54y5Qpo9SpU+vGjRtaunRpvH0x79+/r3nz5kmSqlevnmKxAgAAAEBCWCsBgFmGDBnUsmVL3bhxQ1OnTpWDg4M+/vjjJ7b79NNPLfZdevjwobp166Z79+7pjTfeUKVKlcxlnTt3lp+fn+bPn6/+/ftb/fZuWFiYpk2bljKDsiJTpkxKly6dbt26pV9//dWibNu2bRo4cKDVdrNnz9auXbviHf/vv//Mm4rHXeIvY8aMcnFxUVhYmG7cuJFyAwAA4AU1Y8YMSVKbNm0Srde6dWtJj/Z/jN3zqFatWpKkr7/+Wrdu3TLXvXr1qlq3bq27d+9a7Sv2jumDBw9aLQ8ICFC5cuV0//59denSReHh4eaya9euqUuXLpKkFi1aKHv27OYyFxcXzZ8/X25ubvrzzz/VtGlTnThxwuo5goODk/wFlVjJGa+bm5u6desm6dH8K+7dTpGRkerZs6fCwsLk7+9vty/zAAAAAHi9cCcTAAs9evQwf0DUoEED5cyZM9H6FSpUUExMjPLnz68aNWrIw8NDmzdv1qVLl+Tj46PZs2db1E+VKpWWL1+uhg0b6ptvvtHUqVNVrFgxZcuWTeHh4Tp27JgOHz4sHx8fderU6ZmM0dHRUV988YV69+6t1q1ba+LEicqVK5fOnTun4OBgffDBB9q4cWO8ZWr++usvtWnTRlmyZFGJEiWULl063bx5U1u2bNHt27dVpEgRi5idnZ3VuHFjLViwQCVKlFBAQIA8PDwkST///PMzGRsAAPayYcMGnThxQq6urmrRokWidQsXLqxSpUpp9+7dmj17tj799FN169ZN06ZN0+7du5U/f35VqFBB9+7d044dO5QjRw41adJEixcvjtdXnTp1lCpVKi1evFgBAQHKmzevHB0dValSJfMStnPnzlWNGjW0ZMkS+fv7q0qVKoqMjFRgYKDu3LmjUqVKacKECfH6Llu2rDZt2qR3331XS5Ys0dKlS1W4cGHlzZtXqVKl0u3bt7Vv3z7znKFRo0ZJXlYvueMdNmyYdu7cqXXr1qlgwYKqXr260qRJo61bt+rcuXPy9vbW/Pnz2ccRAAAAwHPBnUwALBQvXlyZM2eWJHXv3v2J9V1cXLRu3Tp169ZNBw8e1OLFixUdHa22bdtq586dyp8/f7w2hQsX1r59+/TNN9+oYMGC2rdvn+bPn6/t27crVapU6tu3rxYtWpTiY4urV69eWrx4sSpWrKijR49q2bJlevjwoSZOnKhffvnFaptPP/1UvXr1UrZs2bR7927Nnz9fu3fvVqFChfTjjz9q27ZtSpMmjUWbn376SV26dJHJZNKCBQs0ffp084boAAC8SmJ/vzVq1Ejp0qV7Yv3Yu5li26VNm1ZbtmwxH1+5cqVOnjypzp07Kzg4WF5eXlb7yZQpk1auXKlatWrp0KFDmj17tqZPn64NGzaY6+TKlUu7d+/WwIED5e3trb///ltr1qxR7ty5NXr0aG3evDnBmMuUKaOjR4/ql19+UdOmTXXnzh2tWrVKf/75p7Zv3y4/Pz8NHDhQ+/fv19KlS5U6deokXa/kjtfV1VWrVq3SpEmTVLx4cW3atEmLFi2Ss7OzPvnkE+3du1elS5dOUgwAAAAA8LRMhq3rOgB4pa1du1Zvvvmm8ufPr8OHDye490BQUJCqV6+uqlWrmpeKA/Bqi4yMlIuLiyIiIl7Z/cHijlGSzeNN6Wv0OlxzAAAAAADw8uJOJgBm0dHRGjJkiCSpT58+Kbq5NQAAAAAAAADg1cKeTAA0c+ZMbdy4UTt37tSBAwdUtGhRtW/f3t5hAQAAAAAAAABeYNzJBEAbNmzQrFmzdOHCBTVt2lR///23nJzIQQMAAAAAAAAAEsaeTAAAIEleh/2B2JMJAAAAAAAg6biTCQAAAAAAAAAAADYjyQQAr4mhQ4fKZDJZPAoUKJBom++++0758+eXu7u7smfPrt69e+vBgwdW644ePVomk0m9evWyOP7gwQN169ZN3t7eSp06tZo1a6bLly9b1Fm3bp0qVqyoNGnSKHPmzOrfv7+ioqKearwAkFImT56sYsWKydPTU56enqpQoYJWrlyZaBvePwEAAAAArwOSTADwGilcuLBCQ0PNj82bNydYd+7cuRowYICGDBmiw4cPa/r06frjjz80aNCgeHV37Nihn376ScWKFYtX1rt3by1btkzz58/Xhg0bdOnSJb399tvm8r1796p+/fqqW7eu9uzZoz/++ENLly7VgAEDUmbQAPCUsmXLptGjR2vXrl3auXOnatSoobfeeksHDx60Wp/3TwAAAADA64I9mQDgNTF06FAtXrxYISEhSarfvXt3HT58WOvWrTMf+/TTT7V9+3aL5NTdu3dVqlQpTZo0SSNHjlSJEiX03XffSZJu376tjBkzau7cuWrevLkk6ciRIypYsKC2bt2q8uXLa9CgQVqzZo127Nhh7nPZsmV69913deXKFaVJk+bpB48U8TrsD8SeTEiq9OnTa8yYMerQoUO8Mt4/AQAAAACvC+5kAoDXyPHjx5UlSxblypVLrVq10rlz5xKsW7FiRe3atUv//vuvJOnUqVNasWKF6tevb1GvW7duatCggWrVqhWvj127dikyMtKirECBAsqRI4e2bt0qSXr48KHc3Nws2rm7u+vBgwfatWtXsscKAM9CdHS05s2bp3v37qlChQpW6/D+CQAAAAB4XZBkQorImTOnTCaTZs2aZe9Q4jlz5oxMJpNy5sz5zM8Vu+fN0KFDn/m58PSqVasmk8mkoKAge4fyXJQrV06zZs3SqlWrNHnyZJ0+fVqVK1fWf//9Z7V+y5YtNXz4cAUEBMjZ2Vm5c+dWtWrVLJZ7mjdvnnbv3q2vvvrKah9hYWFycXFR2rRpLY5nypRJYWFhkqQ6deooODhYv//+u6Kjo3Xx4kUNHz5ckhQaGpoCIweAp7d//36lTp1arq6u6tq1qxYtWqRChQpZrcv7p6XixYvLZDLJ1dVV169ft3c4SRY7h3z8kSpVKhUsWFDdu3fX6dOn7R3mSy0oKEgmk0nVqlWzdygAAAAAkokkE5BE/BGMl129evX0zjvvqFixYqpTp45WrFihW7du6c8//7RaPygoSF9++aUmTZqk3bt366+//tLy5cs1YsQISdL58+fVs2dP/fbbb/G+SW+L2rVra8yYMeratatcXV2VL18+87f9HRz4NQXgxZA/f36FhIRo+/bt+uijj9SmTRsdOnTIal3eP/9nx44d2rdvnyQpIiJCc+bMSfFzPI8v+TRr1kxt2rRRmzZtVLFiRV28eFETJ05UsWLFtGnTpmd2XgAAAAB40TnZOwDgWcuaNasOHz78XPay6N69u1q0aKEMGTI883Ph6c2ePVvh4eHKkSOHvUOxi7Rp0ypfvnw6ceKE1fLPP/9cH374oTp27ChJKlq0qO7du6fOnTvrs88+065du3TlyhWVKlXK3CY6OlobN27UhAkT9PDhQ2XOnFkRERG6deuWxbfxL1++rMyZM5t/7tOnj3r37q3Q0FClS5dOZ86c0cCBA5UrV65nM3gAsJGLi4vy5MkjSSpdurR27Nih77//Xj/99FO8urx//s/06dMlPZqPXbx4UdOnT1fPnj3tHJXtxo4da3FXfGhoqOrXr6+QkBC1adNGx44dk5MTf1rZ6o033tDhw4fl4eFh71AAAAAAJNOL8RVH4BlydnZWgQIFlDt37md+rgwZMqhAgQIkmV4SOXLkUIECBV7bDzbu3r2rkydPytfX12p5eHh4vG/COzo6SpIMw1DNmjW1f/9+hYSEmB9lypRRq1atFBISIkdHR5UuXVrOzs5at26duY+jR4/q3Llz8fYyMZlMypIli9zd3fX7778re/bsFh/AAsCLJCYmRg8fPrRaxvvnI+Hh4fr9998lSb/++qtSp06t/fv3a8eOHXaO7On5+vpq/PjxkqTTp09r586ddo7o5eTh4WHeawwAAADAy4kkE+zmwoUL+uSTT5Q3b165ubnJy8tLlSpV0k8//aTo6GirbQzD0IwZM1SmTBl5eHjI29tb9erVU3BwcILL2SW2J9Px48fVvn17+fv7y9XVValTp5afn58aNGigmTNnmutVq1ZN1atXlyRt2LDBYl3+uP0+abmWY8eO6eOPP1b+/Pnl4eEhT09PFSpUSB9//LEOHDiQ5GsXe25JmjlzpipUqCAvLy+ZTCadOXPGXO/SpUvq06ePChYsKA8PD6VJk0Zly5bVhAkTFBUVZbXve/fu6fPPP1fevHnl6uqqLFmyqH379rp48WKC44t7/Ny5c+rQoYOyZ88uZ2dntW3b1qLuggULVLduXWXMmFEuLi7KmjWrPvjggwSXHNq1a5fee+89ZcuWTS4uLvL09FSuXLnUrFkzLVmyxKJuTEyMpk6dqkqVKilt2rRydnaWj4+Pihcvrk8++cTi2kiJ78kUFRWlKVOmqGLFivLy8pKbm5vy5s2rHj166OLFi1Zjjfu8LFy4UAEBAfL09FSqVKlUqVIlrVixwmq756Vv377asGGDzpw5o+DgYDVt2lSOjo56//33JUmtW7fWwIEDzfUbNWqkyZMna968eTp9+rTWrFmjzz//XI0aNZKjo6PSpEmjIkWKWDxSpUolb29vFSlSRJLk5eWlDh06qE+fPgoMDNSuXbvUrl07VahQQeXLlzefa8yYMdq/f78OHjyoESNGaPTo0frhhx/MH8oCgD0NHDhQGzdu1JkzZ7R//34NHDhQQUFBatWqlSTePxMyf/583blzR0WKFFH16tX13nvvSfrf3U2Pi93j8/Hf17Hatm0bbw9Qk8mkYcOGSZKGDRtmMUd7fA5y48YNDRo0SIULFzbPi0qXLq1vvvlG9+/ft3l8pUuXNv87Nua489Hw8HB98cUX5nnY43PRefPmqWbNmkqfPr1cXV3l5+en9u3b69ixYwme8+zZs2rbtq0yZ85snpsMGTJEDx48SHBeE/d4SEiI3n77bWXIkEGurq4qVKiQxo0bJ8MwrJ4vOfOhpM6vH79ej7NlDggAAADAfljTAXaxY8cO1a1bVzdu3FCOHDnUpEkT3b59W0FBQQoODtaiRYu0dOlSubi4WLTr1q2bJk+eLAcHB1WuXFm+vr7av3+/qlSpol69etkUw4EDB1SpUiXduXNH+fPnV8OGDeXo6KgLFy5o48aNunjxotq1aydJqlu3rtzc3LR69WplypRJdevWNfeT1LuW5s6dq/bt2+vhw4fKkSOH6tevr5iYGJ06dUpTpkyRj4+P+YOlpPrkk080adIkVaxYUQ0aNNCpU6fMSY6NGzeqSZMmunnzpnLmzKk333xTDx8+1L///qtPPvlEy5Yt099//22xjOC9e/dUvXp17dixQ6lTp1bt2rXl7u6uVatWafny5eZ9HhJy/PhxlSxZUi4uLqpUqZIMwzBfn6ioKLVq1Up//vmnXF1dVbp0aWXNmlXHjh3Tb7/9pr/++kt//fWXxbVdt26d6tWrp8jISBUvXlwVKlQwb2y+fPlyRUdH66233jLX79ixo2bOnCk3NzcFBAQoY8aMunHjhk6dOqUJEyaoZs2aVpONj3v48KEaNmyotWvXys3NTdWrV5enp6eCg4P1448/6vfff9fq1asT/Jb4kCFDNGLECFWsWFH169fXkSNHFBwcrIYNG2rhwoVq2rTpE2N4Fi5cuKD3339f169fV8aMGRUQEKBt27YpY8aMkqRz585ZfPN+8ODBMplMGjx4sC5evKiMGTOqUaNGGjVqlE3nHT9+vBwcHNSsWTM9fPhQderU0aRJkyzqrFy5UqNGjdLDhw9VvHhxLVmyRPXq1Xv6QQNACrhy5Ypat26t0NBQeXl5qVixYlq9erXefPNNSbx/JiQ2mdS+fXvzf6dPn6558+Zp/Pjxcnd3f+pztGnTRiEhIdq7d6+KFy+uEiVKmMsCAgLM/z516pRq1Kihs2fPKmPGjKpfv74iIyMVGBio/v37648//tDatWuVLl26JJ/7zp075n+7urpalMUmfQ4dOqQqVaqoePHiun79uqRHX5pq27atZs+eLScnJ1WpUkU+Pj7avXu3Zs6cqT/++EMLFy60mBNJ0qFDh1S1alVdu3ZNWbJk0VtvvaV79+5p3LhxWr9+vWJiYhKNd/Xq1fr222+VO3duvfnmmwoNDdXmzZvVt29fnT9/Xt99951F/eTMh2yZXyfG1jkgAAAAADsygBTg5+dnSDJmzpz5xLoPHjww1+/atasRERFhLjt58qSRM2dOQ5IxaNAgi3ZLliwxJBmpU6c2tmzZYlE2btw4Q5IhyahatapF2enTpw1Jhp+fn8Xxdu3aGZKMkSNHxosxPDzc2LBhg8WxwMBAq/3HNWTIEEOSMWTIEIvjO3fuNJydnQ2TyWT88MMPRnR0tEX5mTNnjJ07dybY7+Nix+rp6Wls3bo1XnloaKjh7e1tmEwmY9KkSRbnu3btmlGjRg1DkjFs2DCLdr179zYkGYUKFTIuXbpkPn7//n2jefPm5vM+Pr7YcUsyPvjgA+PBgwfxYho0aJAhyShXrpxx6tQpi7L58+cbjo6ORrp06YybN2+aj1evXt2QZMyZMydef7du3bIY+9mzZw1JRrZs2YzQ0NB49Q8dOmScPXvW4ljVqlUNSUZgYKDF8f79+xuSjNy5cxunT582H4+IiDA6dOhgSDL8/f2Nhw8fWrSLvQZp06Y1tm3bZvUa5cuXL15swMsiIiLCkGTxvv2qiTvG5Iw3pa/R63DN8Wo6evSoIclwdnY2rly5Yj5eoEABQ5Ixe/bseG1i54dxf/fG1aZNG6vzzYTmX3GVK1fOkGQ0btzYuHv3rvn4lStXjFKlShmSjJYtW1q0iZ1DJhTThAkTzOWxc5vY+aIko1ixYlbnJJMnTzYkGRkyZDD27NljPh4TE2MeS9q0aS2um2EY5jhbtGhhMde6cOGCkT9/fvN5H5/XxM53JBlTpkyxKFu3bp1hMpkMR0dH4/z58xZlyZkPpdT82pY5IAAAAAD7Yrk8PHfz58/X2bNnlSVLFn333XcWd9LkypVLY8eOlST9+OOPevDggbns+++/l/To7p2KFSta9NmnTx+VLVvWpjguX74sSVbvznF3d1eVKlVs6i8xI0eOVGRkpLp3765PPvkk3j4Nfn5+FkuuJFXfvn0tlsyJ9d133+n69evq1q2bPvroI4vzeXt7a/bs2XJ2dtaECRPMy6Pcv39f06ZNk/Tom9Nx9+lxc3PTpEmTnrh3Ufr06TVhwoR43+a9ceOGxo8fLzc3Ny1cuFD+/v4W5c2bN1eXLl108+ZNzZkzx3w8sefIy8vLYuyxdUuVKmWxIXqsggULJmm9/wcPHmjixImSHl2HuHc+OTs764cfflCmTJl0+vRpLViwwGofw4cPV7ly5SyODRw4UF5eXjp27JjOnz//xDgAAHiZzZgxQ5LUuHFj8x2z0v/uakpoybxnYfPmzdq+fbs8PDw0depUpUqVylyWMWNGTZ06VdKj5esuXLjwxP5CQ0M1efJkDRgwQNKjMT4+t5GkCRMmWJ2TxM51v/jiC4s7r0wmk4YMGaJixYrp1q1b5nmZJG3atEm7d+9W6tSpNXHiRIu5VtasWTVu3Lgnxv3222+rS5cuFsdq1KihOnXqKDo6WoGBgebjyZ0PpdT82pY5IAAAAAD7IsmE5y52nfgWLVrES0ZIj/4ATpcunf777z/t2rVL0qOl1oKDgyXJvP/B41q2bGlTHG+88YYk6aOPPtLq1astElopKTo6WmvWrJEkde7cOUX7bt68udXjy5cvlyTz3gePy5o1q/LmzaurV6/q+PHjkh6te3/37l1lyJBBtWvXjtcmY8aM5mWBElKrVi15eXnFOx4YGKj79++rUqVKypo1q9W2sWvxxz7P0v+eo1atWmnz5s0J7iMlSQUKFFCaNGm0YsUKjRo1SqdPn0401oTs3LlTd+/eVfr06dWoUaN45R4eHmrRooV5XNZYa+fq6qpcuXJJUoJ7GAAA8CqIiorSL7/8Iul/SaVYrVu3lpOTkzZu3KiTJ08+l3hi555169ZVpkyZ4pWXLl1axYsXV0xMjDZs2GC1D39/f/NeT1myZNHHH3+su3fvqlatWhZ7RMXy8fFR5cqV4x2/cOGCedxt2rSJV24ymczLycWdZ8TGVbduXaVPnz5euwYNGiht2rRWY49lbX4iPfoijmQ5P0nufCil5te2zAEBAAAA2Bd7MuG5i/0D1to3PqVHf1z7+/vr5s2b5rrXrl0z/5Ga0J46SdlrJ65+/fpp8+bNWrt2rerWrStnZ2cVL15cVapUUYsWLWy+Myoh169f17179yRJ+fPnT5E+YyU05lOnTkmS1Q83Hnf16lXly5fP/M3dxK7jk67xk+JZt26dec+oxOKJ9dVXX2nfvn1auXKlVq5cKXd3d5UqVUrVqlVTq1atzB+KSFKaNGk0c+ZMtWvXToMHD9bgwYPl6+ur8uXLq27dumrZsqVSp06d6LmlJ78+JSl37twWdR+X0B1Tnp6ekpTsD1wMw+BDFthVZGSkvUN4bXHtYS9OTk5P/N39uOXLlyssLExZs2ZVnTp1LMoyZcqk+vXra+nSpZoxY4bN+1QlR1J/t+/duzfB3+3NmjVT6tSpZTKZ5ObmpuzZs6tmzZrx7lyOldCcKLZ/b29v87zAWixx60pK0jzNz89Pt27dSrDclvlJcudDKTW/tmUOCAAAAMC+SDLhlWHrByAeHh5as2aNduzYoVWrVik4OFjBwcHauXOnvv32W3388cfmZUJeVAltmB278XPz5s0tloSxxtvb2+LnxK7jk67xk+LJkyePKlWqlGgfBQoUMP87c+bM2rlzpzZs2KC1a9dqy5Yt2r59u7Zs2aIvv/xSX331lfr372+u36xZM9WqVUtLly7Vpk2btGXLFi1atEiLFi3SF198oTVr1qho0aKJnj8lPL4cYkqJioqSi4vLM+kbSCpPT89n9hpHfA4ODvL09HzieznwrERERFgsbZwUsUvhPXjwQFWrVo1XHpuUmDVrloYPHy5HR8ck9Rs7n7CHsWPH2vSFpoTmRE/raeZpz+O9O6Xm17bOAQEAAADYD0kmPHexy6XF3t1iTexSZ7F1vb295erqqocPH+rs2bMqVKhQvDZnzpxJVjxly5Y1f6syKipKixcvVuvWrTVp0iQ1b95c1atXT1a/sby9veXh4aHw8HAdPXpURYoUear+kiJ79uw6fvy4+vfvrzJlyiSpTey1Tuw6JvcaZ8+eXdKjO7msLSmTGJPJpGrVqpmX03vw4IFmzZqlbt26adCgQWrevLn5m7TSo3X6P/zwQ3344YeSpPPnz+uTTz7RkiVL1L179wSXwYkVex0SW24v9rWb0NJ/z4qTk5MiIiKe6zmBxzk4OCT5A2E8PUdHR924ccOuH67j9ebkZNufC6GhoVqxYoWkR3dzb9myJcG6ly5d0qpVq9SgQQNJMn+R4r///rNa/+zZszbFEispc8/n9bs9tv/r16/rzp07Vu9mshZLUuZpyb0+icWZ3PlQSsyvbZ0DAgAAALAPvoqM5y72D8U//vjD6rJhixYt0s2bN5UmTRqVLl1a0qMNhitUqCBJmjt3rtV+f//996eOzcnJSc2bNzcv7RISEmIui/3gw9blyhwdHc17GcXdwPlZqlevniTpzz//THKb0qVLy8PDQ1evXtXatWvjlV+7ds28t5StatasKRcXFwUFBenKlSvJ6iOWm5ubunbtqmLFiikmJkb79u1LtH727Nk1bNgwSZbPZ0LKlCmj1KlT68aNG1q6dGm88vv372vevHmS9NQJSFuZTCY5Ozvz4GHXBwmm58/R0dHuzzuP1/dh653is2bNUnR0tMqVKyfDMBJ8/N///Z+k/931JP0vWXH48OF4/YaFhWn37t1Wz/mkOVrs3HPVqlW6fPlyvPI9e/YoJCREDg4OqlKlStIHmwzZsmUzJ0asffHGMAzz8bjzjNi4Vq1apZs3b8Zrt3LlSqvHkysl50OJza9tYescEAAAAMDzQZIJz90777yjHDly6NKlS+rTp4/FBwKnT5/Wp59+Kkn65JNP5ObmZi7r0aOHJOmHH37Qtm3bLPr8/vvvtX37dpvimDRpko4ePRrveFhYmHbu3Cnp0dr2sbJlyyZJOn78uM17Y3z22WdycnLShAkTNGnSJBmGYVF+9uxZ7dq1y6Y+E9OvXz+lTZtW3377rcaNG2f17pfTp09rzpw55p89PDzUsWNHSVLv3r0tPoR5+PChunfvbt5bylaZMmXSJ598onv37qlRo0bav39/vDoPHz7U0qVLdeTIEfOxsWPH6ty5c/HqHjlyRMePH5f0v+doz549+uOPP3T//v149ZctW2ZRNzFubm7q1q2bJOnTTz+1+FZwZGSkevbsqbCwMPn7+6t58+ZP7A8AgNfJjBkzJElt2rRJtF7r1q0lSX///bd5P8ZatWpJkr7++muLvYWuXr2q1q1b6+7du1b7ip2jHTx40Gp5QECAypUrp/v376tLly4KDw83l127dk1dunSRJLVo0cJ89/Wz1LdvX0nSiBEjtHfvXvNxwzA0cuRIhYSEKG3atOrUqZO5rEqVKipevLj+++8/ffLJJxZzu0uXLpnnzyklufMhW+fXCbFlDggAAADAvlguDylqxIgRmjJlSoLlkyZNUqlSpbRgwQLVrVtXkydP1ooVK1S+fHn9999/Wr9+vR48eKA6depoyJAhFm2bNm2qzp07a+rUqQoICFDlypXl6+ur/fv36/Dhw+rdu7fGjx+f5D1rpk6dqm7dusnf319FihSRp6enrl69qk2bNun+/fuqUaOGGjdubK6fI0cOlSlTRjt37lTRokVVpkwZubm5KUOGDBo9enSi5ypbtqymT5+ujh07qlu3bvrmm29UtmxZxcTE6NSpU9q7d6+++OIL851bTytbtmxasmSJmjVrpr59++qbb75RkSJF5Ovrq9u3b+vw4cM6efKkypUrpw8++MDcbtSoUdqyZYt27dqlPHnyqEaNGnJzc9PmzZsVERGhNm3a6JdffknWvkCjR49WaGio5s6dqxIlSqh48eLKlSuXnJycdOHCBYWEhOjevXtauXKleV+mkSNHql+/fipQoIAKFiwod3d3Xbp0SZs3b1ZUVJRat26tUqVKSXqUqGvRooV5Y+js2bMrKipK+/fv19GjR+Xi4qJvvvkmSbEOGzZMO3fu1Lp161SwYEFVr15dadKk0datW3Xu3Dl5e3tr/vz57I8EAEAcGzZs0IkTJ+Tq6qoWLVokWrdw4cIqVaqUdu/erdmzZ+vTTz9Vt27dNG3aNO3evVv58+dXhQoVdO/ePe3YsUM5cuRQkyZNtHjx4nh91alTR6lSpdLixYsVEBCgvHnzytHRUZUqVVK7du0kPboTvkaNGlqyZIn8/f1VpUoVRUZGKjAwUHfu3FGpUqU0YcKEZ3FZ4unSpYuCg4P166+/qkyZMqpatap8fHy0e/duHT16VO7u7po7d64yZsxobmMymTRnzhxVrVpVv/32m4KCglSpUiWFh4crMDBQJUqUUIUKFbR169YUm58kZz5k6/w6IbbMAQEAAADYmQGkAD8/P0PSEx+BgYHmNufOnTO6detm5MqVy3BxcTHSpEljVKhQwZg8ebIRGRlp9TwxMTHGtGnTjFKlShlubm5G2rRpjdq1axsbN240Zs+ebUgy3n//fYs2p0+fNiQZfn5+Fsf//vtv46OPPjJKlixpZMyY0XBxcTGyZctmVKtWzfjll1+MiIiIeOc/e/as0bJlS8PX19dwcnKK1++QIUMMScaQIUOsxn/w4EGjQ4cOhr+/v+Hq6mp4eXkZhQoVMrp3724cPHgwSdfaMAzz9XySy5cvG59//rlRqlQpI02aNOYxVqxY0RgyZIixb9++eG3+++8/Y9CgQebnJXPmzMaHH35onD171mjfvr0hyfjpp58s2jxp3HGtWLHCePvtt42sWbMazs7ORtq0aY2CBQsaLVq0MObOnWvcu3fPXHfOnDlGu3btjCJFihjp06c3XF1dDT8/P6NevXrGokWLjJiYGHPd0NBQY/To0Ub9+vUNf39/w8PDw/D09DQKFSpkdOvWzThy5Ei8WKpWrRrvdRkrMjLSmDRpklG+fHnztcudO7fxySefGBcuXLA6tic9L4mdD8CLISIiwpBkREREWPw7Oe2B182HH35oSDKaN2+epPrfffedIckoWLCg+diFCxeM1q1bGz4+PoaLi4vh7+9v9OvXz/jvv/+MNm3aGJKMmTNnxutr48aNRq1atYx06dIZDg4OhiSjTZs2FnWuX79uDBw40ChYsKDh5uZmeHh4GCVLljRGjx5thIeHx+szdg4pyTh9+nSSxhQYGGhIMqpWrfrEunPnzjWqVatmpE2b1nB2djayZ89utG3b1uqcJW5MH374ofn65M6d2xg0aJARHh5u5MqVy5BkHD161KLNk+Yfic3jbJ0P2Tq/Tuh62TIHBAAAAGBfJsN4bN0u4CXVvn17zZw5U+PGjVOfPn3sHc4rJzIyUkWKFNGxY8e0a9cuvj0K4JUUGRkpFxcX81JUsf92dna2uX1S2wDA0zp9+rTy5MmjNGnS6MaNG3JwYFV0AAAAAM8Hf33gpXLw4MF4+wLFxMRo2rRpmjVrltzc3PT+++/bKbpXw65duxQTE2Nx7O7du+revbuOHTumYsWKkWACAAB4zu7du2d136mzZ8+qVatWiomJUZs2bUgwAQAAAHiu2JMJL5UxY8bozz//VMmSJZU1a1bdu3dPhw4d0pkzZ+To6KhJkybJ19fX3mG+1Jo1a6bw8HAVLVpUPj4+unLlikJCQnTjxg2lT59es2bNsneIAAAAr52rV6+qSJEiyp07t/LlyydPT0+dO3dOu3fv1sOHD1W8eHGNGDHC3mECAAAAeM2wXB5eKitXrtS0adO0a9cuXbt2TVFRUfLx8VGlSpXUq1cvlS9f3t4hvvR++OEHLVq0SEeOHNHNmzfl4OAgPz8/1a5dW3379lX27NntHSIAPDMslwfgRXX37l0NGzZM69ev17lz53Tr1i15eHgof/78atasmT755BN5eHjYO0wAAAAArxmSTAAAAP8fSSYAAAAAAICkY8FuAAAAAAAAAAAA2IwkEwC8pkaPHi2TyaRevXolWu/WrVvq1q2bfH195erqqnz58mnFihXm8q+++kply5ZVmjRp5OPjoyZNmujo0aMWfVSrVk0mk8ni0bVrV4s6586dU4MGDeTh4SEfHx/169dPUVFRKTZeAEgpSXn/nDZtmipXrqx06dIpXbp0qlWrlv7991+LOnfv3lX37t2VLVs2ubu7q1ChQpoyZYrV/gzDUL169WQymbR48WKLsh49eqh06dJydXVViRIlnnJ0AAAAAAAknZO9AwAAPH87duzQTz/9pGLFiiVaLyIiQm+++aZ8fHy0YMECZc2aVWfPnlXatGnNdTZs2KBu3bqpbNmyioqK0qBBg1S7dm0dOnRIqVKlMtfr1KmThg8fbv457r4R0dHRatCggTJnzqzg4GCFhoaqdevWcnZ21pdffplyAweAp5TU98+goCC9//77qlixotzc3PT111+rdu3aOnjwoLJmzSpJ6tOnj9avX685c+YoZ86c+ueff/Txxx8rS5Ysaty4sUV/3333nUwmU4Lna9++vbZv3659+/Y9/SABAAAAAEgikkwA8Jq5e/euWrVqpWnTpmnkyJGJ1p0xY4Zu3Lih4OBg8/4yOXPmtKizatUqi59nzZolHx8f7dq1S1WqVDEf9/DwUObMma2e559//tGhQ4e0du1aZcqUSSVKlNCIESPUv39/DR06VC4uLskYKQCkLFveP3/77TeLn3/++WctXLhQ69atU+vWrSVJwcHBatOmjapVqyZJ6ty5s3766Sf9+++/FkmmkJAQjRs3Tjt37pSvr2+8c/3www+SpKtXr5JkAgAAAAA8VyyXhyTLmTNnvOWuXF1dlS1bNr311lv6+++/rbYbOnRovHaPPx5f2iXu0lpjx45NMKaOHTvKZDJp6NChFseDgoLM7TNnzqx79+5ZbX/hwgVzPeB10a1bNzVo0EC1atV6Yt2lS5eqQoUK6tatmzJlyqQiRYroyy+/VHR0dIJtbt++LUlKnz69xfHffvtNGTJkUJEiRTRw4ECFh4eby7Zu3aqiRYsqU6ZM5mN16tTRnTt3dPDgQVuHCADPhC3vn48LDw9XZGSkxXtjxYoVtXTpUl28eFGGYSgwMFDHjh1T7dq1Ldq1bNlSEydOTDBR/yILCgpSp06dVKhQIaVLl07Ozs7y9vbWG2+8oe7du2vt2rUyDMOiTdu2bePNFZ2cnJQhQwZVrVpVEydOVGRkZILne9K802Qy6datW+Y21uaqjo6OSpcuncqXL68vv/xSd+/etXq+M2fOWO3fwcFB6dOnV0BAgCZOnMjyr5IePnyoQYMGKW/evHJ1dZXJZIr3xZUXSUxMjGbNmmW+o9vZ2Vnp06dXvnz51LhxY33zzTc6c+aMuf7nn38uk8mkhg0bJthnrVq1ZDKZlCpVKkVERFitM3bsWJlMJlWuXNl8LO7r+nFx/2566623Eh3T/PnzLV6nFy5ceMJVeHHMmjVLJpNJbdu2tald7P+jL/JrLVbse9Hjf9u+CBK6/i/T9X2V2Pr/Q1J/Nz7+eBFfi7Y4dOiQmjRpIh8fHzk6Or4SY3oasa+bxB5xVyxJDj5fSx7eS/Eq4E4m2KxSpUrKkyePpEcfJu/Zs0dLly7V0qVL1bt3b3377bdW22XKlEl169a1WpYjR44Ez/fVV1+pY8eOyf5ld/nyZY0bN05ffPFFstrDPs6cOSN/f3/5+flZ/AGPpzNv3jzt3r1bO3bsSFL9U6dOaf369WrVqpVWrFihEydO6OOPP1ZkZKSGDBkSr35MTIx69eqlSpUqqUiRIubjLVu2lJ+fn7JkyaJ9+/apf//+Onr0qP766y9JUlhYmEWCSZL557CwsOQOFwBSjK3vn4/r37+/smTJYpGg+vHHH9W5c2dly5ZNTk5OcnBw0LRp0yzuAu3du7cqVqz4xA+PXzTXrl1Tq1at9M8//0iSsmbNqkqVKsnLy0u3b9/WgQMHNHHiRE2cOFElS5bU7t274/WRO3duBQQESJIePHigI0eOaOPGjdq4caN+//13rVmzRu7u7gnG0KZNmwTLrN0hG3euGhkZqVOnTmn79u3avn27Zs+erU2bNiljxowJ9tmsWTOlTp1a0qPlZk+fPq3g4GBt2bJFf/75p9asWfNS3Zkb+yHR40nA5Pr88881ZswYZcqUSW+99ZY8PDyUIUOGFOnbFkmZY967d0+NGjVSYGCgJKlUqVKqUqWKHB0dderUKa1atUrLli2Th4eHunfvLkmqXr26Ro4cqU2bNik6OlqOjo4WfUZERCg4OFjSo+Txv//+a359xxV7zurVq9s8thUrVujy5cvx5lSxpk+fbnOfSBlBQUGqXr26qlatqqCgoOfWFpCkzJkzW/2dGBISor179yb4Wc3LvM/jvXv31KBBA505c0ZlypRRnTp15Ojo+FKPKaWkSpVKzZs3t1oWd0n7V9nQoUM1bNgwDRky5LVOPOLp8Tv6f0gywWYdO3a0+MZMVFSUevfurQkTJmj8+PF6//33VbZs2XjtChQooFmzZtl0Lg8PD924cUOjR4/W6NGjbY7V3d1dDx480NixY/XRRx8l+sEA8Ko7f/68evbsqTVr1sjNzS1JbWJiYuTj46OpU6fK0dFRpUuX1sWLFzVmzBirSaZu3brpwIED2rx5s8Xxzp07m/9dtGhR+fr6qmbNmjp58qRy5879dAMDgGcsOe+fcY0ePVrz5s1TUFCQRfsff/xR27Zt09KlS+Xn56eNGzeqW7du5mTU0qVLtX79eu3Zsyclh/PM3bp1SwEBATp69KgKFCigSZMmWf3A/MCBAxo/frzmzZtntZ+AgIB4c8d58+bp/fff15YtWzRhwgT169cvwThsnXdam6tu3LhRb775po4ePaqhQ4dq4sSJCbYfO3ZsvG+gBgcHq0aNGtq4caOmTp1qTki8jv78809J0qZNm5Q3b147R5O4oUOHKjAwUFmyZNHKlSvj7cF2+/ZtLVy40GL5yooVK8rV1VV37tzR7t274/09tH37dt2/f1+lSpXS7t27FRQUFC/JFB0dbZ5D2ZpkKlOmjHbu3KnZs2db/f/i/PnzWrNmjcqWLZvsZLk9NW3aVOXLl5eXl5e9Q3lmunfvrhYtWtgl+ZpcWbNm1eHDh83LauPFlNBnMUOHDtXevXuT9VnNi27Hjh06c+aMKlasqC1bttg7nBdKhgwZXrnnG4D9sVwe/l97dx5ew/X/Afx9k9zs+4ZYggSxJyE0C0FCiERCkERohBItaZUSVRq6qrWbWlq7qlJVjaKKRBDEXmrfEkuokBBkz+f3R56Z3ps79+beLKXf3+f1PPchM+fMnNnOnDln5pwaMzAwwLx582BpaQkASE5OrrVlJyQkQE9PD19++SXu3r2rc3wnJycMHjwY+fn5VY6dwNj/uhMnTuDvv/+Gp6cnDAwMYGBggP379+PLL7+EgYGBZBd4DRo0QMuWLZXexm3dujXu3bun0s3LhAkTsH37dqSkpKBRo0Ya09K1a1cAwNWrVwFUvF13//59pTDC3//F7qEYY/9bqpN/CubPn485c+Zg9+7dShXVBQUFmD59OhYuXIjQ0FB06NABEyZMQGRkpNhV8L59+3Dt2jVYW1uL6wUqvpgRxnF6GSUkJODSpUto3rw50tPT1VaWt2vXDitWrBC/3NBGVFQUevfuDaB2y5zqdO/eXXz7uzrr8/HxEd8W3rt3b62m7b8mKysLAF76BiYAYsNnUlKSSgMTAFhZWWHUqFHo16+fOM3Y2BivvPIKAEie08LbrdOmTYNcLpcMc+LECTx58gRGRkbw9vbWKc3Dhw+HoaEhVq1aJTl/9erVKC8vx6hRo3Ra7svCysoKbm5ukuPS/a+wt7eHm5vbf6qRSS6Xw83NjV8aYy+d/9I9hzHG/hdwIxOrFcbGxuLNu3JFcU20a9cOI0aMQEFBgeRXE9r4+OOPYWBggKVLl+LGjRu1lrbKSktLsXLlSgQGBsLe3l4cryowMBBfffWVUlhhrIHVq1fj3LlziIyMRIMGDaCvr6/0qe6jR48wffp0tG3bFqamprCwsECnTp0wd+5cFBQUSKZjz549CA0NRb169SCXy2FjY4MWLVpg+PDhSEtLUwpbVFSEefPmoVOnTrCwsIChoSHq168PLy8vTJ06FY8ePVJZfkFBARYsWIBXXnkF1tbWMDY2RqtWrTB16lQ8fPhQJbxif9HPnj3Du+++C1dXVxgZGYmf7d+5c0dl/zRr1gwAkJmZqdJPsECx3/KsrCyMHj0ajRs3hlwuV/ra7vnz55gzZw48PT1hYWEBU1NTtG3bFjNmzEBubq5KmhX7wy0tLcXcuXPRtm1bmJiYwN7eHkOHDsXFixeV4ly7dk0cv0FxrKHK2rZtC5lMhh07dqgNU1cCAgJw9uxZnD59Wvx17twZMTExOH36tEq3LkBF95hXr15FeXm5OO3y5cto0KCB2OUPEWHChAnYunUr9u3bJx47TU6fPg0AYkWBt7c3zp49i7///lsM88cff8DS0hJt2rSpyWYzxliNVSf/BIC5c+fiww8/xK5du9C5c2eleSUlJSgpKYGennJxXF9fX8xzp02bhj///FNpvQCwaNEitRXJL9q1a9ewYcMGABXptLGxqTJOly5ddFqHUOlfm2XOulyf8LKEunGZbt++jYSEBLRo0QLGxsawsrKCr68vli1bprEB8/fff0dISAgcHR1haGgIJycnREZG4vjx45LhHz9+jBkzZqB9+/YwMzODkZERnJyc4Ovri/fff18c50ooXwkql8N07cZYGNdV6HZPcVmV36Q+ceIEYmJi0KRJExgZGcHW1hZBQUFqy03nz59HUlISfH190bBhQxgaGsLOzg6BgYHil1OKtC1jCsfa0dFRp20VGlSluktJTU2Fvr4+goKC4OXlhcOHD6u8sCPE8/b21vmrSTs7OwwYMAAXLlzA4cOHleYREVavXg0TExNER0frtFx1hOOq7nxQfN5RN/3MmTMYNGgQHBwcYGJigg4dOuCLL76QPO+rGoNm+/bt8Pf3h4WFBaysrNCtWzds27atyu3Izc1FUlIS3N3dxeeE9u3b46OPPpIs0ys+fzx48ADjx49H48aNYWhoiMaNGyMhIUFpzDegYtws4dzYv3+/0jmn+PWj1JhM2sT19/eHTCbDDz/8oHY7586dC5lMhqFDh1a5T3ShaRwRxetqy5Yt8PPzg6WlJczMzODr66vxeai0tBTfffcdevToAVtbWxgZGaFZs2Z4/fXXcevWLck4ujwHC/bu3YtBgwaJzzaOjo4YOHCgyjUkyMjIwNSpU9GlSxfUr18fhoaGqFevHkJDQ7Fnzx7JOIrn7qNHjzBx4kS4uLjAyMhI5YWRffv2YciQIWjUqBGMjIzg4OAALy8vJCUlST5rA9D6GVtXwnhvqampOHDgAEJDQ+Hg4AA9PT3xulZ3nUttu5TLly8jPj4eLi4u4v2ve/fuWL9+fbXTLYw/JbwgsmbNGsl8XjEP27ZtG3r16gVbW1txmwW65hECXe5nUmNRVv5JXWPVTZs2MjMz8dlnn6FXr17iNlhbW8PPzw/Lli1Tqh/QRnZ2Nt566y20bNkSxsbGMDU1RePGjREQEKB2HPa7d+9i0qRJaN26tVgf5uXlha+//rpGY13KZDLMnj0bADB79myl/ax4rupaxgD+Of969OiBkpISfPbZZ2Jdkp2dHQYNGoQLFy5oTB8RYfny5ejUqRPMzMxgZWWFPn36qM2XdPX8+XN8/vnn8PPzg42NDYyMjODs7IzQ0FCxDC/QJh8AqleW3bx5MwIDA2FnZyeO2dqmTRuMGTMGf/75p1JYbcuwil6m+3td1QErnm/Pnz/H9OnT4erqCmNjYzg5OWH06NEq94KUlBTIZDK4ubmp7RK7sLAQdnZ2kMlkOH/+vGQYScSYlpydnQkArVq1SnJ+ixYtCADNnDlTaXpSUhIBIH9/f63X5e/vTwBo3bp1lJmZSUZGRqSvr08XLlxQCjd69GgCQElJSUrTU1JSCAC5uLgQEdHrr79OAGjYsGFK4W7dukUAqKaXQl5eHvn5+REAksvl5O/vT9HR0dSzZ09ycHBQWX5sbCwBoDFjxpCRkRE1bdqUhg4dSqGhoTR//nwiIrp27Zq4zx0cHCgiIoIGDBhAFhYWBIA8PT3p0aNHSstdvXo1yWQykslk1LVrV4qMjKQBAwaQp6cn6evr01tvvSWGLSsro4CAAAJAlpaW1K9fP4qOjqbAwEBxvadOnVJa/p07d6h9+/YEgGxtbSkwMJAGDhwohm/atCndvHlTKc6qVasIAIWHh1OHDh3I2tqaQkNDKSwsjBwdHQkAOTs7U15enhjn22+/pYiICAJAZmZmFBsbq/QTCOfWsGHDyNbWlurXr08RERE0aNAgmjx5MhERPXz4kNzd3cXtHDBgAEVERJC9vT0BoGbNmtGNGzeU0nzjxg0xXYMGDSK5XE6BgYEUFRVFzZs3JwBkbm5O6enpSvFCQ0MJAC1fvlzyPNm3b594XpaXl0uG+bf5+/srnRcjRoygadOmiX9nZWWRhYUFTZgwgS5dukTbt28nR0dH+uijj8Qwr7/+OllZWVFqaiplZ2eLv+fPnxMR0dWrV+mDDz6g48eP040bN2jbtm3UvHlz6t69u7iM0tJSateuHfXp04dOnz5Nu3btIgcHB3r33XfrficwpqC4uJgAUHFxsdL/qxOf/W+rKv+cM2cOGRoa0k8//aSUN+bn5ysto23btpSSkkLXr1+nVatWkbGxMX3zzTdq1wuAtm7dqjTtypUrdOrUKYqPj6eWLVvSqVOn6NSpU1RUVFRr26utzz//nACQjY0NlZWVVWsZQjlJ8Z6vaMyYMQSAunXrpjJPKAPqUrarqqz68ccfEwBq3LixyjyhzABApTwh6NatGwGgxMRElXkZGRlka2tLAKhJkyYUGRlJffv2JWNjYwJAQUFBksdxxowZBIBkMhn5+vpSdHS0WN7R19enFStWKIV/9uwZtWvXTixXhoaGUlRUFPXo0YPq169PACg3N5eIiLZu3SoeA+E4KP4ePHigeYdWMnnyZLXLO3DggBju888/Jz09PQJA7u7uNHjwYPLz8yNDQ0MCQLNnz1ZZtvAs4ObmRkFBQRQZGUne3t7ict5++22l8NqWMV1cXMT9X1hYqPW27t+/XywnlpSUiNOLiorIxMSEOnXqRERE7777LgGg/fv3K8Xv27ev5LZqOq8Vn5t27NhBAOi1115TCrN3714CQDExMURE4rJu3bql9bZVJpT/1Z33wjGv/OwoTH/99dfJ2NiYmjZtSpGRkdSnTx/xWA8ePFilrCw8U0jlCwsXLhS3qUuXLhQdHU2dO3cmADRp0iSxXF/ZX3/9RY0bNyYA1KBBA+rbty+FhoZSvXr1xPNQ8RmF6J/8YtSoUdSoUSOqV68eDRo0iIKDg8nKyooAkJeXl1I54NNPP6WgoCACQPXq1VM654RnFsVlKz7bahN3y5YtBIB8fHwkj0VZWRk1bdpU8pzTlrr9r/jcVJlwTN5//30xr4qMjKSOHTuK+dfPP/+sEu/JkyfUo0cP8Vry9/enwYMHU6tWrQgA2dnZ0cmTJ5Xi6PIcLJg8eTIBID09PerSpQsNGTKEunbtSjKZjPT19WnlypUqcQICAkhPT4/at29PwcHBNGTIEPL09BS39fPPP1e77/r370/NmjUjGxsbGjBgAA0ZMkS8JomIEhISxOW4u7tTVFQU9evXT3z+TElJUVmmLs/YUjTd/4S85Y033iA9PT1q06YNRUVFUZ8+fWjDhg1EpP46r5xOqet206ZN4r3Ozc2NBg4cSL169SIzMzMCQHFxcRrTrs6FCxcoNjaWfH19xWdvqXxeyMMmTJhAAKhz584UHR1N/v7+lJaWRkTVyyOIdL+fffvttyr3I+En3LubN2+uFKc6aROOh9T1WtmHH34o1pcEBARQVFQU+fv7i9swaNAgyToNqXtVdnY2OTk5iWWdsLAwioyMpG7dupGtrS1ZWVmpLGf//v1kY2Mj1jMNGDCAgoKCxGl9+vSp9vNWbGysmA917NhRaX9/++23YjhdyxhE/9yvfXx8KDAwkExNTalv374UEREhHi9ra2uNdVCxsbEkl8upV69eNHToUGrZsiUBICMjIzpy5Ei1tlmQlZVFbdq0IQBkampKvXv3pqioKOrWrRtZWVmpnBva5APVKcvOnj2bAJCBgQF1796doqOjKTg4mNq1a0cymYwWLVokhtWlDCt42e7vdVUHLJxv3t7e9Morr5Cpqal4b2rQoAEBoPr169Ply5eV4gn1urt375Y8T1auXEkAqGfPnpLz1eFGJqY1TY1M58+fJ319fQJAx44dU5pX00YmIhIfDgYOHKgUTttGpuzsbDIzMyOZTKbUcFJbjUyDBg0iAOTh4aFysygpKaFffvlFaZrig/a0adMkK2G6du1KAGjAgAH09OlTcfrff/8tFmQrN5o1a9aMACg9sAvu37+vVBgXHoI9PDzoyZMnKuGPHTtGOTk54t/l5eViQW306NFKcUpKSsRCeuVMSCjICDeXx48fi/MePXokVoh88sknSvE0PbAIhHMLAA0fPlyyEiAyMpIAUNeuXZW2Jz8/n/r16yf5QKZYYWRvb09nzpwR55WWlooPAM7Ozkrr/OOPP8SCihShUmPBggVqt+nfVrmS1N/fX+UhID09nbp27UpGRkbUvHlz+vjjj6m0tFScL+yryj8hr8jKyqLu3buTra0tGRkZkaurK02ZMkXpXCAiunnzJvXr149MTEzI3t6eJk+erFRBw9i/gRuZmLaqyj+FclPln2KZJTs7m0aOHElOTk5kbGxMrVq1ogULFmh8EQFQbWQSyk2Vf+oqf+vSiBEjCAAFBARUexmaGpkKCwvF8s68efNU5tdFI5OPjw8BoPHjx6vMU9fIVFRURJcuXaI33nhDLE9kZWWpbItwnowbN04p37h27ZpYKTx9+nSleDt37iQAZGxsrPJw+N133xFQ8dLTuXPnxOlr1qwhANSvXz+V/KmsrIxSU1NVKgBqo4ys7fJ27dpFMpmM7O3tVSrB//zzT2rUqBEBoNTUVKV5qampdO3aNZXlXbx4UYxz9OhRpXnalDEXLVokprdevXo0ZswYWrFiBZ08eVKpDFSZ0JgEgA4fPixOT0tLIwBihcOuXbtUKhpLSkrI3NycAIgVnAJtG5nKysqoUaNGZGFhQc+ePRPDxMTEEADat28fEb0cjUxCpZViWe/cuXPiC3pLly5ViqeusvrMmTOkr69Penp6tHnzZqV569evJ5lMJnm8nz9/LjYmzpgxQ+n8f/bsGUVHRxOgWtGt+PwxcuRIpWeBrKwsatiwIQEQK98EwjHU9Ews1cikTdzS0lLxeFRufCEiSk5OJgDUoUMHteuuSk0amaytrVUqRoVtbdmypUq8YcOGEQAKCQmh+/fvK80Trs0WLVooXYu6PAcTES1fvpwAkKurq9KzHlHFc7KFhQUZGhqqVMzt2LGD7t69q7KO9PR0srS0JLlcTrdv31aap/g8HBAQoPIMRET05ZdfElDRgCZcp4qOHj2qdA+p7jN2Zdo0MgGgxYsXS8avbiPTn3/+SUZGRmRsbExbtmxRmnfz5k2xAnTNmjUa06+JpgYuon/yMH19fdq2bZvK/OrmEdW9n0k5efIkmZubq6SxumnTpZEpIyODzp49qzL9zp07YgPNpk2bVOZL3auEBoWxY8eqlHGLi4tpz549StOys7PJzs6OZDIZffPNN0r1ZTk5OdSrVy+Ve6iu1OW3iqpTxlC8X3t4eFB2drY4r6CgQGyQGDt2rFI8xfKks7MzXbp0SZxXWlpKo0aNIqCica26ysrKxBcw+vTpQ3///bfS/IKCAvrtt9+UplWVD1SnLFtYWEgmJiZkbm5OFy9eVFnmzZs3lT4w0LUM+zLe3+uqDljxfHN1daXMzExxXkFBgVgH+corryjF+/bbb8V1SenUqRMBUMmfq8KNTExrUo1MeXl59Pvvv5Obm5t4AVemeKGq+1V+OKncyPTw4UOx5VjxgU3bRiaif974DAoKEqfVRiPT6dOnxQf9ygVKdYQMpmXLlpIPqgcOHCCg4s2Ce/fuqcw/fvw4ARVvXSk+HJqamkq+BSJl06ZNBIDefPNNrcILFRru7u6SFf9lZWXi2wWKhRGhIGNmZiZZIN+4cSMBoF69eilN16WRydbWVvINoszMTNLT0yOZTKby8EBEdPv2bfHtikOHDqmsG5B+G62wsFC8wXz//fdK89q2bSv5gHPr1i0yMDAgU1NTlbcsGGMvD25kYqxmhBc4oqKiJOefPn1a8k1dxfumVCNTYWEhnTp1ivr3708AqHfv3lRQUKCyfMWHLXW/ypVhUpVsxcXFdOHCBRo5cqRY/lF8WUWgWGZQ94uOjpasiF+3bh0BICcnJ8kXZX766ScCQBYWFkrbKnyJPmnSJMl9HBISQkDF25KCuXPnEgBauHChZBwpNS0j67I84cH6p59+kpwvlFsjIiK0Xt+yZcsIAE2ZMkVpujZlTKKKL9iEN+oVfxYWFvTqq69KVowQ/XN8FCt3hQq25ORkIqp42cnAwIB69Oghhjl8+DABIBMTE5UGP20bmYiI3nvvPQJAq1evJqKK5zUTExNq3ry5WLknLOtFNjI1aNBA8hr+6quvCKhoRFCkrsL4tddeIwAUGRkpmY6wsDDJ471kyRICKhoypOTn55OjoyMZGBgovTks5BeNGjVSasgTzJkzh4CKN6EV1WUjE9E/1/jo0aNV5gmVmsuWLVMbvyo1aWT68ssvVeYVFhaKz/eKjSfnz58nmUxGTk5Oki9CEhEFBwcrXU9Euj0Hl5WViV9VHD9+XDKMsD8V30SvivCFYuWKWGHfyeVyyQrrkpISsXFV2wq96j5jV6ZNI5OmZVS3kUl4EVR4g7+yjIwMAiB+/Vkd2jYyVb5WBdXNI2rrfnbz5k3xS4TK51R106bYOKnup/jFnDq///47AaAhQ4aozJO6Vwkv3Eh9uSglMTGRgIqvzKTcvn2b5HI5OTg4VLuHGG0amTRRV8YQ8muZTEanT59WiXfkyBECVL9MUyxP/vrrryrxsrOzCaj4mqm6z5m//PKLeP9V7FlBk6rygeqUZf/++28CtH/xQdcy7Mt4f6+rOmDF8mHljxuIKl6yMDU1JUC5zvP58+dkZ2dHenp6Kr1RCeXRxo0ba3yxSgqPycR0FhcXJ/YxaW1tjaCgIFy5cgXr16/Hhx9+qDZevXr1EBsbK/kzNzfXuE5bW1skJiYCgPivrqZMmQJ7e3v8/vvvOg0wXZVdu3YBAPr374+GDRvqFDc8PFxyHAehD+C+ffuiXr16KvM7deqEjh07ory8HPv37xend+nSBY8fP8arr76KEydOaOwn19PTE/r6+li5ciUWL16M7OxsjWn97bffAFQMNi4MPK5IT08P3bt3BwCkp6erzO/cubPkQL2tW7cGgBr1GR0YGAgrKyuV6WlpaSgvL4eHh4fkoM0NGzZEUFAQAOkBmgGIfTkrMjIyQmRkJADVPvfffPNNAMDXX3+tNH3ZsmUoLS1FTEwMrK2tq9wmxhhj7H/RrVu3sGbNGpXf1atXVcIqjqNgbGwMDw8P/Pbbbxg3bhx27dpV5Zg16sqdrq6ukuEV+1I3NDRE69atsXr1aoSGhuLo0aOws7PTuL6IiAhxHSNGjEBAQACsrKywadMmTJ8+HU+fPlUKL5QhoqKiYGRkpLK8QYMGwcbGBvn5+Thx4gSAinFKDh06BABqx7gYPXo0AOWyjZeXF4CKcVnWrl0rOe7mi5KTk4OMjAyYmJggNDRUMowwbolUGfPp06fYvHkzpk+fjrFjx2LkyJEYOXIktmzZAgC4dOlStdI1ffp03L59G6tXr0ZcXBw6duwIfX195OfnY+3atfDw8JAcW0NqXKbU1FTo6emhW7duAABzc3N4enriyJEjKCoqUgrv6+srjntZHcKz2sqVKwEAGzZsQEFBgTgewMti6NChktewUPa+cuUK7t69W+VyhP02fPhwyflSZXngn2cboUxfmbm5OTp37ozS0lIcO3ZMZX5AQABMTU1VptfGs011vPbaazA1NcWGDRuUxpy9evUqdu/eDWtra7X7qK5JXddGRkZo3rw5AOV9tWPHDhAR+vXrBwsLC8nlSeUHujwHnzp1Cnfv3oWLiws6deqk9ToEDx8+xNq1azF16lSMGTNGzHOE53J1eY6Hh4e4zYpOnDiBBw8ewN7eHgMHDlSbbil1+YwtGDx4cI2Xoai8vBw7d+4EoP7669y5M8zNzXHq1CkUFhbW6vorU7d91ckjano/E+Tm5qJfv37Izs5GYmIi3njjjRqnTZGZmZnaMpIwjiRQMYZ3cnIy3n//fYwbNw5xcXEYOXIkli1bBkD7+6sw9ua0adPw888/q5SHKqtq+xo2bIgWLVrgwYMHuHLlilZpqK7qljGaNGmCjh07qkyv6to0MDBA3759VabXr18fNjY2KCoqUjs+W1WEusthw4ZVWQdbmbrrpDplWQcHBzRt2hR//vknJk+eXOWYP7qWYV/m+3tt1wELrK2tMWDAAJXpjo6O4vmkWC41MTHB2LFjUV5ejiVLlijFWbx4MQBg3LhxascdVke1ppixKvj6+ooP5w8ePMCBAweQn5+P119/HS1atFA7eLObm5vaASG1MXHiRHz99ddIS0vD9u3bERISolN8S0tLzJgxAxMnTkRiYiKOHj1a7bQoyszMBFCxfbqSGrwR+CfTEgYmluLi4oIzZ84oZXDffPMNQkJCsG7dOqxbt04cGLFXr14YMWIEmjRpohR/0aJFmDJlCiZMmIAJEybA2dkZ3t7eCAkJwZAhQ5QecK9fvw4AmDlzJmbOnKlxux48eKAyTXHdiiwtLQGgRoXHmu5HxbCKrK2t1TYICcu8ffu20vThw4eLhafs7Gw0aNAAxcXF+PbbbwEAEyZM0LgtjDHG2H+Zvb09AOmyAACEhIQoDTIbGBiIvXv3SoZ1cXGBn58fAODJkyc4fvw4bt26haVLl6J9+/YqlS6V6VrurFevnvgg9vz5c5w5cwaXL19GcnIyZs6cic8++0xj/Pnz56uUSfLy8jB06FD88MMPyM/PR3JysjivqnKKTCZDs2bNkJubK4Z9+PChWGZSF0+qbNOjRw8kJiZi3rx5iI2NhUwmQ4sWLeDr64uwsDCEhoZCT+/FvH9448YNEBEKCgokKygUVT6vkpOTERcXp7HC5cmTJ9VOm7W1tVjxBlRU/G3duhUzZsxAdnY2YmNjkZmZqVQZITQyHTp0CCUlJSgvL8eRI0fg7u6u9FKUv78/MjIycOTIEfj7+4sP/0L86nJxcUH37t2RlpaGa9euYeXKldDT01PbKPmiqDt/LSwsYGdnh4cPH+L27dtwcnLSuByhLK5ueeqmC882I0aMwIgRIzSu499+tqkOGxsbjBgxAsuWLcOKFSvwzjvvAKh4PiQixMXFSVaa/Rt02VfCcVmxYgVWrFihcbmKx0WX52BhHdeuXauy4bXysf/222/x9ttv49mzZ2rjqMtz1D2zCvUJrVq10rkh+N84D9Wlu7oePnwo7qPGjRtrFV7Xl3l1oW77qpNH1OR+JigqKkJ4eDguXLiA6OhofPrpp7WSNkX29vZVlpGOHDmCyMhIZGVlqQ2j7f11xIgR+OOPP/D9998jIiIC+vr6aNOmDfz8/DB48GD06tVLKbywfcKLGZo8ePAALVu21CoduqpJGaOqa1N4waSyBg0aQC6Xq42bm5tb7ev6RdRdSpVlAWDt2rUYPHgwFi5ciIULF8LW1hZdu3ZF7969MWLECPF5AtC9DPsy399ruw5Ycbnq7h/q6i7feOMNzJs3DytWrMCsWbNgbGyMBw8eYPPmzTAyMsKYMWO02SQl3MjEdPbaa68pPaQ8fvwYAwcOREpKCoYOHYrz58/XSQHWxMQESUlJiI+Px/Tp0xEcHKzzMl5//XV8/vnnOHbsGH766Sd4e3vXejp1YWJiUqvLa926NS5duoTdu3dj3759SE9Px4EDB7Bv3z588MEHWLFihdIbbAkJCRg6dCh+/fVXHDx4EAcPHsTGjRuxceNGJCUl4cCBA+KbUcLbYH5+fmLlhTpt27ZVmVaXFRe1vR91oVhRBgCmpqYYM2YM5s6di+XLlyMpKQlbtmzB/fv30a1bN8kvqnRZV2lpaU2TzBjToKSk5KVaDmMvmoGBgU6VXp6enli3bh1OnjyJ8vLyGt3//fz8lCpBysrK8O6772LevHmYOHEifH19Jd8SrS6pF6K++uorvPnmm5g7dy78/f11Ln9aW1tjwYIF6NChA7Zv346//vpLspz0b5gzZw7GjRuH5ORkHDx4EIcOHcKqVauwatUqeHl5ISUlBWZmZv96uoQyprm5OSIiIrSOd+fOHURGRqKgoABTp05FTEwMmjZtCnNzc+jp6WH37t0ICgpSKavVhI2NDUaNGgUPDw94enoiJycHhw4dQu/evcUwXl5eMDMzw7Nnz5CRkYGysjIUFBSIb68L/P39MW/ePKSkpMDX1xcHDx4EUPNGJgAYNWoU9u/fj7fffhvHjx9Hnz59tKrMrU2aviTRVm0eu8qE9Kl7a1iRs7OzyrQX1SiryZtvvolly5ZhyZIlmDRpEgoLC7Fq1SrIZDKMHz/+haVLl30lHBd3d/cq8/euXbuK/9flOVhYR/369cVeLdRRrOg8ceIE4uPjoa+vj88++wyhoaFo0qQJTE1NIZPJsHz5csTHx6s9b+vimfXfOA9rkm6pfEBxmrovDRVV1VhTU+q2rzp5RHXvZwIiwsiRI5GWloYePXpg9erVkmWwmuZfVXn+/DnCw8Nx//59xMXF4fXXX4erqyssLS2hr6+Py5cvo1WrVlrn0Xp6eli/fj2mT5+O3377DYcOHcKhQ4ewZMkSLFmyBKGhodi6dav41YSwfYMHD66yXFLVV+bVVdMyRnWvzZfx3gLUfv7VrVs33Lx5E7/99hv279+P9PR0/P7779i5cyeSkpKwdetWBAQEiOF1KcO+zPf3l6nuslGjRhg0aBA2bdqEH3/8EbGxsfjuu+9QVFSEESNGwMHBQed1cCMTqzErKyv8+OOPcHNzQ2ZmJhYuXIgZM2bUybpGjx6NhQsX4uzZs1i3bp3O8Q0NDfHhhx9ixIgReO+997B79+4ap0lo5b548WKNlyUQ3tQRWuClCPMqv9VjYGCA4OBgsRLkyZMnWLhwIWbPno34+HgMHDhQ6UZdr149jBkzRmylvnjxIkaNGoXDhw9j2rRpWLNmDYB/3jIKCwsT34x72dVkPwIVbx/n5eVJfs108+ZNABUZc2Xjx4/HggULsHz5ckyfPl3sOq+mXzGVlpbWqPsUxph2LC0toaenV60KMj09PVhaWr6QilrG6kJxcbHaNyqlhISEYPLkycjNzcWOHTt0/vJcE6Fi7+jRo0hLS8PkyZOxZ8+eWlu+lISEBGRkZGD9+vWYNGkS+vTpI9ltsCaK3SNduHBBbGTSppxy48YNpbB2dnYwMjJCUVERrl+/LvnyiqayTdOmTZGQkICEhAQAwLFjxzB8+HAcO3YMc+fOxezZs3XattoglDGFLt60fbhPTk5GQUEBBg4cKPmVWV12oePh4QF7e3vk5OQgJydHaZ5cLoefn5/YRbdwL/H391cK5+fnBz09PaSmpiIoKAjPnj2Dubm52C1MTQwePBgJCQnil3OjRo2q8TIrE8qk+fn5kvOFN6bVEc7tyvLz88W3xqXK2ZU1bNgQ165dw82bNyUbcIUye2WNGzfGxYsXMXr06FrvDuxFadOmDQIDA7Fnzx7s3LkTd+/eRV5eHvr161flS4IvCyE/8PX1Vel+vCraPgcL67Czs9Ppi9fNmzeDiJCQkICpU6eqzK9uniPUJ1y+fBlE9FJ1a1mV6uQD9vb2MDExQUFBAebPn6/UkPcyqU4eUd37mSAxMREbN25E27ZtsXXrVrXP/nWdf6WlpeH+/fvw9PQUu15VVN1zvU2bNmjTpg2mTJkCIsK+ffswbNgwJCcnY+3atYiLiwNQsX1XrlxBYmIiOnfuXKNtqa4XWcaoKy+q7rJyWVZgYmKCwYMHi+fwgwcPMGPGDCxfvhyjRo1SyT+0LcP+F+/vNa27VFfWUZwnVaZ68803sWnTJixevBjDhw/H0qVLAVS/7vLlbCJl/zkODg5iw9L8+fORl5dXJ+vR19fHJ598AgB4//331X5iqklMTAw6duyIK1euiF2Y1YTQrcqOHTu06jdcG8Kbjrt27cL9+/dV5p86dQqnT59WGgdJHUtLS8yaNQvW1tZ4/vw5Ll++rDG8m5ubOO7V6dOnxen9+vUD8E/huq4JBaqafLnTvXt36Onp4fTp0zhz5ozK/OzsbLFfWnVvjUo1ZhYXF+PHH38EAJW3UoGKm3d4eDju3r2L999/H+np6XBycsKgQYOqvS1AxYNTcXEx//jHvzr+PXr0SOf+hwX6+vp49OjRC98G/vGvtn66Nqi4urqKfaBPmjQJjx8/rta1pI5MJsOiRYsgk8mwd+/eWh1nU53PPvsMJiYmuHTpUrVecrp27Zr4f8U+8IUyxI8//ijZ9cbWrVuRm5sLCwsLcdwQAwMDsQtBdZWjQoWQNl/EeHl5id0OKpb7AIiNi3X9FbWTkxM6dOiA/Px8sVymDaFPfqm3UIkIGzZskIynTRmzqrJuXl6e2EWO1EO74rhMwnhMlcvsVlZWcHd3x5EjR8TxSfz8/HS+5qSYmppi5MiRsLOzQ7NmzRAeHl7jZVYmVHJcuHBBZd69e/dw8uRJjfE3b94s+SwnXGOurq5adZElNN59//33kvPXrl0rOV14ttm0aVOV66gNNXm20SXuW2+9BaBifFhhXIX/UnfdwnH59ddfa9zVm7rnYC8vL9jb2+P8+fP466+/tF6epjynsLBQHKNFV507d4a9vT0ePHiAX375pVrLeFE05QNEJOZtivT19cWvP/+t6686qpNHVPd+BlSMgzJv3jw4OTlh586dGsdxruv8SzjX1XUbtn79+hqvQyaTISAgAMOGDQMgXfdUl+dHVflqdcsYLzOh7vKHH37Q2OWnLqpTllXHwcEBc+fOBQBkZWUpjS8oRV0Z9r90fxfUtA44Ly9PqUtuwYMHD8S8SKru0tfXF506dcKxY8cwY8YMZGVlwcvLS+0wOFXhRiZWa9544w00adIEjx8/xoIFC+psPYMGDULXrl2RlZWFn3/+Wef4MplM7Nf2888/r3F63N3dERYWhoKCAoSFhan0WVtaWopff/1Vp2X6+fmha9euKCgoQHx8PJ4/fy7Oy8nJQXx8PICKwfWEt2WeP3+OhQsXSvYpeuDAAeTl5UFfX198EN63bx927Nih0qUTEWH79u0AlG+oYWFh8PLyQkZGBuLi4iTXk5ubi6VLl9ZKZYSDgwMMDQ1x7969ag9O3aRJEwwZMgREhPj4eKW+dJ89e4axY8eisLAQPj4+8PHxkVzGhx9+iHPnzol/l5eXIzExEbdv30bjxo3VfgYvPODNmTMHABAfH1/jSgOZTAa5XM4//vGvjn/VbWAS6Ovrv/Bt4B//autXnTeqFy9eDFdXV1y5cgU+Pj6SA9QCFW/WVe4fXBuenp4YMmQIACApKUnn+LpycnIS35r86KOPdCrn5OXliV+A29raKo0vMGTIEDRp0gR3797FpEmTlJZ748YNTJ48GUDF11TGxsbiPGH6kiVLVMazWr16NX799VfI5XKxLAJUPOSnpaWpfKFZUlIiPnxWrkgRyoy6VMJW10cffQQAiIuLk3xIJiIcPXpUqRcCYQDmn376CdnZ2eL0srIy8SUfKdqUMbt06YJvvvlGcv69e/cQGxuL4uJicTzTyoRGpvT0dBw5cgQdO3aUrDD09/dHUVGR2BhQG13lCb744gvk5OTg+vXrddLdVGBgIICKRljFFwwfPHiAV199tcqB3e/evYt33nkHZWVl4rQLFy7ggw8+AAC8/fbbWqUjISEB+vr62LRpE7Zu3ao0b+PGjWor7ceOHQtnZ2ds3rwZiYmJkl9i3Lt3r1ZeSgT+uZ6uXLmic5e6usQNDg6Gq6srdu3ahTNnzsDFxUWscPsv8PDwQEREBG7duoVBgwZJvp397NkzfP/992JFnK7PwXK5HElJSSAiDBw4UOyqUlFZWRn27duHI0eOiNOEPGfNmjVK50thYSHeeOMNtV/nVcXAwADvvfcegIrzMi0tTSXMsWPHqnW/rGtCPrBu3TqcP39enF5SUoLExEQcO3ZMMl5SUhIMDQ0xZcoUrFmzRrL3gHPnzlWrvqe2VDePqM79bNu2bXjzzTdhaWmJHTt2VNm9aV3nX8K5vnfvXqXjCgDLly8XX7jV1tq1a3HixAmV6fn5+eJ4hIplkClTpsDa2hoLFy7EggULUFxcrBL3xo0bNWrsqqqMU90yxstswIAB8PDwwN27dzFkyBCVsaYKCwslG4Y1qU5ZNjMzE999953keFbCNWNjYyOOgaRrGfa/dH8XVKcOuLLJkycr3SeKioowfvx4PHv2DF26dIGvr69kvMp1lzV6MYUY05KzszMBoFWrVqkNs3LlSgJAFhYW9PDhQyIiSkpKIgDk7++v9br8/f0JAK1bt05yfmpqKgEQf0lJSUrzU1JSCAC5uLioXUePHj2UllETjx49oldeeYUAkKGhIfXo0YOGDRtGvXr1IgcHB5Xlx8bGVrkvr127Ju5zR0dHGjx4MIWFhZGlpSUBIE9PT3r06JEYPjc3lwCQnp4edezYkQYPHkzR0dHk7e1NMpmMAND7778vhl+0aBEBIEtLSzG9AwcOFNdpZWVFp06dUkrTnTt3yN3dnQCQmZkZ+fj4UFRUFA0aNIjc3d1JX1+fAFBBQYEYZ9WqVQSAYmNjJbfzxo0bBICcnZ1V5g0ePJgAUOPGjSk6OppGjx5No0ePFucL51bl468oJyeHOnbsKG5TeHg4DR48WDwuzZo1oxs3bkimqUmTJjRw4ECSy+XUu3dvioqKIhcXF3H7Dxw4oHa9REQeHh4EgORyOWVnZ2sMyxh7+RQXFxMAKi4uftFJYew/5/79+xQQECCWsxo1akQhISE0fPhwioiIoA4dOojlk/bt29PZs2fFuEI5SV3ZgYjo8uXLZGBgQABo9+7d4nShDKhL2U6bsuqjR4/I2tqaANDy5cvF6UKZAQBFRERQbGwsxcbG0ogRIygwMJCsrKwIABkbG1NycrLKcjMyMsjW1lYsC0VGRlJwcDAZGxsTAAoKCqKioiKVeDNmzCAAJJPJyM/Pj4YNG0aenp4EgPT19WnFihVK4d966y0CQPb29tS7d2+KiYmhAQMGkKOjIwGghg0b0q1bt5TivPPOO2KcoUOHiuWwnJwcrfetoqqOyxdffCEeU1dXV+rfvz8NGzaMevfuLaYzMTFRDF9SUkKdOnUiAGRubk79+/enoUOHkrOzM8nlckpMTFR7XKsqYwrHTV9fn9zd3SkiIoIiIyPJz8+P5HI5ASBbW1s6fPiw5LaUlpaKZXYANHHiRMlwv/zyi9LzSEZGhmQ4Ted1Vc9NUoRlVT7musjNzVV6VgkLCxPP+fbt21N4eLjk845wfY8bN46MjY2pWbNmFBUVRUFBQWRoaEgAaODAgVReXq4UT9Mzxdy5c8Vt6tq1Kw0bNoy8vLwIAL399ttqnzXOnTtHTZs2JQBkbW1N3bt3p2HDhlF4eDi1adOGZDIZ1atXTylOVc8fwrGSOu86d+5MAKhVq1YUExNDo0ePVjqnNS27qriKPv/8c3F/LFiwQDKMrtTtf03PclVd88K5m5KSojT9yZMn4v3D0NCQvLy8aOjQoTRkyBDy8vISz5MLFy4Qke7PwYIpU6aIaWzbti2FhYVRVFQU9ejRQ8zvlyxZIoZXPOft7OwoPDycIiIiyNHRkSwsLMR8tvI+qup5mIiovLycxo0bJ6bHw8ODoqKiKDg4mJo3b66yn2ryjK1I0/1P3fGpLCwsjACQiYkJ9e7dmwYMGECNGjUiS0tLtfuEiGjTpk1kamoqlhH69OlDMTEx1K9fP2rUqBEBoMjISI3r1qSqfSQcy8p1AYqqk0cQ6X4/E45x+/btxXJE5d/kyZNrnDZhn1R1XhD9c1wNDQ2pT58+FBUVRW5ubiSTyei9997T6boXluXk5ETBwcEUExNDwcHB4r22Xbt29OTJE6U4+/fvJ3t7e/Ee06tXL4qJiaGQkBCxTqZr165Vboc69+7dIzMzMwJAvr6+NHLkSBo9ejStXLmSiKpfxtB0D9C0j7S5ZrU5Z6ty8+ZNatWqFQEgU1NT6tOnD0VHR1P37t3JyspKZf3a5AO6lmVPnTol1pMJ+fvQoUPF+jOZTEbfffedGL46ZdiX7f5eF3XAimny9vamrl27kqmpKYWEhNDQoUPJyclJXNbFixfVrreoqIjq1atHAMjBwYEKCwvVhq0KNzIxrWnTyFRaWkpt2rQhADRt2jQiqptGJiKi4OBgMXOuTiPT0aNHlR7qaqqoqIiWLFlC3bp1I2trazI0NKRGjRpR7969afHixUphtclgiIgePnxI7777LrVu3ZqMjY3J1NSUPDw8aM6cOfT8+XOlsCUlJbR06VKKjo4mNzc3srKyIhMTE3JxcaGIiAjau3evUvirV6/SrFmzKCAggJo0aULGxsZkY2NDHTp0oGnTpql96CwsLKSlS5dSz549yc7OjgwMDMjR0ZHc3d1p/Pjx9PvvvyuFr0kB+OHDhxQfH09NmjQRH+gVj5U2jUxERM+ePaNPP/2U3N3dydTUlIyNjal169Y0ffp0lUy6cppKSkro448/Jjc3NzIyMiJbW1uKiIigv/76S+M6iUgseERHR1cZljH28uFGJsZqbs+ePTRq1Chq1aoVWVpakoGBAdnY2JCnpyfFx8fTH3/8QWVlZUpxtGlkIiKKj48XH6wEddXIRET06aefiuUD4WFZsZGp8s/MzIxat25NEyZMoCtXrqhdblZWFo0fP56aN29OhoaGZGFhQd7e3rRkyRIqKSlRG2/nzp0UHBwslsfq169PQ4YMoaNHj6qEPXXqFE2bNo38/PyoYcOGZGhoSA4ODtSpUyf65JNPJBuOCgoKaOrUqeTq6ipW6takckOb43L27FkaO3YstWjRQiz7Nm/enIKCgujLL7+kO3fuKIXPz8+n6dOnU6tWrcjY2JgcHR0pPDycjh8/rrEyoKoy5tmzZ2nRokUUGhpKbm5uZG1tTQYGBmRra0s+Pj40e/ZsevDggcZt6d+/v7jcX375RTLMw4cPxUpwS0tLKi0tlQz3MjYyERHdvn2bXn31VXJ0dCRDQ0Nq1qwZTZkyhfLz89U+7yhOP3nyJIWGhpKdnR0ZGRlR27ZtaeHChZLnfVXPFNu2bSM/Pz8yMzMjc3Nz8vHxoZ9++qnKirsnT57Q3Llzydvbm6ytrUkul1ODBg3Iy8uLpkyZQunp6Urha1IJlZmZScOGDaMGDRqIFdCK6dK07KriKrpw4YJYgZibmysZRlf/ZiMTEVFZWRlt2LCBgoODqV69eiSXy8nOzo7atWtHcXFxtHXrVrF8putzsKJDhw5RTEwMOTs7k5GREVlYWFDLli0pPDycvvvuO5VnxQcPHtAbb7xBLi4uZGRkRE5OTjR8+HC6cuWK2n2kTSOTYOfOnRQWFiZus4ODA3Xp0oVmz54tvsSrzTL/zUamwsJCmjFjBjVv3pzkcjk5OjpSdHQ0Xb16Vat0vv3229SuXTsyMzMjY2NjcnZ2ph49etCcOXPo6tWrGtetSW00MhHpnkcIdLmfCWnR9JM6lrqmTZdGpuLiYpo3bx61b9+eTE1NydbWlvr06UO7d+/W+bpPS0ujiRMnUpcuXah+/fpkaGhI9evXJ29vb/rqq6/o6dOnkmm4f/8+zZw5kzw9PcnCwkKsY/Px8aGkpCT6888/q9wOTdLS0igwMJBsbGxIT09P5XypThnjZW9kIqrYrs8++4y8vLzIwsKCjIyMyNnZmQYMGEAbN25UCqttPqBLWfbJkyf0+eef08CBA6lFixZkbm5OZmZm1LJlS3r11Vfp+PHjSuGrU4YV1vOy3N/rog64cpqePn1KU6ZMoWbNmpGhoSHVq1ePRo4cSVlZWRrXSUQUGRlJAOjdd9+tMqwmMqJ/YXAVxhj7D7l58yaaNWsGZ2dnjQPoaVJWVgYXFxdkZmYiPT1dsisVxtjLraSkBIaGhiguLoZcLn/RyWGMMcb+80aOHIk1a9Zg1apVGDly5ItOzv+kGTNm4OOPP8bYsWOxbNmyF50cxhhjjNWB1NRU9OzZE/7+/mLXk7rKy8tDo0aNUFhYiBs3blTZXacmPCYTY4zVgeXLlyMzMxPe3t7cwMQYY4wxxhirc9nZ2Vi8eDH09PQwceLEF50cxhhjjL3EPv30Uzx79gxDhw6tUQMTANRsFHrGGGOiS5cuYd68ebh37x527doFPT09zJ8//0UnizHGGGOMMfY/bNq0abhz5w727NmDvLw8jBs3Thy4njHGGGNMkJ6ejpUrV+LGjRvYt28fTE1N8dFHH9V4udzIxJiCnJwcvPPOO1qHf+211+Dn51eHKWL/JdnZ2VixYgUMDQ3Rtm1bzJo1Cz4+Pi86WYwxxhhjtea7777DwYMHtQprb2/PL9z8B+jSbV14eDjCw8PrLC2sejZu3IisrCzUr18fEydOxJw5c9SGnTNnDi5evKjVct3c3DBt2rTaSiZj1cJ5FNPknXfeQU5OjlZh/fz88Nprr9VxiurexYsXNebzlU2bNg1ubm51mCL2X3L58mWsWLECJiYmeOWVV/DZZ5+hefPmNV4uj8nEmAJhLB5tcV/ijDH2v4vHZGKMMVXCmDraqMn4luzfI5PJtA6blJSEWbNm1V1iWJ3r0aMH9u/fr1XYmozzwFht4TyKadK0aVNkZmZqFTY2NharV6+u2wT9C4SxeLSVkpKCHj161F2CGAM3MjHGGGOMSeJGJsYYY4wxxhhjjDHN9F50AhhjjDHGGPsvmTNnDmQymcZB1VevXg2ZTKb0MzY2VgozcuRIlTB9+/ZVWdZvv/2Grl27wsTEBDY2NirdwBw7dgwBAQGwtraGjY0NgoKCcObMmdrYVMYYY4wxxhhjTCNuZGKMMcYYY0xLx44dw7Jly9ChQ4cqw1paWiI7O1v8SXXl0bdvX6UwP/zwg9L8LVu2YMSIEYiLi8OZM2dw6NAhDBs2TJz/9OlT9O3bF02aNMHRo0dx8OBBWFhYICgoCCUlJTXfYMYYY4wxxhhjTAODF50AxhhjjDHG/guePn2KmJgYfPvtt/joo4+qDC+TyVC/fn2NYYyMjNSGKS0txVtvvYV58+Zh9OjR4vQ2bdqI/7948SIePXqEDz74AI0bNwZQMR5Bhw4dkJmZCVdXV202jTHGGGOMMcYYqxb+kokxxhhjjDEtjB8/Hv3790dgYKBW4Z8+fQpnZ2c0btwYYWFh+Ouvv1TCpKamwtHREa1atcLrr7+Ohw8fivNOnjyJO3fuQE9PDx4eHmjQoAH69euHc+fOiWFatWoFOzs7rFixAsXFxSgoKMCKFSvQunVrNG3atMbbzBhjjDHGGGOMacKNTIwxxhhjjFVh48aNOHnyJD799FOtwrdq1QorV67Etm3bsH79epSXl8PHxwe3b98Ww/Tt2xdr167F3r178dlnn2H//v3o168fysrKAADXr18HAMyaNQszZszA9u3bYWNjgx49euDRo0cAAAsLC6SmpmL9+vUwMTGBubk5du3ahZ07d8LA4MV3WpCamooxY8agTZs2sLGxgVwuh52dHbp06YIJEyZgz549ICKlOFJjVRkYGMDe3h7+/v5YvHix2q4AU1NTVeJK/fLy8sQ4s2bNUpmvr68PGxsbvPLKK/jkk0/w9OlTyfXdvHlTcvl6enqwtbWFn58fFi9ejNLS0lrbp/9VRUVFmD59Olq0aAEjIyPIZLKXuiG0vLwcq1evRu/eveHo6Ai5XA5bW1u0bNkSAwYMwNy5c3Hz5k0x/MyZMyGTyRASEqJ2mYGBgZDJZDAzM0NxcbFkmPnz50Mmk6Fbt27iNMXzurIePXqI88LCwjRu0+bNm5XOU8X86GUnjHM3cuRIneIJ1+jLfK4JhLxo1qxZLzopKtTt///S/v1fouv1oO29sfLvZTwXdXH+/HmEh4fD0dER+vr6/xPbVBNS44VW/llbW9doHeruVf9fcJ7I/j978U+ejDHGGGOMvcRu3bqFt956C3/88QeMjY21iuPt7Q1vb2/xbx8fH7Ru3RrLli3Dhx9+CACIiooS57dv3x4dOnSAi4sLUlNTERAQgPLycgDAe++9h4iICADAqlWr0KhRI2zevBnx8fEoKCjA6NGj4evrix9++AFlZWWYP38++vfvj2PHjsHExKS2doNOcnJyEBMTg927dwMAGjZsCF9fX1hZWeHx48c4d+4cFi9ejMWLF8PDwwMnT55UWYaLiwv8/PwAAIWFhbh48SLS0tKQlpaGH374AX/88YfG7YuNjVU7z9DQUGVavXr10LdvXwBASUkJrl+/jqNHj+Lo0aNYu3YtDhw4AAcHB7XLjIiIgLm5OQCguLgYN27cQHp6Og4dOoRNmzbhjz/+kFzvy0qoJKrcCFhdM2fOxLx581CvXj2EhYXB1NQU9vb2tbJsXdy8eRPNmjWDs7OzUiORomfPniE0NBQpKSkAAE9PT3Tv3h36+vq4fv06du3aheTkZJiammLChAkAgJ49e+Kjjz7CgQMHUFZWBn19faVlFhcXIz09HQDw/PlzZGRkiOe3ImGdPXv21HnbduzYgfv376NevXqS81esWKHzMlntSE1NRc+ePeHv74/U1NR/LS5jAFC/fn3Je+Lp06dx5swZpfufInd3938hdXXj2bNn6N+/P27evInOnTsjKCgI+vr6/+ltqi1mZmYYPHiw5DxTU9N/OTWMvdy0KTeyCtzIxBhjjDHGmAYnTpzA33//DU9PT3FaWVkZ0tLS8PXXX6OoqEilQrkyuVwODw8PXL16VW2Y5s2bw97eHlevXkVAQAAaNGgAQHkMJiMjIzRv3hxZWVkAgA0bNuDmzZs4fPgw9PT0xGk2NjbYtm2bUkPWvyUvLw9+fn64dOkS3Nzc8M0330hWmJ87dw6LFi3Cxo0bJZfj5+eH1atXK03buHEjoqOjcejQIXz99deYMmWK2nRUjlsVNzc3lThpaWno3bs3Ll26hFmzZmHx4sVq48+fP1/lzdX09HT06tULaWlpWL58udgg8f/Rpk2bAAAHDhxAixYtXnBqNJs1axZSUlLg5OSEnTt3okOHDkrzHz9+jC1btojXKFDRkGxkZIQnT57g5MmT8PLyUopz9OhRFBQUwNPTEydPnkRqaqpKI1NZWRkOHjwIQPdGps6dO+P48eNYu3at5HVx69Yt/PHHH/Dy8sKxY8d0WvbLYODAgXjllVdgZWX1opNSZyZMmICoqKgX0vhaXQ0bNsSFCxcgl8tfdFKYBlL3N6Airztz5oza+f9lx44dw82bN+Hj44NDhw696OS8VOzt7f/njjdj7MXj7vIYY4wxxhjTICAgAGfPnsXp06fFX+fOnRETE4PTp09X2cAEVFQenz17VqlSurLbt2/j4cOHYphOnTrByMgIly5dEsOUlJTg5s2bcHZ2BlDxRYSenp5S1yTC38KXUP+2hIQEXLp0Cc2bN0d6errayvJ27dphxYoV4pcb2oiKikLv3r0BAMnJybWSXk26d+8uvv1dnfX5+PiIbwvv3bu3VtP2XyM0jL7sDUwAxIbPpKQklQYmALCyssKoUaPQr18/cZqxsTFeeeUVAJA8p4UvUKZNmwa5XC4Z5sSJE3jy5AmMjIyUvoTUxvDhw2FoaIhVq1ZJzl+9ejXKy8sxatQonZb7srCysoKbm5vGPPS/zt7eHm5ubv+pRia5XA43Nze4uLi86KQwpuS/dM9hjLH/BdzIxBhjjDHGmAYWFhZo166d0s/MzAx2dnZo164dAODVV1/Fu+++K8b54IMPsHv3bly/fh0nT57E8OHDkZmZiddeew0A8PTpU0yZMgVHjhzBzZs3sXfvXoSFhcHV1RVBQUEAAEtLS4wbNw5JSUnYvXs3Ll26hNdffx0AMGTIEABA7969kZubi/Hjx+PChQv466+/EBcXBwMDg2p1t1VT165dw4YNGwAAixYtgo2NTZVxunTpotM6hEr/+/fv657Aaqjp+urXrw8Aasdlun37NhISEtCiRQsYGxvDysoKvr6+WLZsmTg+l5Tff/8dISEhcHR0hKGhIZycnBAZGYnjx49Lhn/8+DFmzJiB9u3bw8zMDEZGRnBycoKvry/ef/99cZwrYVwYQeXxGnTtKqRp06aQyWRit3uKy6r8JvWJEycQExODJk2awMjICLa2tggKCsKOHTskl33+/HkkJSXB19cXDRs2hKGhIezs7BAYGCh+OaVo5MiRaNasGQAgMzNTZdsEwrF2dHTUaVuFa06qS7PU1FTo6+sjKCgIXl5eOHz4sMq4TEI8b29vrbvmFNjZ2WHAgAG4cOECDh8+rDSPiLB69WqYmJggOjpap+WqIxxXdeeDMLZa5WOsOP3MmTMYNGgQHBwcYGJigg4dOuCLL76QPO+rGoNm+/bt8Pf3h4WFBaysrNCtWzds27atyu3Izc1FUlIS3N3dYWFhAVNTU7Rv3x4fffQRnj9/rhJecdykBw8eYPz48WjcuDEMDQ3RuHFjJCQkKI35BlSMmyWcG/v371c65xS/fpQak0mbuP7+/pDJZPjhhx/UbufcuXMhk8kwdOjQKveJLjSNP6J4XW3ZsgV+fn6wtLSEmZkZfH191V7XQEV++d1336FHjx6wtbWFkZERmjVrhtdffx23bt2SjLNnzx6EhoaiXr16kMvlsLGxQYsWLTB8+HCkpaVJxtm7dy8GDRqEBg0awNDQEI6Ojhg4cKDKNSTIyMjA1KlT0aVLF9SvXx+GhoaoV68eQkNDsWfPHsk4iufuo0ePMHHiRLi4uMDIyAg9evRQCrtv3z4MGTIEjRo1gpGRERwcHODl5YWkpCQ8fPhQcvnPnj3Du+++C1dXVxgZGYld4925c0fN3tWOMN5bamoqDhw4gNDQUDg4OEBPT0+8rtVd51LbLuXy5cuIj4+Hi4uLeP/r3r071q9fX+10C+NPCS+IrFmzRjKfV8zDtm3bhl69esHW1lbcZoGueYRAl/uZ1FiUlX9S11h106aNzMxMfPbZZ+jVq5e4DdbW1vDz88OyZct0fpEpOzsbb731Flq2bAljY2OYmpqicePGCAgIwPz58yXj3L17F5MmTULr1q1hamoKCwsLeHl54euvv67xWJeK5+65c+cQGRmJBg0aQF9fXykPrk5eJEWbsZqquq9qq7S0FCtXrkRgYCDs7e1hZGSERo0aITAwEF999ZVSWG33w6NHjzB9+nS0bdtWPBadOnXC3LlzUVBQIJkOXfLkoqIizJs3D506dYKFhQUMDQ1Rv359eHl5YerUqeJYtIoKCgqwYMECvPLKK7C2toaxsTFatWqFqVOnSuaXivmRtvmmtuVGxft3VlYWRo8ejcaNG0Mulyvlf8+fP8ecOXPg6ekpXrNt27bFjBkzkJubq5JmxfOmtLQUc+fORdu2bWFiYgJ7e3sMHToUFy9eVIpz7do1cWxZTflA27ZtIZPJNN6LdcXd5THGGGOMMVZDWVlZYnd1QMWD/5gxY3Dv3j3Y2NigU6dOSE9PF7u+09fXx59//ok1a9YgLy8PTk5O6NOnDz788EMYGRmJy5k3bx4MDAwwYsQIFBQUoGvXrti3b5/YeOPm5obk5GTMnj0b3t7e0NPTg4eHB3bt2vVC3vjfvn07ysvLYWNjg5CQkDpZx5MnTwBA7bgzL9v6MjIyAFQ8zFV27Ngx9O3bF48ePUKTJk0QHh6Ox48fIzU1Fenp6di6dSt+/fVXlbGcZs6ciY8++ggymQw+Pj5o0qQJLly4gE2bNmHLli1Yvny50hcrz58/h5+fH86dOwcHBwcEBATAzMwM9+7dw8WLF5Geno5JkybB2toa7u7uiI2NxZo1awCojm0ljDulrcGDByMnJ0dyea6uruL/v/jiC0yaNAnl5eVwd3dH165dce/ePaSmpmL37t2YPXs23n//faVlL1y4ECtWrICbmxvat28Pa2trZGVlISUlBXv37sWRI0ewcOFCMbyfnx+ePn2KLVu2aByTokmTJrh27RqWLl2Kfv36KV2TmvTs2ROzZs3CgQMHUFpaCgODisft4uJiHD58GO7u7rC0tIS/vz/S09Nx5MgRdO/eXYxfk/GYAGDUqFH46aefsHLlSqUvoVJSUnD9+nXExMS8NN3NZWRk4PXXX0f9+vUREBCA3NxcpKamYuLEiTh48CA2bdqk9eDxixYtwqRJkwBUNFq7uLjgypUrCA8PF6dLOX/+PPr27Ytbt26hQYMG8PPzg1wuR0ZGBmbOnIktW7YgNTVVcp/dunULnp6eKCkpga+vLwoLC8VuPI8ePYpDhw6JXcj17dsXxsbG+P3331XGvqnqqyVt4r711lti961SjYjl5eVYsmQJALyQLjuTkpLw4YcfwsfHB8HBwWKeExISgi1btmDgwIFK4fPz8zFgwACkpqbC3NwcnTp1goODA86ePYulS5di8+bN+OOPP+Dh4SHGWbNmDeLi4gBUnAM9e/ZEQUEBbt++jY0bN8Le3l7pWgOAd955BwsWLICenh46d+6Mbt26ISsrC9u2bUNycjK+/fZbcZmC6dOnIyUlBW3btkWnTp1gZmaGa9euYfv27di+fTs+//xzvPXWW5L7IScnB507d0ZeXh66deuGTp06KeXtb775plgB7O7ujm7duuHx48e4dOkSPvjgA/Ts2VOlUerx48fw8fFBVlYWunXrhnbt2uHw4cNYu3Yt9u/fjzNnztT4mt+8eTOWLl0KNzc3BAYG4tGjR1rniVUt99VXX0VhYSHc3NwQHByMx48f4+jRoxgxYgT27duHlStX6rxcobL46tWrOHTokNL4jlIWLFiAr7/+Gp07d0bfvn1x9+5d8Qv16uYRut7PNKXvxIkTOHfunMpX8zXJv7Sxbt06zJw5E82aNUPLli3h6+uL7OxsHD58GIcOHcLu3bvx008/aZVP37t3D507d8bdu3fRpEkTMV+7e/cuTp8+jRMnTuCdd95RipOWlobw8HDk5uaiadOm6N27N4qKipCRkYGEhAQkJydj+/btNe6qMz09HePGjUODBg3QvXt3FBQUwMLCAkD18qIX7fHjxwgJCcHBgwchl8vh4+MDJycn3Lt3D3/++Sf27t2LhIQElXia9sP169fRq1cvZGZmwsHBAcHBwSgpKUFKSgoSExPx448/Ys+ePUovlumSJ5eXl6N///7Yu3cvLC0t0a1bN1hbW+PBgwe4cuUK5s2bh2HDhsHW1lZc/t27d9G3b1+cPXsWtra28PLygoWFBU6ePIl58+Zh8+bNSE1NFXt+qLyPtM03tS03Cq5cuQIPDw8YGhrC19cXRCTeqx89eoSAgACcPn0alpaW6NWrF+RyOfbv34+PP/4YGzZswL59+9Q2REZGRiI5ORn+/v7o0KEDMjIysHnzZuzcuRO7d+8Wy30uLi7o378/kpOT8f3332PMmDEqy0pJScH58+fh4uKi9FV+jRFjjDHGGFNRXFxMAKi4uPhFJ4Wx/4wRI0YQAAoICKj2MmJjYwkAxcbGqswrLCykZs2aEQCaN2+eyvyUlBQCQLo85iQlJREA8vf3l5zv4+NDAGj8+PEq827cuCGu78aNG+L0oqIiunTpEr3xxhsEgOzt7SkrK0tlW5ydnQkAjRs3TimvuXbtGjVt2pQA0PTp05Xi7dy5kwCQsbEx7d69W2ned999RwBILpfTuXPnxOlr1qwhANSvXz+VPK2srIxSU1OpqKhIabqu+7Eqmpa3a9cukslkZG9vT/v371ea9+eff1KjRo0IAKWmpirNS01NpWvXrqks7+LFi2Kco0ePKs0Tjpmzs7PatC5atEhMb7169WjMmDG0YsUKOnnyJJWWlqqNV1RURCYmJgSADh8+LE5PS0sjADR58mRxewHQ7NmzxTAlJSVkbm5OACgtLU1puZrOa39/fwJA69ato7KyMmrUqBFZWFjQs2fPxDAxMTEEgPbt20dE/xyLW7duqd2WqgjnruJ5r0i4jletWiU5HQC98cYbVFJSIs47d+4cOTg4EABaunSpUrxVq1ZJ5gtnzpwhfX190tPTo82bNyvNW79+PclkMsnj/fz5c3JxcSEANGPGDKXz/9mzZxQdHU0AKC4uTimekF8AoJEjR1JhYaE4Lysrixo2bEgAaMOGDUrxhGOoLp9RXHZSUpJOcUtLS8XjcfLkSZX5ycnJBIA6dOigdt1VUbf/NV1Pwn6ytramI0eOKM0TtrVly5Yq8YYNG0YAKCQkhO7fv680T7g2W7RooXQtCveFAwcOqCzv/v37Kvtl+fLlBIBcXV3pzJkzSvP2799PFhYWZGhoSJcvX1aat2PHDrp7967KOtLT08nS0pLkcjndvn1baZ6w74R74+PHj1Xif/nllwSA7OzsxOtU0dGjR5XuIYrLDAoKUlrmo0ePyN3dnQDQJ598orIsRZruf0LeAoAWL14sGV/ddV45nZXPmz///JOMjIzI2NiYtmzZojTv5s2b1L59ewJAa9as0Zh+TdStWyBcM/r6+rRt2zaV+dXNI6p7P5Ny8uRJMjc3V0ljddMm7BNN9z9BRkYGnT17VmX6nTt3qGPHjgSANm3apDJf6l41e/ZsAkBjx46l8vJypXnFxcW0Z88epWnZ2dlkZ2dHMpmMvvnmGyorKxPn5eTkUK9evVTuobpSvBdNmzZNaR2C6uRF6vJEbcoeVd1XtTFo0CACQB4eHirLKSkpoV9++UVpmjb7oWvXrgSABgwYQE+fPhWn//333+Tp6UkAaNiwYUpxdMmT9+/fL6b5yZMnKuGPHTtGOTk54t/l5eXk6+tLAGj06NFKcUpKSmjy5MkEgHr27Km0nOrmm9ocO8WywfDhw5XKBoLIyEgCQF27dlXanvz8fOrXrx8BIB8fH8l1C88Siver0tJSSkhIENOmuM4//viDAFDHjh0l0xsREUEAaMGCBWq3qTq4kYkxxhhjTAI3MjGmO+EhKSoqSnL+6dOnKTY2VuWn+BAq1chUWFhIp06dov79+xMA6t27NxUUFKgsX7EyXt2vcmWYVCVbcXExXbhwgUaOHEkAyN3dXemBUKD48KfuFx0dLVlhsG7dOgJATk5Okg+jP/30EwEgCwsLpW0NCAggADRp0iTJfRwSEkIAaMyYMeK0uXPnEgBauHChZBwp/2Yjk1CB8dNPP0nO37RpEwGgiIgIrde3bNkyAkBTpkxRmq5NZQER0ccff0xmZmYqx9PCwoJeffVVunjxomQ84fgoVlIIFWzJyclEVFGhYGBgQD169BDDHD58mACQiYmJSoOfto1MRETvvfceAaDVq1cTEVFeXh6ZmJhQ8+bNxcq9l6GRqUGDBpLX8FdffSVW3ClSV2H82muvEQCKjIyUTEdYWJjk8V6yZIlYeSglPz+fHB0dycDAgB49eiROF/KLRo0aKTXkCebMmUMAaNSoUUrT67KRieifa3z06NEq84KCgggALVu2TG38qtSkkenLL79UmVdYWEhWVlYEQKnx5Pz58ySTycjJyUmyspGIKDg4WOl6IiIyNTUlKysrrbalrKyMnJycCAAdP35cMoywP4WGYW28++67kg0ywr6Ty+WSjeIlJSVi42rlBhd1hGWamZlJNnpt3LiRAFCvXr00LkebRiZNy6huI5NQ2Tp//nzJeBkZGQSAOnXqpDH9mmjbyFT5WhVUN4+orfvZzZs3qUGDBpLnVHXTpljJru6XkpKiMV1ERL///jsBoCFDhqjMk7pXCS/c/Pzzz1Uum4goMTGRANCECRMk59++fZvkcjk5ODioNFppSzh3W7ZsKfnySHXzohfZyHT69GkCKl5CqtzYrU5V++HAgQMEgExNTenevXsq848fP04ASE9PT6lMoUueLFwTb775plbhhZet3N3dlV5UEZSVlVG7du0IgFJDaXXzTV0amWxtbSkvL09lfmZmJunp6ZFMJlN5sYGo4pw2NjYmAHTo0CGVdQOgzz//XCVeYWGh+HLL999/rzSvbdu2BKg29N26dYsMDAzI1NSUcnNz1W5TdfCYTIwxxhhjjLF/xa1bt7BmzRqV39WrV1XCKo6jYGxsDA8PD/z2228YN24cdu3aVeWYNbGxsZI/xS7aFCmOd2JoaIjWrVtj9erVCA0NxdGjR2FnZ6dxfREREeI6RowYgYCAAFhZWWHTpk2YPn06nj59qhReGPMhKipKsuuhQYMGwcbGBvn5+Thx4gSAin72Dx06BABqx7gYPXo0gH+6XgMALy8vABXjsqxdu1ayb/sXJScnBxkZGTAxMUFoaKhkGKGLqPT0dJV5T58+xebNmzF9+nSMHTsWI0eOxMiRI7FlyxYAwKVLl6qVrunTp+P27dtYvXo14uLi0LFjR+jr6yM/Px9r166Fh4eHZD/2UuMypaamQk9PD926dQNQ0eWgp6cnjhw5gqKiIqXwvr6+Kt0j6iIuLg4ymUzsZmrDhg0oKCgQx114WQwdOlTyGha6U7xy5Qru3r1b5XKE/TZ8+HDJ+ZW7exT89ttvACq6n5Fibm6Ozp07o7S0FMeOHVOZHxAQAFNTU5XprVu3BoAaj4ejq9deew2mpqbYsGGD0rgOV69exe7du2Ftba12H9U1qevayMgIzZs3B6C8r3bs2AEiQr9+/cSumiqTyg+6dOmCx48f49VXX8WJEyc0jhdz6tQp3L17Fy4uLujUqZPW6xA8fPgQa9euxdSpUzFmzBgxz9m/fz8A9XmOh4eHuM2KTpw4gQcPHsDe3l6l68CqdO7cWbJr3No8D6vqHkpX5eXl2LlzJwD111/nzp1hbm6OU6dOobCwsFbXX5m67atOHlHT+5kgNzcX/fr1Q3Z2NhITE/HGG2/UOG2KzMzM1JaRhHEkgYpxcpKTk/H+++9j3LhxiIuLw8iRI7Fs2TIA2t9fhbE3p02bhp9//lmlPFRZVdvXsGFDtGjRQuxOrSbCw8NVuiIEqp8XvUi7du0CAPTv3x8NGzbUKa66/SDcY/v27SvZbXSnTp3QsWNHlJeXi3kgoFue7OnpCX19faxcuRKLFy9Gdna2xrQK50dERITYLbEiPT09sSs+qWNTl/lmYGCgZBeVaWlpKC8vh4eHhzjWq6KGDRuKY/Iqlt8VSZVnjIyMxOuk8nigb775JgDg66+/Vpq+bNkylJaWIiYmBtbW1lVuky54TCbGGGOMMQ1KSkpedBIYe2EMDAx0qpgW+h1/8OCB5PyQkBAQkfh3YGAg9u7dKxlWcRyFJ0+e4Pjx47h16xaWLl2K9u3bq1S6VKZuIHJ1FMc7ef78Oc6cOYPLly8jOTkZM2fOxGeffaYx/vz581X6Uc/Ly8PQoUPxww8/ID8/H8nJyeI84SFWGFC4MplMhmbNmiE3N1cM+/DhQ7HCTV08FxcXpeUDFRUhiYmJmDdvHmJjYyGTydCiRQv4+voiLCwMoaGhSmOK/Ztu3LgBIkJBQUGV43xUPq+Sk5MRFxcnOcCzQBhTqzqsra3FijegouJv69atmDFjBrKzsxEbG4vMzEylxgahkenQoUMoKSlBeXk5jhw5And3d6WKB39/f2RkZODIkSPw9/cXKweqOx6TwMXFBd27d0daWhquXbuGlStXQk9PT22j5Iui7vy1sLCAnZ0dHj58iNu3b8PJyUnjcm7fvq1xeeqmX79+HQAwYsQIjBgxQuM6pPKzJk2aSIa1tLQEgDqvGK/MxsYGI0aMwLJly7BixQpxfJNvvvkGRIS4uDjJRrF/gy77SjguK1aswIoVKzQuV/G4fPPNNwgJCcG6deuwbt06WFhYwMvLC7169cKIESOU0iCs49q1a1Xe3yof+2+//RZvv/02nj17pjaOujxH3TgbmZmZAIBWrVrp3BD8b5yH6tJdXQ8fPhT3UePGjbUKr2uFuS7UbV918oia3M8ERUVFCA8Px4ULFxAdHY1PP/20VtKmyN7evsoy0pEjRxAZGYmsrCy1YbS9v44YMQJ//PEHvv/+e0REREBfXx9t2rSBn58fBg8ejF69eimFF7ZPeDFDkwcPHqBly5ZapUNKVcdf17zoRRLyEjc3N53jqtsPVZVVgYpyx5kzZ5TKnbrkyS4uLli0aBGmTJmCCRMmYMKECXB2doa3tzdCQkIwZMgQpZdvhGMzc+ZMzJw5U+N2/dv375ruR8WwiqytrdU2CAnLFMpDguHDh4sNu9nZ2WjQoAGKi4vx7bffAqibMRq5kYkxxhhjTIKenh4sLS1hZmb2opPC2AtTXFys06DKnp6eWLduHU6ePIny8vIaNVz4+fkpVYKUlZXh3Xffxbx58zBx4kT4+vqiY8eO1V5+ZW5ubiqVLl999RXefPNNzJ07F/7+/ggODtZpmdbW1liwYAE6dOiA7du346+//kLbtm1rLc26mDNnDsaNG4fk5GQcPHgQhw4dwqpVq7Bq1Sp4eXkhJSXlheR3wtut5ubmiIiI0DrenTt3EBkZiYKCAkydOhUxMTFo2rQpzM3Noaenh927dyMoKEipUbOmbGxsMGrUKHh4eMDT0xM5OTk4dOgQevfuLYbx8vKCmZkZnj17hoyMDJSVlaGgoEB841ng7++PefPmISUlBb6+vjh48CCAmjcyAcCoUaOwf/9+vP322zh+/Dj69OmjVWVubdL01rK2avPYVSakT93b2YqkBg5/UY2ymrz55ptYtmwZlixZgkmTJqGwsBCrVq2CTCbD+PHjX1i6dNlXwnFxd3evMn/v2rWr+P/WrVvj0qVL2L17N/bt24f09HQcOHAA+/btwwcffIAVK1aIX3IJ66hfv7745rg6wosTQMUXR/Hx8dDX18dnn32G0NBQNGnSBKamppDJZFi+fDni4+PVnrcmJiZV7wAd/RvnYU3SLZUPKE5T96Whoqoaa2pK3fZVJ4+o7v1MQEQYOXIk0tLS0KNHD6xevVqy4bGm+VdVnj9/jvDwcNy/fx9xcXF4/fXX4erqCktLS+jr6+Py5cto1aqV1nm0np4e1q9fj+nTp+O3337DoUOHcOjQISxZsgRLlixBaGgotm7dKn5JI2zf4MGDqyyXVPWVeVWqOv665kU1URv3zeqq7fxJlzwZABISEjB06FD8+uuvOHjwIA4ePIiNGzdi48aNSEpKwoEDB8Svj4T95OfnJzbMqCNV5q7LfLMu8nltVb4eTU1NMWbMGMydOxfLly9HUlIStmzZgvv376Nbt26SX1TVFDcyMcYYY4xJ0NfXx6NHj15ogZ+xF02qGwpNQkJCMHnyZOTm5mLHjh0ICQmptbQIFXtHjx5FWloaJk+ejD179tTa8qUkJCQgIyMD69evx6RJk9CnTx+d94li90gXLlwQH3iFN7OFNzKl3LhxQymsnZ0djIyMUFRUhOvXr0s+IArLk3rzu2nTpkhISEBCQgIA4NixYxg+fDiOHTuGuXPnYvbs2TptW20QGj+ELt60ffhPTk5GQUEBBg4cKPmVWU270NHEw8MD9vb2yMnJQU5OjtI8uVwOPz8//P7770hJSRHvIf7+/krh/Pz8oKenh9TUVAQFBeHZs2cwNzcXuzasicGDByMhIUH8cm7UqFE1XmZlwlvF+fn5kvOFN6rVEc7tyvLz88Uv0xo1alRlOho2bIhr167h5s2bkpVJN2/elIzXuHFjXLx4EaNHj6717sBelDZt2iAwMBB79uzBzp07cffuXeTl5aFfv35VVsS9LIT8wNfXV6WLn6oYGBggODhYfBngyZMnWLhwIWbPno34+HgMHDgQZmZm4jrs7Ox0+uJ18+bNICIkJCRg6tSpKvOrm+cIb9VfvnwZRPRSdWtZlerkA/b29jAxMUFBQQHmz5+v1JD3MqlOHlHd+5kgMTERGzduRNu2bbF161a1XafWdf6VlpaG+/fvw9PTU+x6VVF1z/U2bdqgTZs2mDJlCogI+/btw7Bhw5CcnIy1a9ciLi4OQMX2XblyBYmJiejcuXONtqW6apIXSanqWikpKamym7iqCHnJxYsXa7QcRdqUVdWVO7XNkwX16tXDmDFjMGbMGHE7Ro0ahcOHD2PatGlYs2YNgH+OTVhYmPjV7suuJvsRqOgZIS8vT/JrJqGcI1VmGj9+PBYsWIDly5dj+vTp4rlcF18xAcDL9/oNY4wxxthLQl9fH3K5nH/8+3/707Wyy9XVVewbfNKkSXj8+HGtXpMymQyLFi2CTCbD3r171fZbXps+++wzmJiY4NKlS1i3bp3O8a9duyb+39zcXPy/8GXLjz/+KNk1x9atW5GbmwsLCwtx3BADAwOxC0F1laNChZA2X8R4eXmJ3Q6ePn1aaZ5cXvEFW2lpaZXLqQknJyd06NAB+fn54ngC2hDGlZJ6S5uIsGHDBsl4QkWPpu2q6u3svLw8sZsgqYd6xXGZhPGYhPEBBFZWVnB3d8eRI0fE8Un8/Px0bsSUYmpqipEjR8LOzg7NmjVDeHh4jZdZmVAJcuHCBZV59+7dw8mTJzXG37x5szgelSLhGnN1ddWqiyyh8e7777+XnL927VrJ6f369QMAbNq0qcp11AZtzrvaiPvWW28BqBiDYfHixQDqrjKpLgjH5ddff61xV2+WlpaYNWsWrK2t8fz5c1y+fBlARb5nb2+P8+fP46+//tJ6eZrynMLCQnEcOF117twZ9vb2ePDgAX755ZdqLeNF0ZQPEJGYtynS19cXv/78t66/6qhOHlHd+xkALF68GPPmzYOTkxN27typcayUus6/hHNdXbdi69evr/E6ZDIZAgICMGzYMADKZZB/O3+WUpt5EQA4ODjA0NAQjx49wt9//60y//fff69xeUvo8nnHjh1ajWmoDaGsumvXLty/f19l/qlTp3D69GnJck5l6vJkddzc3JCYmAhA+vwQGv7rWk3u34Lu3btDT08Pp0+fxpkzZ1TmZ2dni3mGuvK71DNIcXExfvzxRwBQ+WIeqLiGw8PDcffuXbz//vtIT0+Hk5MTBg0aVO1t0YQbmRhjjDHGGGO1ZvHixXB1dcWVK1fg4+OjNBCwops3b6r0H64NT09PDBkyBACQlJRUo7Rqw8nJSfzy56OPPtLpITMvL098y9LW1lZpfIEhQ4agSZMmuHv3LiZNmqS03Bs3bmDy5MkAKr6mMjY2FucJ05csWaIyntXq1avx66+/Qi6Xi5XNQEWDlTDosKKSkhLxobZyxanQeKJLJWx1ffTRRwCAuLg4pXGrBESEo0ePYvfu3eI0YYDmn376Sent37KyMvFBWopQ0XPv3j2xIq2yLl264JtvvpGcf+/ePcTGxqK4uFgcM6AyoYIgPT0dR44cQceOHSUrDP39/VFUVCQ2BtRGV3mCL774Ajk5Obh+/XqddDcVGBgIoKIRNi8vT5z+4MEDvPrqq1UO7H737l288847KCsrE6dduHABH3zwAQDg7bff1iodCQkJ0NfXx6ZNm7B161aleRs3blRbaT927Fg4Oztj8+bNSExMlHy7/N69e+LYBTUlXE9XrlzReaxHXeIGBwfD1dUVu3btwpkzZ+Di4iJWyP0XeHh4ICIiArdu3cKgQYMkv0R79uwZvv/+e7HC8/nz51i4cKHk2BsHDhxAXl4e9PX1xf0ol8uRlJQEIsLAgQPFrioVlZWVYd++fThy5Ig4Tchz1qxZo3S+FBYW4o033lD7dV5VDAwM8N577wGoOC/T0tJUwhw7dqxa98u6JuQD69atw/nz58XpJSUlSExMxLFjxyTjJSUlwdDQEFOmTMGaNWskew04d+4cfv7557pJuBaqm0dU5362bds2vPnmm7C0tMSOHTuq7N60rvMv4Vzfu3ev0nEFgOXLl4uV2tpau3YtTpw4oTI9Pz9fHI9QsQwyZcoUWFtbY+HChViwYAGKi4tV4t64caNWGrvUqU5epIlcLhcbYWbMmKF0zp85c6ZWXgZwd3dHWFgYCgoKEBYWpjKeVmlpKX799Vedlunn54euXbuioKAA8fHxeP78uTgvJycH8fHxAICoqCjxvNU1T963bx927Nihcn8jImzfvh2A8vkRFhYGLy8vZGRkIC4uTnI9ubm5WLp0aa28KKVNubEqTZo0wZAhQ0BEiI+PVxpL9NmzZxg7diwKCwvh4+MDHx8fyWV8+OGHOHfunPh3eXk5EhMTcfv2bTRu3FhtF53C88CcOXMAAPHx8bXyQpMkYowxxhhjjLFadP/+fQoICCAABIAaNWpEISEhNHz4cIqIiKAOHTqQTCYjANS+fXs6e/asGDc2NpYAUGxsrNrlX758mQwMDAgA7d69W5yekpIirlNbSUlJBID8/f3Vhnn06BFZW1sTAFq+fLk4/caNG+L6IiIiKDY2lmJjY2nEiBEUGBhIVlZWBICMjY0pOTlZZbkZGRlka2tLAMjZ2ZkiIyMpODiYjI2NCQAFBQVRUVGRSrwZM2YQAJLJZOTn50fDhg0jT09PAkD6+vq0YsUKpfBvvfUWASB7e3vq3bs3xcTE0IABA8jR0ZEAUMOGDenWrVtKcd555x0xztChQ2n06NE0evRoysnJ0XrfKqrquHzxxRfiMXV1daX+/fvTsGHDqHfv3mI6ExMTxfAlJSXUqVMnAkDm5ubUv39/Gjp0KDk7O5NcLqfExES1x3Xw4MEEgBo3bkzR0dHitgmE46avr0/u7u4UERFBkZGR5OfnR3K5nACQra0tHT58WHJbSktLydLSUtzmiRMnSob75ZdfxDAAKCMjQzKcpvPa39+fANC6devU7tvKhGVVPua6yM3NJWdnZwJAjo6OFBYWJp7z7du3p/DwcAJAq1atUoonXN/jxo0jY2NjatasGUVFRVFQUBAZGhoSABo4cCCVl5crxVu1apXafGHu3LniNnXt2pWGDRtGXl5eBIDefvtt8fqq7Ny5c9S0aVMCQNbW1tS9e3caNmwYhYeHU5s2bUgmk1G9evWU4gj5RVJSkuR+EY6V1HnXuXNnAkCtWrWimJgYGj16tNI5rWnZVcVV9Pnnn4v7Y8GCBZJhdKVu/wt5oNT+reqaF87dlJQUpelPnjwR7x+Ghobk5eVFQ4cOpSFDhpCXl5d4nly4cIGIKs5FAKSnp0cdO3akwYMHU3R0NHl7e4v3mffff19l/VOmTBHT2LZtWwoLC6OoqCjq0aOHmN8vWbJEDK94ztvZ2VF4eDhFRESQo6MjWVhYiPls5X2k6dwVlJeX07hx48T0eHh4UFRUFAUHB1Pz5s1V9lNVy9R0XBRpuv+pOz6VhYWFEQAyMTGh3r1704ABA6hRo0ZkaWmpdp8QEW3atIlMTU3FMkKfPn0oJiaG+vXrR40aNSIAFBkZqXHdmlS1j4RjeePGDbXLqE4eQaT7/Uw4xu3btxfLEZV/kydPrnHahH1S1XlB9M9xNTQ0pD59+lBUVBS5ubmRTCaj9957T6frXliWk5MTBQcHU0xMDAUHB4v32nbt2tGTJ0+U4uzfv5/s7e3Fe0yvXr0oJiaGQkJCyMXFRczvq0u4F1W+RynSNS8i0nztHTlyRIzTsmVLGjx4MHl7e5NcLqfY2FitzsmqPHr0iF555RUxzT169KBhw4ZRr169yMHBQeXYaLMfrl27pnS/Hzx4MIWFhYnlHE9PT3r06JEYXtc8edGiRQSALC0txfQOHDhQXKeVlRWdOnVKKU137twhd3d3AkBmZmbk4+NDUVFRNGjQIHJ3dyd9fX0CQAUFBWKcmuSbVZUbqyobEBHl5ORQx44dxW0KDw+nwYMHi8elWbNmKsdeSFOTJk1o4MCBJJfLqXfv3hQVFSVeB2ZmZnTgwAG16yUi8vDwIAAkl8spOztbY9ia4EYmxhhjjDHGWJ3Ys2cPjRo1ilq1akWWlpZkYGBANjY25OnpSfHx8fTHH39QWVmZUhxtGpmIiOLj4wkAeXt7i9PqqpGJiOjTTz8VHz6Fhh/FRqbKPzMzM2rdujVNmDCBrly5ona5WVlZNH78eGrevDkZGhqShYUFeXt705IlS6ikpERtvJ07d1JwcDDZ2dmRgYEB1a9fn4YMGUJHjx5VCXvq1CmaNm0a+fn5UcOGDcnQ0JAcHByoU6dO9Mknn0g2HBUUFNDUqVPJ1dVVrBSpSeWHNsfl7NmzNHbsWGrRogUZGxuTqakpNW/enIKCgujLL7+kO3fuKIXPz8+n6dOnU6tWrcjY2JgcHR0pPDycjh8/rrGy/+HDhxQfH09NmjQRG40U03b27FlatGgRhYaGkpubG1lbW5OBgQHZ2tqSj48PzZ49mx48eKBxW/r37y8u95dffpEM8/DhQ7HCxdLSkkpLSyXDvYyNTEREt2/fpldffZUcHR3J0NCQmjVrRlOmTKH8/Hy1FVeK00+ePEmhoaFkZ2dHRkZG1LZtW1q4cKHkeV9V5dC2bdvIz8+PzMzMyNzcnHx8fOinn36qsrL9yZMnNHfuXPL29iZra2uSy+XUoEED8vLyoilTplB6erpS+Jo0MmVmZtKwYcOoQYMGYgW0Yro0LbuquIouXLhAAMjU1JRyc3Mlw+jq32xkIiIqKyujDRs2UHBwMNWrV4/kcjnZ2dlRu3btKC4ujrZu3UrFxcVEVNHgvHTpUoqOjiY3NzeysrIiExMTcnFxoYiICNq7d6/aNBw6dIhiYmLI2dmZjIyMyMLCglq2bEnh4eH03XffKVWcEhE9ePCA3njjDXJxcSEjIyNycnKi4cOH05UrV9TuI20amQQ7d+6ksLAwcZsdHByoS5cuNHv2bHr48KHWy/w3G5kKCwtpxowZ1Lx5c5LL5eTo6EjR0dF09epVrdL59ttvU7t27cjMzIyMjY3J2dmZevToQXPmzKGrV69qXLcmtdHIRKR7HiHQ5X4mpEXTT+pY6po2XRqZiouLad68edS+fXsyNTUlW1tb6tOnD+3evVvn6z4tLY0mTpxIXbp0ofr165OhoSHVr1+fvL296auvvqKnT59KpuH+/fs0c+ZM8vT0JAsLCzI0NKRGjRqRj48PJSUl0Z9//lnldqijTeMKkW55EVHV197hw4epT58+ZGlpSSYmJtSxY0f65ptvqLy8vFYamYiIioqKaMmSJdStWzeytrYW91vv3r1p8eLF1doPDx8+pHfffZdat24tns8eHh40Z84cev78uVJYXfPkq1ev0qxZsyggIICaNGlCxsbGZGNjQx06dKBp06apLasUFhbS0qVLqWfPnmJZ2NHRkdzd3Wn8+PH0+++/K4WvSb5ZVblRm0YmIqJnz57Rp59+Su7u7mRqakrGxsbUunVrmj59usr9pnKaSkpK6OOPPyY3NzcyMjIiW1tbioiIoL/++kvjOolIfPEqOjq6yrA1ISP6FzowZIwxxhhjjDHG2P9rI0eOxJo1a7Bq1SqMHDnyRSfnf9KMGTPw8ccfY+zYsVi2bNmLTg5jjDHGquHmzZto1qwZnJ2dJbts1EZZWRlcXFyQmZmJ9PR0yW6eawuPycQYY4wxxhhjjDH2H5ednY3FixdDT08PEydOfNHJYYwxxtgLtHz5cmRmZsLb27tOG5gAoI5GemKMMcYYY4wxxhhjdW3atGm4c+cO9uzZg7y8PIwbNw6tW7d+0clijDHG2L/s0qVLmDdvHu7du4ddu3ZBT08P8+fPr/P1ciMTY4wxxhhjjDGtfPfddzh48KBWYe3t7f+Vh1pWM7p0WxceHo7w8PA6Swurno0bNyIrKwv169fHxIkTMWfOHLVh58yZg4sXL2q1XDc3N0ybNq22kslYtXAexTR55513kJOTo1VYPz8/vPbaa3WcoprLycnBO++8o3X41157DX5+fnWYIvZfkp2djRUrVsDQ0BBt27bFrFmz4OPjU+fr5TGZGGOMMcYYY4xpRRhTRxs16UOe/XtkMpnWYZOSkjBr1qy6Swyrcz169MD+/fu1Cuvv74/U1NS6TRBjVeA8imnStGlTZGZmahU2NjYWq1evrtsE1QJhLB5t8TiH7GXAjUyMMcYYY4wxxhhjjDHGGGNMZ3ovOgGMMcYYY4wxxhhjjDHGGGPsv4cbmRhjjDHGGGOMMcYYY4wxxpjOuJGJMcYYY4wxxhhjjDHGGGOM6YwbmRhjjDHGGGOMMcYYY4wxxpjOuJGJMcYYY4wxxhhjjDHGGGOM6YwbmRhjjDHGGGOMMcYYY4wxxpjOuJGJMcYYY4wxxhhjjDHGGGOM6YwbmRhjjDHGGGOMMcYYY4wxxpjOuJGJMcYYY4wxxhhjjDHGGGOM6YwbmRhjjDHGGGOMMcYYY4wxxpjOuJGJMcYYY4wxxhhjjDHGGGOM6YwbmRhjjDHGGGOMMcYYY4wxxpjOuJGJMcYYY4wxxhhjjDHGGGOM6YwbmRhjjDHGGGOMMcYYY4wxxpjOuJGJMcYYY4wxxhhjjDHGGGOM6YwbmRhjjDHGGGOMMcYYY4wxxpjOuJGJMcYYY4wxxhhjjDHGGGOM6YwbmRhjjDHGGGOMMcYYY4wxxpjOuJGJMcYYY4wxxhhjjDHGGGOM6YwbmRhjjDHGGGOMMcYYY4wxxpjOuJGJMcYYY4wxxhhjjDHGGGOM6YwbmRhjjDHGGGOMMcYYY4wxxpjOuJGJMcYYY4wxxhhjjDHGGGOM6YwbmRhjjDHGGGOMMcYYY4wxxpjO/g/WB5WTFIfCEgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the plot\n",
    "plot = plot_critical_difference(combined_results.values,\n",
    "                                combined_results.columns.tolist(), \n",
    "                                alpha=0.15, \n",
    "                                lower_better=False)\n",
    "\n",
    "# Retrieve the figure and axes from the plot\n",
    "fig = plot[0].figure\n",
    "ax = plot[0]\n",
    "\n",
    "# Adjust figure size\n",
    "fig.set_size_inches(6, 3)\n",
    "\n",
    "# Adjust layout\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the figures\n",
    "fig.savefig(f\"{save_dir}PMLBmini_critical_difference.eps\", bbox_inches='tight')\n",
    "fig.savefig(f\"{save_dir}PMLBmini_critical_difference.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_latex_table(df):\n",
    "    table = \"\"\"\n",
    "\\\\begin{table}[t]\n",
    "\\\\caption{Test accuracies on the concentric circles task.}\n",
    "\\\\label{tab:concentric-circles}\n",
    "\\\\vskip 0.15in\n",
    "\\\\begin{center}\n",
    "\\\\begin{small}\n",
    "\\\\begin{sc}\n",
    "\\\\begin{tabular}{lcc}\n",
    "\\\\toprule\n",
    "Model & Mean Acc & Std Dev \\\\\\\\\n",
    "\\\\midrule\n",
    "\"\"\"\n",
    "    for model_name in df.columns:\n",
    "        accs = df[model_name]\n",
    "        mean_acc = np.mean(accs)\n",
    "        std_acc = np.std(accs)\n",
    "        table += f\"{model_name} & {mean_acc:.4f} & {std_acc:.4f} \\\\\\\\\\n\"\n",
    "    \n",
    "    table += \"\"\"\n",
    "\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "\\\\end{sc}\n",
    "\\\\end{small}\n",
    "\\\\end{center}\n",
    "\\\\vskip -0.1in\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "    return table\n",
    "\n",
    "# Example usage\n",
    "# Assuming `results_df` is your pandas DataFrame\n",
    "latex_table = create_latex_table(combined_results)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiment on single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found, loading\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, tensor\n",
    "import pandas as pd\n",
    "import tabmini\n",
    "import aeon\n",
    "from aeon.visualisation import plot_critical_difference, plot_significance\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from models.base import LogisticRegression\n",
    "from models.gridsearch_wrapper import SKLearnWrapper\n",
    "from models.random_feature_representation_boosting import GradientRFRBoostClassifier\n",
    "from models.end2end import End2EndMLPResNet\n",
    "\n",
    "class Config:\n",
    "    save_dir = Path.cwd() / \"results\" / \"PMLBmini\"\n",
    "\n",
    "\n",
    "\n",
    "#download dataset, cache it\n",
    "dataset_save_path = Config.save_dir / 'PMLBmini_dataset.pkl'\n",
    "if not os.path.exists(dataset_save_path):\n",
    "    print(\"Dataset not found, downloading\")\n",
    "    dataset = tabmini.load_dataset(reduced=False)\n",
    "    os.makedirs(Config.save_dir, exist_ok=True)\n",
    "    with open(dataset_save_path, 'wb') as f:\n",
    "        pickle.dump(dataset, f)\n",
    "else:\n",
    "    print(\"Dataset found, loading\")\n",
    "    with open(dataset_save_path, 'rb') as f:\n",
    "        dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 10: parity5\n",
    "X, y = dataset[\"parity5\"]\n",
    "# X, y = dataset[\"parity5\"]\n",
    "scaler = MinMaxScaler()\n",
    "#scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = torch.tensor(X).float()\n",
    "y = torch.tensor(y.values)[..., None].float()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits tensor([[ 23.14333915710449218750],\n",
      "        [-26.46641921997070312500],\n",
      "        [ 40.89808654785156250000],\n",
      "        [-42.63124847412109375000],\n",
      "        [ -6.75979614257812500000],\n",
      "        [ 21.31249427795410156250],\n",
      "        [-54.55385589599609375000],\n",
      "        [-38.07231521606445312500],\n",
      "        [-31.18783760070800781250],\n",
      "        [-24.93739128112792968750]])\n",
      "test AUC: 0.19999999999999998\n",
      "test accuracy: 0.20000000298023224\n",
      "test cross-entropy: 24.239530563354492\n",
      "train AUC: 1.0\n",
      "train accuracy: 1.0\n",
      "train cross-entropy: 0.0038458420895040035\n"
     ]
    }
   ],
   "source": [
    "# model = LogisticRegression(\n",
    "#     n_classes=2,\n",
    "#     l2_lambda=0.0001,\n",
    "#     max_iter = 300,\n",
    "# )\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = GradientRFRBoostClassifier(\n",
    "    in_dim=X.shape[1],\n",
    "    n_classes=2,\n",
    "    l2_cls=0.0001,\n",
    "    l2_ghat=0.00001,\n",
    "    n_layers=1,\n",
    "    randfeat_xt_dim=512,\n",
    "    randfeat_x0_dim=512,\n",
    "    hidden_dim=512,\n",
    "    upscale_type=\"SWIM\",\n",
    "    feature_type=\"SWIM\",\n",
    "    use_batchnorm=False,\n",
    "    boost_lr=1,\n",
    "    activation=\"relu\",\n",
    "    do_linesearch=False,\n",
    "    freeze_top_at_t=2,\n",
    "    ghat_ridge_solver=\"solve\",\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "logits = model(X_test)\n",
    "print(\"logits\", logits)\n",
    "probs = nn.functional.sigmoid(logits)\n",
    "# print(\"out and y\", torch.cat([logits, y_test], dim=1))\n",
    "# print(\"binary class pred and y\", torch.cat([probs > 0.5, y_test], dim=1))\n",
    "auc = roc_auc_score(y_test.numpy(), probs.detach().numpy())\n",
    "print(\"test AUC:\", auc)\n",
    "print(\"test accuracy:\", (probs > 0.5).eq(y_test).float().mean().item())\n",
    "print(\"test cross-entropy:\", nn.functional.binary_cross_entropy_with_logits(logits, y_test).item())\n",
    "\n",
    "#train\n",
    "model.eval()\n",
    "logits = model(X_train)\n",
    "probs = nn.functional.sigmoid(logits)\n",
    "auc = roc_auc_score(y_train.numpy(), probs.detach().numpy())\n",
    "print(\"train AUC:\", auc)\n",
    "print(\"train accuracy:\", (probs > 0.5).eq(y_train).float().mean().item())\n",
    "print(\"train cross-entropy:\", nn.functional.binary_cross_entropy_with_logits(logits, y_train).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO cross entropy loss\n",
    "# TODO ridgeCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bugfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 10: parity5\n",
    "X, y = dataset[\"analcatdata_fraud\"]\n",
    "# X, y = dataset[\"parity5\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=100, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=10, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=1, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.1, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.01, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.1s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.375 total time=   0.1s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.375 total time=   0.1s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.1s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.1s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.1s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.0s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.001, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.1s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.1s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=0.01, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.1s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.375 total time=   0.1s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.1s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=0.001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.1s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.1s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.1s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=0.0001, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.250 total time=   0.1s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.1s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.1s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.1s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.875 total time=   0.1s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=1e-05, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.500 total time=   0.1s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.800 total time=   0.1s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.1s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.875 total time=   0.1s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.1s\n",
      "[CV 1/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.600 total time=   0.1s\n",
      "[CV 2/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.1s\n",
      "[CV 3/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.625 total time=   0.1s\n",
      "[CV 5/5] END activation=tanh, boost_lr=1, do_linesearch=False, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=128, in_dim=11, l2_cls=0.0001, l2_ghat=1e-07, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=32, randfeat_xt_dim=32, seed=42, upscale_type=identity, use_batchnorm=False;, score=0.750 total time=   0.1s\n",
      "Best params: {'activation': 'tanh', 'boost_lr': 1, 'do_linesearch': False, 'feature_type': 'SWIM', 'freeze_top_at_t': 2, 'ghat_ridge_solver': 'solve', 'hidden_dim': 128, 'in_dim': 11, 'l2_cls': 0.01, 'l2_ghat': 1e-06, 'modelClass': <class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, 'n_classes': 2, 'n_layers': 1, 'randfeat_x0_dim': 32, 'randfeat_xt_dim': 32, 'seed': 42, 'upscale_type': 'identity', 'use_batchnorm': False}\n",
      "test AUC: 0.8250000000000001\n",
      "test accuracy: 0.6153846153846154\n",
      "naive test acc 0.6153846153846154\n",
      "train AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "from PMLBmini import WrapperGridSearch\n",
    "\n",
    "model = WrapperGridSearch(\n",
    "    param_grid={\n",
    "        \"modelClass\": [GradientRFRBoostClassifier],\n",
    "        \"l2_cls\": [100, 10, 1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        \"l2_ghat\": [0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001],\n",
    "        \"n_layers\": [1],\n",
    "        \"randfeat_xt_dim\": [32],\n",
    "        \"randfeat_x0_dim\": [32],\n",
    "        \"hidden_dim\": [128],\n",
    "        \"upscale_type\": [\"identity\"],\n",
    "        \"feature_type\": [\"SWIM\"],\n",
    "        \"use_batchnorm\": [False],\n",
    "        \"boost_lr\": [0.1, 1, 10],\n",
    "        \"activation\": [\"tanh\"],\n",
    "        \"do_linesearch\": [False],\n",
    "        \"freeze_top_at_t\": [2],\n",
    "        \"ghat_ridge_solver\": [\"solve\"],\n",
    "    },\n",
    "    verbose=3,\n",
    "    scaler=StandardScaler(),\n",
    "    seed=42,\n",
    "    scoring = \"roc_auc\",\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "pred_test = model.predict_proba(X_test)\n",
    "pred_train = model.predict_proba(X_train)\n",
    "print(\"test AUC:\", roc_auc_score(y_test, pred_test[:, 1]))\n",
    "print(\"test accuracy:\", (pred_test.argmax(axis=1) == y_test).mean())\n",
    "print(\"naive test acc\", (y_test == 0).mean())\n",
    "print(\"train AUC:\", roc_auc_score(y_train, pred_train[:, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
