{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMLBmini experiments\n",
    "\n",
    "This notebook runs the PMLBmini experiments, and compares RANDOM FEATURE BOOSTING and END2END to the saved PMLBmini models\n",
    "\n",
    "NOTE that we assume tabmini is installed in the cwd https://github.com/RicardoKnauer/TabMini \n",
    "\n",
    "Should take no more than 30 minutes to run this notebook, ie run all models and datasets sequentially on a single CPU core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, tensor\n",
    "import pandas as pd\n",
    "import tabmini\n",
    "import aeon\n",
    "from aeon.visualisation import plot_critical_difference, plot_significance\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "from models.gridsearch_wrapper import SKLearnWrapper\n",
    "from models.random_feature_representation_boosting import GradientRFRBoostClassifier\n",
    "from models.end2end import End2EndMLPResNet\n",
    "from PMLBmini import test_on_PMLBmini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#####      Equal/Random Guessing        ######\n",
    "##############################################\n",
    "\n",
    "\n",
    "class EqualGuessing(BaseEstimator, ClassifierMixin):\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Guess probabilty 0.5 for each class\"\"\"\n",
    "        # Guess [0.5, 0.5]\n",
    "        return np.ones((X.shape[0], 2)) * 0.5\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        # Get the probabilities from predict_proba\n",
    "        proba = self.predict_proba(X)\n",
    "        # Calculate the log of ratios for binary classification\n",
    "        decision = np.log((proba[:, 1] + 1e-10) / (proba[:, 0] + 1e-10))\n",
    "        return decision\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dir = \"/home/nikita/Code/random-feature-boosting/results/PMLBmini_rocauc/\"\n",
    "save_dir = \"/home/nikita/Code/random-feature-boosting/results/PMLBmini_scoring_experiments/\"\n",
    "# train_guessing_and_xgboost, test_guessing_and_xgboost = test_on_PMLBmini(\n",
    "#     EqualGuessing(),\n",
    "#     'EqualGuessing',\n",
    "#     [i for i in range(44)],\n",
    "#     save_dir, \n",
    "#     other_saved_methods={\"XGBoost\"},\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python PMLBmini.py \\\n",
    "#     --models E2E_MLP_ResNet \\\n",
    "#     --dataset_indices 0 \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/results/PMLBmini/ \\\n",
    "#     --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python PMLBmini.py \\\n",
    "#     --models \"Logistic(ours)\" \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/results/PMLBmini/ \\\n",
    "#     --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO wrong results for both built in rocauc and neglogloss\n",
    "# for i in range(44):\n",
    "#     !python PMLBmini.py \\\n",
    "#         --models \"Logistic(ours)\" \\\n",
    "#         --dataset_indices {i} \\\n",
    "#         --save_dir /home/nikita/Code/random-feature-boosting/results/PMLBmini/ \\\n",
    "#         --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python PMLBmini.py \\\n",
    "#     --models GRFRBoost_featSWIM_upiid_linesearchTrue_freezeFalse \\\n",
    "#     --dataset_indices 0 \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/results/PMLBmini/ \\\n",
    "#     --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AutoPrognosis</th>\n",
       "      <th>AutoGluon</th>\n",
       "      <th>TabPFN</th>\n",
       "      <th>Logistic regression</th>\n",
       "      <th>HyperFast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>parity5</th>\n",
       "      <td>0.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_fraud</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_aids</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_bankruptcy</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_japansolvent</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labor</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_asbestos</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lupus</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postoperative_patient_data</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_cyyoung9302</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_cyyoung8092</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_creditscore</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appendicitis</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>molecular_biology_promoters</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_boxing1</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mux6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_boxing2</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hepatitis</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corral</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glass2</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backache</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prnn_crabs</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonar</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biomed</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prnn_synth</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analcatdata_lawsuit</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spect</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_statlog</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_h</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hungarian</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleve</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_c</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haberman</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spectf</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colic</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horse_colic</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house_votes_84</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saheart</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irish</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             AutoPrognosis  AutoGluon  TabPFN  \\\n",
       "parity5                               0.27       1.00    0.02   \n",
       "analcatdata_fraud                     0.86       0.80    0.79   \n",
       "analcatdata_aids                      0.73       0.77    0.63   \n",
       "analcatdata_bankruptcy                0.98       0.98    0.96   \n",
       "analcatdata_japansolvent              0.85       0.88    0.91   \n",
       "labor                                 0.88       0.94    0.99   \n",
       "analcatdata_asbestos                  0.87       0.84    0.85   \n",
       "lupus                                 0.84       0.79    0.82   \n",
       "postoperative_patient_data            0.49       0.55    0.44   \n",
       "analcatdata_cyyoung9302               0.89       0.85    0.87   \n",
       "analcatdata_cyyoung8092               0.73       0.90    0.85   \n",
       "analcatdata_creditscore               1.00       0.99    1.00   \n",
       "appendicitis                          0.78       0.84    0.82   \n",
       "molecular_biology_promoters           0.88       0.93    0.88   \n",
       "analcatdata_boxing1                   0.89       0.89    0.76   \n",
       "mux6                                  1.00       1.00    1.00   \n",
       "analcatdata_boxing2                   0.82       0.78    0.71   \n",
       "hepatitis                             0.85       0.82    0.85   \n",
       "corral                                1.00       1.00    1.00   \n",
       "glass2                                0.89       0.91    0.89   \n",
       "backache                              0.60       0.72    0.75   \n",
       "prnn_crabs                            1.00       1.00    1.00   \n",
       "sonar                                 0.88       0.93    0.92   \n",
       "biomed                                1.00       0.96    0.95   \n",
       "prnn_synth                            0.94       0.95    0.95   \n",
       "analcatdata_lawsuit                   0.99       0.99    1.00   \n",
       "spect                                 0.84       0.82    0.83   \n",
       "heart_statlog                         0.91       0.89    0.90   \n",
       "breast_cancer                         0.69       0.69    0.73   \n",
       "heart_h                               0.87       0.89    0.88   \n",
       "hungarian                             0.86       0.86    0.86   \n",
       "cleve                                 0.90       0.89    0.89   \n",
       "heart_c                               0.91       0.91    0.91   \n",
       "haberman                              0.70       0.71    0.72   \n",
       "bupa                                  0.66       0.64    0.68   \n",
       "spectf                                0.91       0.94    0.93   \n",
       "ionosphere                            0.97       0.98    0.98   \n",
       "colic                                 0.87       0.86    0.87   \n",
       "horse_colic                           0.88       0.85    0.84   \n",
       "house_votes_84                        0.99       0.99    0.99   \n",
       "vote                                  1.00       0.99    1.00   \n",
       "saheart                               0.77       0.76    0.77   \n",
       "clean1                                0.93       1.00    0.99   \n",
       "irish                                 1.00       1.00    1.00   \n",
       "\n",
       "                             Logistic regression  HyperFast  \n",
       "parity5                                     0.17       0.02  \n",
       "analcatdata_fraud                           0.77       0.73  \n",
       "analcatdata_aids                            0.61       0.53  \n",
       "analcatdata_bankruptcy                      0.97       0.88  \n",
       "analcatdata_japansolvent                    0.85       0.91  \n",
       "labor                                       0.97       0.98  \n",
       "analcatdata_asbestos                        0.86       0.87  \n",
       "lupus                                       0.85       0.79  \n",
       "postoperative_patient_data                  0.38       0.34  \n",
       "analcatdata_cyyoung9302                     0.87       0.84  \n",
       "analcatdata_cyyoung8092                     0.79       0.84  \n",
       "analcatdata_creditscore                     0.94       0.87  \n",
       "appendicitis                                0.84       0.87  \n",
       "molecular_biology_promoters                 0.88       0.89  \n",
       "analcatdata_boxing1                         0.67       0.67  \n",
       "mux6                                        0.70       0.95  \n",
       "analcatdata_boxing2                         0.68       0.70  \n",
       "hepatitis                                   0.84       0.83  \n",
       "corral                                      0.96       1.00  \n",
       "glass2                                      0.72       0.79  \n",
       "backache                                    0.72       0.78  \n",
       "prnn_crabs                                  1.00       0.81  \n",
       "sonar                                       0.85       0.89  \n",
       "biomed                                      0.94       0.93  \n",
       "prnn_synth                                  0.94       0.94  \n",
       "analcatdata_lawsuit                         1.00       0.98  \n",
       "spect                                       0.82       0.83  \n",
       "heart_statlog                               0.89       0.89  \n",
       "breast_cancer                               0.70       0.69  \n",
       "heart_h                                     0.86       0.85  \n",
       "hungarian                                   0.85       0.84  \n",
       "cleve                                       0.88       0.88  \n",
       "heart_c                                     0.91       0.89  \n",
       "haberman                                    0.66       0.58  \n",
       "bupa                                        0.67       0.66  \n",
       "spectf                                      0.88       0.87  \n",
       "ionosphere                                  0.90       0.97  \n",
       "colic                                       0.86       0.86  \n",
       "horse_colic                                 0.82       0.83  \n",
       "house_votes_84                              0.99       0.98  \n",
       "vote                                        0.99       0.99  \n",
       "saheart                                     0.77       0.76  \n",
       "clean1                                      1.00       0.96  \n",
       "irish                                       0.83       0.97  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV and set the index\n",
    "saved_results = pd.read_csv('https://raw.githubusercontent.com/RicardoKnauer/TabMini/master/plotting/results/test_scores_wide_3600.csv', delimiter=\";\", index_col=0)\n",
    "saved_results.index.name = None\n",
    "saved_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all the models\n",
    "import itertools\n",
    "model_names = []\n",
    "for scoring in [\"auc\", \"acc\", \"crossentropy\"]:\n",
    "    model_names.append(f\"E2E_MLP_ResNet_{scoring}\")\n",
    "    model_names.append(f\"RFNN_{scoring}\")\n",
    "    for feat in [\"SWIM\"]:\n",
    "        for up in [\"identity\", \"SWIM\", \"iid\"]:\n",
    "            for linesearch in [True, False]:\n",
    "                for freeze in [False]:\n",
    "                    for activation in [\"tanh\", \"relu\"]:\n",
    "                            name = f\"GRFRBoost_feat{feat}_up{up}_linesearch{linesearch}_freeze{freeze}_{activation}_{scoring}\"\n",
    "                            model_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all the models\n",
    "import itertools\n",
    "model_names = []\n",
    "for scoring in [\"crossentropy\"]: # [\"auc\", \"acc\", \"crossentropy\"]:\n",
    "    model_names.append(f\"E2E_MLP_ResNet_{scoring}\")\n",
    "    model_names.append(f\"RFNN_{scoring}\")\n",
    "    # for feat in [\"SWIM\"]:\n",
    "    #     for up in [\"identity\", \"SWIM\", \"iid\"]:\n",
    "    #         for linesearch in [True, False]:\n",
    "    #             for freeze in [False]:\n",
    "    #                 for activation in [\"tanh\", \"relu\"]:\n",
    "    #                         name = f\"GRFRBoost_feat{feat}_up{up}_linesearch{linesearch}_freeze{freeze}_{activation}_{scoring}\"\n",
    "    #                         model_names.append(name)\n",
    "#model_names.append(\"GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_relu_crossentropy\")\n",
    "#model_names.append(\"GRFRBoost_featSWIM_upidentity_linesearchFalse_freezeFalse_relu_crossentropy\")\n",
    "model_names.append(\"GRFRBoost_featSWIM_upidentity_linesearchFalse_freezeFalse_tanh_crossentropy\")\n",
    "#model_names.append(\"GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeFalse_tanh_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # join all the models\n",
    "# import itertools\n",
    "# model_names = [\"E2E_MLP_ResNet\", \"RFNN\", #\"RFNN_relu\",\n",
    "#                 \"GRFRBoost_featSWIM_upidentity_linesearchTrue_freezeFalse_relu\",  \n",
    "#                 #\"GRFRBoost_featSWIM_upiid_linesearchFalse_freezeFalse\",    \n",
    "#                 #\"GRFRBoost_featSWIM_upidentity_linesearchFalse_freezeFalse_relu\", \n",
    "#                 #\"GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeFalse\",           \n",
    "#                 #\"GRFRBoost_featSWIM_upiid_linesearchFalse_freezeFalse_relu\",  \n",
    "#                 #\"GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeTrue\",\n",
    "#                ]\n",
    "# # for feat, up, linesearch, freeze, relu in itertools.product([\"SWIM\"], [\"SWIM\"], [False], [False], [\"_relu\"]):\n",
    "# #     name = f\"GRFRBoost_feat{feat}_up{up}_linesearch{linesearch}_freeze{freeze}{relu}\"\n",
    "# #     model_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [\"SWIM\"] # feat\n",
    "# [\"SWIM\", \"iid\", \"identity\"] # up\n",
    "# [False, True] # linesearch\n",
    "# [False] # freeze\n",
    "# [\"\", \"relu\"] # relu\n",
    "# [\"auc\", \"crossentropy\", \"acc\"] # scoring\n",
    "# #[\"ridge\", \"ridgecv\"] # ghat module        \n",
    "# 1*3*2*1*2*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results = saved_results.copy()\n",
    "for model_name in model_names:\n",
    "    results_one_model = [pd.read_csv(f\"{save_dir}{model_name}/test_{i}.csv\", index_col=0)\n",
    "                         for i in range(44)]\n",
    "    df_one_model = pd.concat(results_one_model, axis=0)\n",
    "    combined_results = combined_results.join(df_one_model)\n",
    "combined_results = combined_results.round(2)\n",
    "combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results.mean(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results.rank(axis=1, ascending=False).mean(axis=0).sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_columns = combined_results.columns[combined_results.isna().any()].tolist()\n",
    "print(nan_columns)\n",
    "combined_results[nan_columns]\n",
    "combined_results = combined_results.drop(columns=nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results.query(\"RFNN_auc > GRFRBoost_featSWIM_upSWIM_linesearchFalse_freezeFalse_relu_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the plot\n",
    "plot = plot_critical_difference(combined_results.values,\n",
    "                                combined_results.columns.tolist(), \n",
    "                                alpha=0.05, \n",
    "                                lower_better=False)\n",
    "\n",
    "# Retrieve the figure and axes from the plot\n",
    "fig = plot[0].figure\n",
    "ax = plot[0]\n",
    "\n",
    "# Adjust figure size\n",
    "fig.set_size_inches(20, 3)\n",
    "\n",
    "# Adjust layout\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the figures\n",
    "fig.savefig(f\"{save_dir}PMLBmini_critical_difference.eps\", bbox_inches='tight')\n",
    "fig.savefig(f\"{save_dir}PMLBmini_critical_difference.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_latex_table(df):\n",
    "    table = \"\"\"\n",
    "\\\\begin{table}[t]\n",
    "\\\\caption{Test accuracies on the concentric circles task.}\n",
    "\\\\label{tab:concentric-circles}\n",
    "\\\\vskip 0.15in\n",
    "\\\\begin{center}\n",
    "\\\\begin{small}\n",
    "\\\\begin{sc}\n",
    "\\\\begin{tabular}{lcc}\n",
    "\\\\toprule\n",
    "Model & Mean Acc & Std Dev \\\\\\\\\n",
    "\\\\midrule\n",
    "\"\"\"\n",
    "    for model_name in df.columns:\n",
    "        accs = df[model_name]\n",
    "        mean_acc = np.mean(accs)\n",
    "        std_acc = np.std(accs)\n",
    "        table += f\"{model_name} & {mean_acc:.4f} & {std_acc:.4f} \\\\\\\\\\n\"\n",
    "    \n",
    "    table += \"\"\"\n",
    "\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "\\\\end{sc}\n",
    "\\\\end{small}\n",
    "\\\\end{center}\n",
    "\\\\vskip -0.1in\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "    return table\n",
    "\n",
    "# Example usage\n",
    "# Assuming `results_df` is your pandas DataFrame\n",
    "latex_table = create_latex_table(combined_results)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiment on single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found, loading\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, tensor\n",
    "import pandas as pd\n",
    "import tabmini\n",
    "import aeon\n",
    "from aeon.visualisation import plot_critical_difference, plot_significance\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from models.base import LogisticRegression\n",
    "from models.gridsearch_wrapper import SKLearnWrapper\n",
    "from models.random_feature_representation_boosting import GradientRFRBoostClassifier\n",
    "from models.end2end import End2EndMLPResNet\n",
    "\n",
    "class Config:\n",
    "    save_dir = Path.cwd() / \"results\" / \"PMLBmini\"\n",
    "\n",
    "\n",
    "\n",
    "#download dataset, cache it\n",
    "dataset_save_path = Config.save_dir / 'PMLBmini_dataset.pkl'\n",
    "if not os.path.exists(dataset_save_path):\n",
    "    print(\"Dataset not found, downloading\")\n",
    "    dataset = tabmini.load_dataset(reduced=False)\n",
    "    os.makedirs(Config.save_dir, exist_ok=True)\n",
    "    with open(dataset_save_path, 'wb') as f:\n",
    "        pickle.dump(dataset, f)\n",
    "else:\n",
    "    print(\"Dataset found, loading\")\n",
    "    with open(dataset_save_path, 'rb') as f:\n",
    "        dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 10: parity5\n",
    "X, y = dataset[\"analcatdata_fraud\"]\n",
    "# X, y = dataset[\"parity5\"]\n",
    "scaler = MinMaxScaler()\n",
    "#scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = torch.tensor(X).float()\n",
    "y = torch.tensor(y.values)[..., None].float()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      7\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m GradientRFRBoostClassifier(\n\u001b[0;32m---> 10\u001b[0m     in_dim\u001b[38;5;241m=\u001b[39m\u001b[43mX\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     11\u001b[0m     n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     12\u001b[0m     l2_cls\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m     13\u001b[0m     l2_ghat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m,\n\u001b[1;32m     14\u001b[0m     n_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     15\u001b[0m     randfeat_xt_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m     16\u001b[0m     randfeat_x0_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m     17\u001b[0m     hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m     18\u001b[0m     upscale_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSWIM\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     feature_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSWIM\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     use_batchnorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m     boost_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     22\u001b[0m     activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     do_linesearch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m     freeze_top_at_t\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     25\u001b[0m     ghat_ridge_solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mridgecv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# model = LogisticRegression(\n",
    "#     n_classes=2,\n",
    "#     l2_lambda=0.0001,\n",
    "#     max_iter = 300,\n",
    "# )\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = GradientRFRBoostClassifier(\n",
    "    in_dim=X.shape[1],\n",
    "    n_classes=2,\n",
    "    l2_cls=0.01,\n",
    "    l2_ghat=0.0001,\n",
    "    n_layers=1,\n",
    "    randfeat_xt_dim=512,\n",
    "    randfeat_x0_dim=512,\n",
    "    hidden_dim=512,\n",
    "    upscale_type=\"SWIM\",\n",
    "    feature_type=\"SWIM\",\n",
    "    use_batchnorm=False,\n",
    "    boost_lr=1,\n",
    "    activation=\"tanh\",\n",
    "    do_linesearch=False,\n",
    "    freeze_top_at_t=2,\n",
    "    ghat_ridge_solver=\"ridgecv\",\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "logits = model(X_test)\n",
    "print(\"logits\", logits)\n",
    "probs = nn.functional.sigmoid(logits)\n",
    "# print(\"out and y\", torch.cat([logits, y_test], dim=1))\n",
    "# print(\"binary class pred and y\", torch.cat([probs > 0.5, y_test], dim=1))\n",
    "auc = roc_auc_score(y_test.numpy(), probs.detach().numpy())\n",
    "print(\"test AUC:\", auc)\n",
    "print(\"test accuracy:\", (probs > 0.5).eq(y_test).float().mean().item())\n",
    "print(\"test cross-entropy:\", nn.functional.binary_cross_entropy_with_logits(logits, y_test).item())\n",
    "\n",
    "#train\n",
    "model.eval()\n",
    "logits = model(X_train)\n",
    "probs = nn.functional.sigmoid(logits)\n",
    "auc = roc_auc_score(y_train.numpy(), probs.detach().numpy())\n",
    "print(\"train AUC:\", auc)\n",
    "print(\"train accuracy:\", (probs > 0.5).eq(y_train).float().mean().item())\n",
    "print(\"train cross-entropy:\", nn.functional.binary_cross_entropy_with_logits(logits, y_train).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO cross entropy loss\n",
    "# TODO ridgeCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bugfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 10: parity5\n",
    "X, y = dataset[\"analcatdata_fraud\"]\n",
    "# X, y = dataset[\"parity5\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV 1/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=10, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-1.489 total time=   0.1s\n",
      "[CV 2/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=10, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-0.648 total time=   0.1s\n",
      "[CV 3/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=10, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-0.862 total time=   0.1s\n",
      "[CV 1/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-1.660 total time=   0.1s\n",
      "[CV 2/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-0.637 total time=   0.1s\n",
      "[CV 3/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-0.918 total time=   0.1s\n",
      "[CV 1/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=0.1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-2.835 total time=   0.1s\n",
      "[CV 2/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=0.1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-0.545 total time=   0.1s\n",
      "[CV 3/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=0.1, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-1.533 total time=   0.1s\n",
      "[CV 1/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=0.01, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-4.614 total time=   0.1s\n",
      "[CV 2/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=0.01, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-0.619 total time=   0.1s\n",
      "[CV 3/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=0.01, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-1.900 total time=   0.1s\n",
      "[CV 1/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=0.001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-3.586 total time=   0.1s\n",
      "[CV 2/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=0.001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-0.597 total time=   0.1s\n",
      "[CV 3/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=0.001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-1.703 total time=   0.1s\n",
      "[CV 1/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=0.0001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-2.533 total time=   0.1s\n",
      "[CV 2/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=0.0001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-0.943 total time=   0.1s\n",
      "[CV 3/3] END activation=relu, boost_lr=1, do_linesearch=True, feature_type=SWIM, freeze_top_at_t=2, ghat_ridge_solver=solve, hidden_dim=512, in_dim=11, l2_cls=0.0001, l2_ghat=1e-06, modelClass=<class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, n_classes=2, n_layers=1, randfeat_x0_dim=512, randfeat_xt_dim=512, seed=42, upscale_type=SWIM, use_batchnorm=False;, score=-1.430 total time=   0.1s\n",
      "Best params: {'activation': 'relu', 'boost_lr': 1, 'do_linesearch': True, 'feature_type': 'SWIM', 'freeze_top_at_t': 2, 'ghat_ridge_solver': 'solve', 'hidden_dim': 512, 'in_dim': 11, 'l2_cls': 10, 'l2_ghat': 1e-06, 'modelClass': <class 'models.random_feature_representation_boosting.GradientRFRBoostClassifier'>, 'n_classes': 2, 'n_layers': 1, 'randfeat_x0_dim': 512, 'randfeat_xt_dim': 512, 'seed': 42, 'upscale_type': 'SWIM', 'use_batchnorm': False}\n",
      "test AUC: 0.775\n",
      "train AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "from PMLBmini import WrapperGridSearch\n",
    "\n",
    "model = WrapperGridSearch(\n",
    "    param_grid={\n",
    "        \"modelClass\": [GradientRFRBoostClassifier],\n",
    "        \"l2_cls\": [10, 1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        \"l2_ghat\": [0.000001],\n",
    "        \"n_layers\": [1],\n",
    "        \"randfeat_xt_dim\": [512],\n",
    "        \"randfeat_x0_dim\": [512],\n",
    "        \"hidden_dim\": [512],\n",
    "        \"upscale_type\": [\"SWIM\"],\n",
    "        \"feature_type\": [\"SWIM\"],\n",
    "        \"use_batchnorm\": [False],\n",
    "        \"boost_lr\": [1],\n",
    "        \"activation\": [\"relu\"],\n",
    "        \"do_linesearch\": [True],\n",
    "        \"freeze_top_at_t\": [2],\n",
    "        \"ghat_ridge_solver\": [\"solve\"],\n",
    "    },\n",
    "    verbose=3,\n",
    "    scaler=MinMaxScaler(),\n",
    "    seed=42,\n",
    "    scoring = \"neg_log_loss\",\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "pred_test = model.predict_proba(X_test)\n",
    "pred_train = model.predict_proba(X_train)\n",
    "print(\"test AUC:\", roc_auc_score(y_test, pred_test[:, 1]))\n",
    "print(\"train AUC:\", roc_auc_score(y_train, pred_train[:, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
