{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, tensor\n",
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "\n",
    "from optuna_kfoldCV import evaluate_dataset_with_model, run_all_openML_with_model\n",
    "from classification_param_specs import evaluate_LogisticRegression, evaluate_XGBoostClassifier\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fetch the collection with ID 99 https://www.openml.org/search?type=study&study_type=task&id=99&sort=runs_included\n",
    "# collection = openml.study.get_suite(99)\n",
    "# dataset_ids = collection.data\n",
    "# metadata_list = []\n",
    "\n",
    "# # Fetch and process each dataset\n",
    "# for i, dataset_id in enumerate(dataset_ids):\n",
    "#     dataset = openml.datasets.get_dataset(dataset_id)\n",
    "#     X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "#         target=dataset.default_target_attribute\n",
    "#     )\n",
    "\n",
    "#     #count missing values in X\n",
    "#     missing_values_count = X.isnull().sum().sum()\n",
    "#     print(f\"Missing values in X: {missing_values_count}\")\n",
    "\n",
    "#     X = np.array(X)\n",
    "#     y = np.array(y)[..., None]\n",
    "#     print(X.shape)\n",
    "#     print(y.shape)\n",
    "    \n",
    "#     # Determine if the dataset has categorical features\n",
    "#     has_categorical = any(categorical_indicator)\n",
    "    \n",
    "#     # Extract the required metadata\n",
    "#     metadata = {\n",
    "#         'dataset_id': dataset.id,\n",
    "#         'name': dataset.name,\n",
    "#         'n_obs': int(dataset.qualities['NumberOfInstances']),\n",
    "#         'n_features': int(dataset.qualities['NumberOfFeatures']),\n",
    "#         '%_unique_y': len(np.unique(y))/len(y),\n",
    "#         'n_unique_y': len(np.unique(y)),\n",
    "#         'has_categorical': has_categorical,\n",
    "#         'n_missing_values': missing_values_count,\n",
    "#     }\n",
    "    \n",
    "#     metadata_list.append(metadata)\n",
    "#     print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset.id}: {dataset.name}\")\n",
    "\n",
    "# # Create a DataFrame from the metadata list\n",
    "# df_metadata = pd.DataFrame(metadata_list).sort_values('%_unique_y', ascending=False).set_index(\"dataset_id\").sort_index()\n",
    "# df_metadata.sort_values('%_unique_y', ascending=True)\n",
    "\n",
    "# # Display the metadata DataFrame\n",
    "# df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 72)\n",
    "# df_metadata.head(72).sort_values(\"n_obs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_metadata.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna_kfoldCV import np_load_openml_dataset, openML_cls_ids\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for idx, id in enumerate(openML_cls_ids):\n",
    "    X,y = np_load_openml_dataset(id, \"classification\")\n",
    "    print(\"idx\", idx, \"id\", id, \"X\", X.shape, \"y\", y.shape, np.isnan(X).sum(), np.isnan(y).sum())\n",
    "\n",
    "# for id in df_metadata.index:\n",
    "#     X,y = np_load_openml_dataset(id, \"classification\")\n",
    "#     print(\"id\", id, \"X\", X.shape, \"y\", y.shape, np.isnan(X).sum(), np.isnan(y).sum())\n",
    "\n",
    "## TODO TODO TODO NEXT: investigate nans, and \"Mean of empty slice\". also look at less than 200 classes and check performance on reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments (just for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python classification_param_specs.py \\\n",
    "#     --models End2End \\\n",
    "#     --dataset_indices 0 2 \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLClassification/ \\\n",
    "#     --n_optuna_trials 2 \\\n",
    "#     --device cuda \\\n",
    "#     --k_folds 5 \\\n",
    "#     --cv_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python classification_param_specs.py \\\n",
    "#     --models LogisticRegression \\\n",
    "#     --dataset_indices 0 2 \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLClassification/ \\\n",
    "#     --n_optuna_trials 10 \\\n",
    "#     --device cuda \\\n",
    "#     --k_folds 2 \\\n",
    "#     --cv_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python classification_param_specs.py \\\n",
    "#     --models XGBoostClassifier \\\n",
    "#     --dataset_indices 0 2 \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLClassification/ \\\n",
    "#     --n_optuna_trials 2 \\\n",
    "#     --device cuda \\\n",
    "#     --k_folds 2 \\\n",
    "#     --cv_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python classification_param_specs.py \\\n",
    "#     --models RFNN \\\n",
    "#     --dataset_indices 0 2 \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLClassification/ \\\n",
    "#     --n_optuna_trials 2 \\\n",
    "#     --device cuda \\\n",
    "#     --k_folds 5 \\\n",
    "#     --cv_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python classification_param_specs.py \\\n",
    "#     --models RFRBoost \\\n",
    "#     --dataset_indices 0 2 \\\n",
    "#     --save_dir /home/nikita/Code/random-feature-boosting/save/OpenMLClassification/ \\\n",
    "#     --n_optuna_trials 2 \\\n",
    "#     --device cuda \\\n",
    "#     --k_folds 5 \\\n",
    "#     --cv_seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join json results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic.v1.utils import deep_update\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from optuna_kfoldCV import openML_cls_ids\n",
    "\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "def custom_deep_update(original, update):\n",
    "    for key, value in update.items():\n",
    "        if isinstance(value, dict) and key in original:\n",
    "            custom_deep_update(original[key], value)\n",
    "        else:\n",
    "            original[key] = value\n",
    "\n",
    "\n",
    "\n",
    "def get_joined_results_json(\n",
    "        models = [\"End2End\", \"Ridge\", \"XGBoostRegressor\",\n",
    "                  \"GradientRFRBoost\", \"GradientRFRBoostID\", \n",
    "                  \"GreedyRFRBoostDense\", \"GreedyRFRBoostDiag\", \"GreedyRFRBoostScalar\",\n",
    "                  \"RandomFeatureNetwork\"],\n",
    "        datasets = openML_cls_ids,\n",
    "        save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLClassification/\",\n",
    "        classification_or_regression = \"classification\",\n",
    "        ):\n",
    "    results_json = {}\n",
    "    for model in models:\n",
    "        for dataset in datasets:\n",
    "            path = os.path.join(save_dir, f\"{classification_or_regression}_{dataset}_{model}.json\")\n",
    "            res = read_json(path)\n",
    "            if results_json == {}:\n",
    "                results_json = res\n",
    "            else:\n",
    "                custom_deep_update(results_json, res)\n",
    "    return results_json\n",
    "\n",
    "\n",
    "\n",
    "def join_jsons_into_array(\n",
    "        results_json,\n",
    "        ):\n",
    "    results = []\n",
    "    for dataset, dataset_results in results_json.items():\n",
    "        res = []\n",
    "        for model_name, model_results in dataset_results.items():\n",
    "            model_res = np.stack([model_results[\"score_train\"], model_results[\"score_test\"], model_results[\"t_fit\"], model_results[\"t_inference\"]])\n",
    "            res.append(model_res)\n",
    "        results.append(res)\n",
    "    return np.stack(results) # (n_datasets, n_models, 4, n_folds)\n",
    "\n",
    "\n",
    "def results_to_df(\n",
    "        models = [\"End2End\", \"Ridge\", \"XGBoostRegressor\", \n",
    "                  \"GradientRFRBoost\", \"GradientRFRBoostID\", \n",
    "                  \"GradientRFRBoost_relu\",\n",
    "                  \"GreedyRFRBoostDense\", \"GreedyRFRBoostDiag\", \"GreedyRFRBoostScalar\",\n",
    "                  \"GreedyRFRBoostDense_relu\", \"GreedyRFRBoostDiag_relu\", \"GreedyRFRBoostScalar_relu\",\n",
    "                  \"RandomFeatureNetwork\", \"RandomFeatureNetwork_iid\",\n",
    "                  \"RandomFeatureNetwork_relu\", \"RandomFeatureNetwork_iid_relu\",\n",
    "                  ],\n",
    "        datasets = openML_cls_ids[:],\n",
    "        save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLClassification/\",\n",
    "        ):\n",
    "    # Load and join the JSON data\n",
    "    results_json = get_joined_results_json(models, datasets, save_dir)\n",
    "    results = join_jsons_into_array(results_json) # (n_datasets, n_models, 4, n_folds)\n",
    "    \n",
    "    # Calculate means and stds across folds\n",
    "    results_mean = np.mean(results, axis=-1)  # (n_datasets, n_models, 4)\n",
    "    results_std = np.std(results, axis=-1)    # (n_datasets, n_models, 4)\n",
    "    \n",
    "    # Create a dictionary to hold both mean and std DataFrames\n",
    "    metrics = [\"score_train\", \"score_test\", \"t_fit\", \"t_inference\"]\n",
    "    metric_dfs = {}\n",
    "    \n",
    "    # Initialize DataFrames for both mean and std metrics\n",
    "    for metric in metrics:\n",
    "        metric_dfs[metric] = pd.DataFrame(index=datasets, columns=models)\n",
    "        metric_dfs[f\"{metric}_std\"] = pd.DataFrame(index=datasets, columns=models)\n",
    "    \n",
    "    # Populate the DataFrames for each metric\n",
    "    for dataset_idx, dataset in enumerate(datasets):\n",
    "        for model_idx, model in enumerate(models):\n",
    "            for metric_idx, metric in enumerate(metrics):\n",
    "                # Set mean value\n",
    "                metric_dfs[metric].loc[dataset, model] = results_mean[dataset_idx, model_idx, metric_idx]\n",
    "                # Set* std value\n",
    "                metric_dfs[f\"{metric}_std\"].loc[dataset, model] = results_std[dataset_idx, model_idx, metric_idx]\n",
    "    \n",
    "    return metric_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"End2End_cpu\", \n",
    "                \"LogisticRegression\", \"XGBoostClassifier\", \n",
    "                \"RFNN\", \"RFNN_iid\",\n",
    "                ]\n",
    "for up in [\"\", \"_upscaleiid\", \"_ID\"]:\n",
    "    for bn in [\"\", \"_batchnormFalse\"]:\n",
    "        for ls in [\"\", \"_linesearchFalse\"]:\n",
    "            models.append(f\"RFRBoost{up}{ls}{bn}\")\n",
    "\n",
    "# for name in  [\"RFRBoost_upscaleiid\", \"RFRBoost_upscaleiid_linesearchFalse\", \n",
    "#               \"RFRBoost_upscaleiid_batchnormFalse\", \"RFRBoost_ID\",\n",
    "#               \"RFRBoost_linesearchFalse_batchnormFalse\",\n",
    "#               \"RFRBoost_upscaleiid_linesearchFalse_batchnormFalse\",\n",
    "#               \"End2End_cpu\",\n",
    "#               \"XGBoostClassifier\",]:\n",
    "#     models.remove(name)\n",
    "\n",
    "#save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLClassification/\"\n",
    "save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLClassification_ce/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(57):\n",
    "    for model in models:\n",
    "        try:\n",
    "            results = results_to_df(models=[model], datasets=[openML_cls_ids[i]],\n",
    "                                    save_dir=save_dir)\n",
    "        except:\n",
    "            print(f\"Failed for {model} on {i}, ie {openML_cls_ids[i]}\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results_to_df(        \n",
    "    models = models,\n",
    "    datasets = openML_cls_ids[[i for i in range(len(openML_cls_ids)) if i not in [33]]],\n",
    "    save_dir=save_dir,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = results_to_df(        \n",
    "    models = [\"End2End_cpu\", \n",
    "                \"LogisticRegression\", \n",
    "                \"XGBoostClassifier\", \n",
    "                \"RFNN\", \"RFNN_iid\", \n",
    "                \"RFRBoost_ID_batchnormFalse\",\n",
    "                #\"RFRBoost_upscaleiid_batchnormFalse\",\n",
    "                ],\n",
    "    datasets = openML_cls_ids[[i for i in range(len(openML_cls_ids)) if i not in [33]]],\n",
    "    save_dir=save_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].mean().sort_values(ascending=True)\n",
    "#ce ce ce ce ce\n",
    "# XGBoostClassifier                                    -0.857749\n",
    "# RFRBoost_ID_batchnormFalse                           -0.857634\n",
    "# RFRBoost_upscaleiid_batchnormFalse                   -0.857406\n",
    "# RFRBoost_upscaleiid_linesearchFalse_batchnormFalse   -0.857285\n",
    "# RFRBoost_ID_linesearchFalse_batchnormFalse           -0.857017\n",
    "# RFRBoost_batchnormFalse                              -0.856695\n",
    "# RFRBoost_linesearchFalse_batchnormFalse              -0.856688\n",
    "# RFRBoost                                             -0.854604\n",
    "# RFRBoost_linesearchFalse                             -0.854588\n",
    "# RFRBoost_upscaleiid_linesearchFalse                  -0.854255\n",
    "# RFRBoost_ID                                          -0.853843\n",
    "# RFRBoost_upscaleiid                                  -0.853546\n",
    "# End2End_cpu                                          -0.852974\n",
    "# RFRBoost_ID_linesearchFalse                          -0.851653\n",
    "# RFNN                                                 -0.850191\n",
    "# RFNN_iid                                              -0.84904\n",
    "# LogisticRegression                                   -0.828274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_train\"].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"t_fit\"].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].rank(axis=1).mean().sort_values()\n",
    "# GradientRFRBoost_upscaleiid        2.400000\n",
    "# GreedyRFRBoostDense_upscaleiid     2.400000\n",
    "# End2End                            3.542857\n",
    "# GreedyRFRBoostDiag_upscaleiid      3.685714\n",
    "# GreedyRFRBoostScalar_upscaleiid    4.657143\n",
    "# RandomFeatureNetwork_iid           5.371429\n",
    "# Ridge                              5.942857\n",
    "# dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"score_test\"].rank(axis=1) == 1).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.visualisation import plot_critical_difference, plot_significance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the plot\n",
    "plot = plot_critical_difference(df[\"score_test\"].values,\n",
    "                                df[\"score_test\"].columns.tolist(), \n",
    "                                alpha=0.05, \n",
    "                                lower_better=True)\n",
    "\n",
    "# Retrieve the figure and axes from the plot\n",
    "fig = plot[0].figure\n",
    "ax = plot[0]\n",
    "\n",
    "# Adjust figure size\n",
    "fig.set_size_inches(6, 3)\n",
    "\n",
    "# Adjust layout\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the figures\n",
    "plot[0].savefig(\"results/OpenMLClassification/OpenMLReg_critical_difference.eps\", bbox_inches='tight')\n",
    "plot[0].savefig(\"results/OpenMLClassification/OpenMLReg_critical_difference.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_latex_table(df):\n",
    "    table = \"\"\"\n",
    "\\\\begin{table}[t]\n",
    "\\\\caption{Test accuracies on the concentric circles task.}\n",
    "\\\\label{tab:concentric-circles}\n",
    "\\\\vskip 0.15in\n",
    "\\\\begin{center}\n",
    "\\\\begin{small}\n",
    "\\\\begin{sc}\n",
    "\\\\begin{tabular}{lcc}\n",
    "\\\\toprule\n",
    "Model & Mean Acc & Std Dev \\\\\\\\\n",
    "\\\\midrule\n",
    "\"\"\"\n",
    "    for model_name in df.columns:\n",
    "        accs = df[model_name]\n",
    "        mean_acc = np.mean(accs)\n",
    "        std_acc = np.std(accs)\n",
    "        table += f\"{model_name} & {mean_acc:.4f} & {std_acc:.4f} \\\\\\\\\\n\"\n",
    "    \n",
    "    table += \"\"\"\n",
    "\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "\\\\end{sc}\n",
    "\\\\end{small}\n",
    "\\\\end{center}\n",
    "\\\\vskip -0.1in\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "    return table\n",
    "\n",
    "# Example usage\n",
    "# Assuming `results_df` is your pandas DataFrame\n",
    "latex_table = create_latex_table(df_old[\"score_test\"])\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = results_to_df(        \n",
    "#     datasets = openML_reg_ids_noCat[[0,1,2  ,4,5,6,7,8,9,10,     13,14,15,16,17,18,19]],\n",
    "#     save_dir = \"/home/nikita/Code/random-feature-boosting/save/regv2_added40nlayers/OpenMLRegression/\",\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2[\"score_test\"].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2[\"score_train\"].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2[\"score_test\"].rank(axis=1).mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of first places\n",
    "# (df2[\"score_test\"].rank(axis=1) == 1).sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at small datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less5000 = df_metadata.query(\"n_obs < 5000\").index\n",
    "less1000 = df_metadata.query(\"n_obs < 1000\").index\n",
    "less5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].loc[less5000].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].loc[less5000].rank(axis=1).mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].loc[less5000].rank(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_test\"].loc[less1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at distribution of params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_param_distribution(\n",
    "        models = [#\"End2End_cpu\", \n",
    "                    \"LogisticRegression\", \"XGBoostClassifier\", \n",
    "                    #\"RFNN\", \"RFNN_iid\", \n",
    "                    \"RFRBoost_ID_batchnormFalse\",\n",
    "                    \"RFRBoost_upscaleiid_batchnormFalse\",\n",
    "                    ],\n",
    "        datasets = openML_cls_ids[[i for i in range(len(openML_cls_ids)) if i not in [33]]],\n",
    "        save_dir = \"/home/nikita/Code/random-feature-boosting/save/OpenMLClassification/\",\n",
    "        ):\n",
    "    # Load and join the JSON data\n",
    "    results_json = get_joined_results_json(models, datasets, save_dir)\n",
    "\n",
    "    # model: list_of_param_names\n",
    "    modelwise_param_names = {model: list(results_json[str(datasets[0])][model]['hyperparams'][0])\n",
    "                            for model in models} \n",
    "\n",
    "    # model: param_name: list_of_param_values\n",
    "    param_distribution = { model: {param: [] for param in param_names}\n",
    "                          for model, param_names in modelwise_param_names.items()}\n",
    "\n",
    "    #populate teh param_districution nested dict\n",
    "    for dataset, dataset_results in results_json.items():\n",
    "        for model_name, model_results in dataset_results.items():\n",
    "            for fold in model_results[\"hyperparams\"]:\n",
    "                for param_name, param_val in fold.items():\n",
    "                    param_distribution[model_name][param_name].append(param_val)\n",
    "\n",
    "    # For each model, plot the distribution of each parameter\n",
    "    for model, param_dict in param_distribution.items():\n",
    "        print(f\"Model: {model}\")\n",
    "        for param_name, param_values in param_dict.items():\n",
    "            if param_name not in [\n",
    "                \"out_dim\", \"loss\", \"objective\", \"feature_type\",\n",
    "                \"upscale_type\", \"sandwich_solver\", \"n_classes\", \"activation\",\n",
    "                \"use_batchnorm\", \"do_linesearch\",\n",
    "                ]:\n",
    "                print(param_name)\n",
    "                # Create figure with two subplots side by side\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "                \n",
    "                # Linear scale plot\n",
    "                ax1.hist(param_values, bins=20)\n",
    "                ax1.set_title(f\"{model} {param_name}\\n(linear scale)\")\n",
    "                ax1.set_xlabel(param_name)\n",
    "                ax1.set_ylabel(\"Count\")\n",
    "                \n",
    "                # Log scale plot\n",
    "                min_val = np.min(param_values)  # Avoid log(0)\n",
    "                max_val = np.max(param_values)\n",
    "                bins = np.logspace(np.log10(min_val), np.log10(max_val), 20)\n",
    "                ax2.hist(param_values, bins=bins)\n",
    "                ax2.set_xscale('log')\n",
    "                ax2.set_title(f\"{model} {param_name}\\n(log scale)\")\n",
    "                ax2.set_xlabel(param_name)\n",
    "                ax2.set_ylabel(\"Count\")\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "plot_param_distribution()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
