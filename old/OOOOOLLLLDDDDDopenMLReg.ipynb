{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, tensor\n",
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "#from aeon.regression.sklearn import RotationForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from preprocessing.stream_transforms import normalize_mean_std_traindata, normalize_streams, augment_time, add_basepoint_zero\n",
    "from utils.utils import print_name, print_shape\n",
    "from models import ResNet, NeuralEulerODE, RidgeCVModule, E2EResNet, StagewiseRandFeatBoostRegression\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import FittableModule, create_layer, GradientRandFeatBoostRegression\n",
    "from ridge_ALOOCV import fit_ridge_ALOOCV\n",
    "\n",
    "\n",
    "N = 100\n",
    "D = 50\n",
    "p = 30\n",
    "d = 4\n",
    "bottleneck_dim = 70\n",
    "\n",
    "gen = torch.Generator().manual_seed(42)\n",
    "X = torch.randn(N, D, generator=gen)\n",
    "y = torch.randn(N, d, generator=gen)\n",
    "model = GradientRandFeatBoostRegression(\n",
    "        gen,\n",
    "        hidden_dim = D,\n",
    "        bottleneck_dim = bottleneck_dim,\n",
    "        out_dim = d,\n",
    "        n_layers = 5,\n",
    "        upscale = \"dense\",\n",
    "    )\n",
    "_, _ = model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/35 Processed dataset 44956: abalone\n",
      " 2/35 Processed dataset 44957: airfoil_self_noise\n",
      " 3/35 Processed dataset 44958: auction_verification\n",
      " 4/35 Processed dataset 44959: concrete_compressive_strength\n",
      " 5/35 Processed dataset 44963: physiochemical_protein\n",
      " 6/35 Processed dataset 44964: superconductivity\n",
      " 7/35 Processed dataset 44965: geographical_origin_of_music\n",
      " 8/35 Processed dataset 44966: solar_flare\n",
      " 9/35 Processed dataset 44969: naval_propulsion_plant\n",
      " 10/35 Processed dataset 44971: white_wine\n",
      " 11/35 Processed dataset 44972: red_wine\n",
      " 12/35 Processed dataset 44973: grid_stability\n",
      " 13/35 Processed dataset 44974: video_transcoding\n",
      " 14/35 Processed dataset 44975: wave_energy\n",
      " 15/35 Processed dataset 44976: sarcos\n",
      " 16/35 Processed dataset 44977: california_housing\n",
      " 17/35 Processed dataset 44978: cpu_activity\n",
      " 18/35 Processed dataset 44979: diamonds\n",
      " 19/35 Processed dataset 44980: kin8nm\n",
      " 20/35 Processed dataset 44981: pumadyn32nh\n",
      " 21/35 Processed dataset 44983: miami_housing\n",
      " 22/35 Processed dataset 44984: cps88wages\n",
      " 23/35 Processed dataset 44987: socmob\n",
      " 24/35 Processed dataset 44989: kings_county\n",
      " 25/35 Processed dataset 44990: brazilian_houses\n",
      " 26/35 Processed dataset 44992: fps_benchmark\n",
      " 27/35 Processed dataset 44993: health_insurance\n",
      " 28/35 Processed dataset 45012: fifa\n",
      " 29/35 Processed dataset 41021: Moneyball\n",
      " 30/35 Processed dataset 44960: energy_efficiency\n",
      " 31/35 Processed dataset 44962: forest_fires\n",
      " 32/35 Processed dataset 44967: student_performance_por\n",
      " 33/35 Processed dataset 44970: QSAR_fish_toxicity\n",
      " 34/35 Processed dataset 44994: cars\n",
      " 35/35 Processed dataset 45402: space_ga\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>n_features</th>\n",
       "      <th>%_unique_y</th>\n",
       "      <th>n_unique_y</th>\n",
       "      <th>has_categorical</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41021</th>\n",
       "      <td>Moneyball</td>\n",
       "      <td>1232</td>\n",
       "      <td>15</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>374</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44956</th>\n",
       "      <td>abalone</td>\n",
       "      <td>4177</td>\n",
       "      <td>9</td>\n",
       "      <td>0.006703</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44957</th>\n",
       "      <td>airfoil_self_noise</td>\n",
       "      <td>1503</td>\n",
       "      <td>6</td>\n",
       "      <td>0.968729</td>\n",
       "      <td>1456</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44958</th>\n",
       "      <td>auction_verification</td>\n",
       "      <td>2043</td>\n",
       "      <td>8</td>\n",
       "      <td>0.998042</td>\n",
       "      <td>2039</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44959</th>\n",
       "      <td>concrete_compressive_strength</td>\n",
       "      <td>1030</td>\n",
       "      <td>9</td>\n",
       "      <td>0.910680</td>\n",
       "      <td>938</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44960</th>\n",
       "      <td>energy_efficiency</td>\n",
       "      <td>768</td>\n",
       "      <td>9</td>\n",
       "      <td>0.764323</td>\n",
       "      <td>587</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44962</th>\n",
       "      <td>forest_fires</td>\n",
       "      <td>517</td>\n",
       "      <td>13</td>\n",
       "      <td>0.485493</td>\n",
       "      <td>251</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44963</th>\n",
       "      <td>physiochemical_protein</td>\n",
       "      <td>45730</td>\n",
       "      <td>10</td>\n",
       "      <td>0.347759</td>\n",
       "      <td>15903</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44964</th>\n",
       "      <td>superconductivity</td>\n",
       "      <td>21263</td>\n",
       "      <td>82</td>\n",
       "      <td>0.141419</td>\n",
       "      <td>3007</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44965</th>\n",
       "      <td>geographical_origin_of_music</td>\n",
       "      <td>1059</td>\n",
       "      <td>117</td>\n",
       "      <td>0.029273</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44966</th>\n",
       "      <td>solar_flare</td>\n",
       "      <td>1066</td>\n",
       "      <td>11</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44967</th>\n",
       "      <td>student_performance_por</td>\n",
       "      <td>649</td>\n",
       "      <td>31</td>\n",
       "      <td>0.026194</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44969</th>\n",
       "      <td>naval_propulsion_plant</td>\n",
       "      <td>11934</td>\n",
       "      <td>15</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44970</th>\n",
       "      <td>QSAR_fish_toxicity</td>\n",
       "      <td>908</td>\n",
       "      <td>7</td>\n",
       "      <td>0.910793</td>\n",
       "      <td>827</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44971</th>\n",
       "      <td>white_wine</td>\n",
       "      <td>4898</td>\n",
       "      <td>12</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44972</th>\n",
       "      <td>red_wine</td>\n",
       "      <td>1599</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44973</th>\n",
       "      <td>grid_stability</td>\n",
       "      <td>10000</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44974</th>\n",
       "      <td>video_transcoding</td>\n",
       "      <td>68784</td>\n",
       "      <td>19</td>\n",
       "      <td>0.159339</td>\n",
       "      <td>10960</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44975</th>\n",
       "      <td>wave_energy</td>\n",
       "      <td>72000</td>\n",
       "      <td>49</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>71993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44976</th>\n",
       "      <td>sarcos</td>\n",
       "      <td>48933</td>\n",
       "      <td>22</td>\n",
       "      <td>0.233258</td>\n",
       "      <td>11414</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44977</th>\n",
       "      <td>california_housing</td>\n",
       "      <td>20640</td>\n",
       "      <td>9</td>\n",
       "      <td>0.186143</td>\n",
       "      <td>3842</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44978</th>\n",
       "      <td>cpu_activity</td>\n",
       "      <td>8192</td>\n",
       "      <td>22</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>56</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44979</th>\n",
       "      <td>diamonds</td>\n",
       "      <td>53940</td>\n",
       "      <td>10</td>\n",
       "      <td>0.215091</td>\n",
       "      <td>11602</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44980</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8192</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>8191</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44981</th>\n",
       "      <td>pumadyn32nh</td>\n",
       "      <td>8192</td>\n",
       "      <td>33</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>8191</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44983</th>\n",
       "      <td>miami_housing</td>\n",
       "      <td>13932</td>\n",
       "      <td>16</td>\n",
       "      <td>0.151522</td>\n",
       "      <td>2111</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44984</th>\n",
       "      <td>cps88wages</td>\n",
       "      <td>28155</td>\n",
       "      <td>7</td>\n",
       "      <td>0.212040</td>\n",
       "      <td>5970</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44987</th>\n",
       "      <td>socmob</td>\n",
       "      <td>1156</td>\n",
       "      <td>6</td>\n",
       "      <td>0.312284</td>\n",
       "      <td>361</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44989</th>\n",
       "      <td>kings_county</td>\n",
       "      <td>21613</td>\n",
       "      <td>22</td>\n",
       "      <td>0.186369</td>\n",
       "      <td>4028</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44990</th>\n",
       "      <td>brazilian_houses</td>\n",
       "      <td>10692</td>\n",
       "      <td>10</td>\n",
       "      <td>0.537879</td>\n",
       "      <td>5751</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44992</th>\n",
       "      <td>fps_benchmark</td>\n",
       "      <td>24624</td>\n",
       "      <td>44</td>\n",
       "      <td>0.108634</td>\n",
       "      <td>2675</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44993</th>\n",
       "      <td>health_insurance</td>\n",
       "      <td>22272</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>75</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44994</th>\n",
       "      <td>cars</td>\n",
       "      <td>804</td>\n",
       "      <td>18</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>798</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45012</th>\n",
       "      <td>fifa</td>\n",
       "      <td>19178</td>\n",
       "      <td>29</td>\n",
       "      <td>0.006935</td>\n",
       "      <td>133</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45402</th>\n",
       "      <td>space_ga</td>\n",
       "      <td>3107</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999356</td>\n",
       "      <td>3105</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     name  n_obs  n_features  %_unique_y  \\\n",
       "dataset_id                                                                 \n",
       "41021                           Moneyball   1232          15    0.303571   \n",
       "44956                             abalone   4177           9    0.006703   \n",
       "44957                  airfoil_self_noise   1503           6    0.968729   \n",
       "44958                auction_verification   2043           8    0.998042   \n",
       "44959       concrete_compressive_strength   1030           9    0.910680   \n",
       "44960                   energy_efficiency    768           9    0.764323   \n",
       "44962                        forest_fires    517          13    0.485493   \n",
       "44963              physiochemical_protein  45730          10    0.347759   \n",
       "44964                   superconductivity  21263          82    0.141419   \n",
       "44965        geographical_origin_of_music   1059         117    0.029273   \n",
       "44966                         solar_flare   1066          11    0.007505   \n",
       "44967             student_performance_por    649          31    0.026194   \n",
       "44969              naval_propulsion_plant  11934          15    0.004274   \n",
       "44970                  QSAR_fish_toxicity    908           7    0.910793   \n",
       "44971                          white_wine   4898          12    0.001429   \n",
       "44972                            red_wine   1599          12    0.003752   \n",
       "44973                      grid_stability  10000          13    1.000000   \n",
       "44974                   video_transcoding  68784          19    0.159339   \n",
       "44975                         wave_energy  72000          49    0.999903   \n",
       "44976                              sarcos  48933          22    0.233258   \n",
       "44977                  california_housing  20640           9    0.186143   \n",
       "44978                        cpu_activity   8192          22    0.006836   \n",
       "44979                            diamonds  53940          10    0.215091   \n",
       "44980                              kin8nm   8192           9    0.999878   \n",
       "44981                         pumadyn32nh   8192          33    0.999878   \n",
       "44983                       miami_housing  13932          16    0.151522   \n",
       "44984                          cps88wages  28155           7    0.212040   \n",
       "44987                              socmob   1156           6    0.312284   \n",
       "44989                        kings_county  21613          22    0.186369   \n",
       "44990                    brazilian_houses  10692          10    0.537879   \n",
       "44992                       fps_benchmark  24624          44    0.108634   \n",
       "44993                    health_insurance  22272          12    0.003367   \n",
       "44994                                cars    804          18    0.992537   \n",
       "45012                                fifa  19178          29    0.006935   \n",
       "45402                            space_ga   3107           7    0.999356   \n",
       "\n",
       "            n_unique_y  has_categorical  \n",
       "dataset_id                               \n",
       "41021              374             True  \n",
       "44956               28             True  \n",
       "44957             1456            False  \n",
       "44958             2039             True  \n",
       "44959              938            False  \n",
       "44960              587            False  \n",
       "44962              251             True  \n",
       "44963            15903            False  \n",
       "44964             3007            False  \n",
       "44965               31            False  \n",
       "44966                8             True  \n",
       "44967               17             True  \n",
       "44969               51            False  \n",
       "44970              827            False  \n",
       "44971                7            False  \n",
       "44972                6            False  \n",
       "44973            10000            False  \n",
       "44974            10960             True  \n",
       "44975            71993            False  \n",
       "44976            11414            False  \n",
       "44977             3842            False  \n",
       "44978               56            False  \n",
       "44979            11602             True  \n",
       "44980             8191            False  \n",
       "44981             8191            False  \n",
       "44983             2111            False  \n",
       "44984             5970             True  \n",
       "44987              361             True  \n",
       "44989             4028             True  \n",
       "44990             5751             True  \n",
       "44992             2675             True  \n",
       "44993               75             True  \n",
       "44994              798            False  \n",
       "45012              133             True  \n",
       "45402             3105            False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the collection with ID 353\n",
    "collection = openml.study.get_suite(353)\n",
    "dataset_ids = collection.data\n",
    "metadata_list = []\n",
    "\n",
    "# Fetch and process each dataset\n",
    "for i, dataset_id in enumerate(dataset_ids):\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        target=dataset.default_target_attribute\n",
    "    )\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)[..., None]\n",
    "    \n",
    "    # Determine if the dataset has categorical features\n",
    "    has_categorical = any(categorical_indicator)\n",
    "    \n",
    "    # Extract the required metadata\n",
    "    metadata = {\n",
    "        'dataset_id': dataset.id,\n",
    "        'name': dataset.name,\n",
    "        'n_obs': int(dataset.qualities['NumberOfInstances']),\n",
    "        'n_features': int(dataset.qualities['NumberOfFeatures']),\n",
    "        '%_unique_y': len(np.unique(y))/len(y),\n",
    "        'n_unique_y': len(np.unique(y)),\n",
    "        'has_categorical': has_categorical\n",
    "    }\n",
    "    \n",
    "    metadata_list.append(metadata)\n",
    "    print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset.id}: {dataset.name}\")\n",
    "\n",
    "# Create a DataFrame from the metadata list\n",
    "df_metadata = pd.DataFrame(metadata_list).sort_values('%_unique_y', ascending=False).set_index(\"dataset_id\").sort_index()\n",
    "df_metadata.sort_values('%_unique_y', ascending=True)\n",
    "\n",
    "# Display the metadata DataFrame\n",
    "df_metadata.loc[44962, \"has_categorical\"] = True\n",
    "df_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_openml_dataset(dataset_id, \n",
    "                        normalize_X:bool = True,\n",
    "                        normalize_y:bool = True,\n",
    "                        train_test_size:float = 0.7,\n",
    "                        split_seed:int = 0,\n",
    "                        device=\"cpu\",\n",
    "                        ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # Fetch dataset from OpenML by its ID\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    df, _, categorical_indicator, attribute_names = dataset.get_data()\n",
    "    df.dropna(inplace=True)\n",
    "    y = np.array(df.pop(dataset.default_target_attribute))[..., None]\n",
    "    X = np.array(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_test_size, random_state=split_seed)\n",
    "\n",
    "    #normalize\n",
    "    if normalize_X:\n",
    "        X_train, X_test = normalize_mean_std_traindata(X_train, X_test)\n",
    "        X_train = np.clip(X_train, -3, 3)\n",
    "        X_test = np.clip(X_test, -3, 3)\n",
    "    if normalize_y:\n",
    "        y_train, y_test = normalize_mean_std_traindata(y_train, y_test)\n",
    "\n",
    "    return (torch.tensor(X_train.astype(np.float32), requires_grad=False, device=device),\n",
    "            torch.tensor(X_test.astype(np.float32), requires_grad=False, device=device),\n",
    "            torch.tensor(y_train.astype(np.float32), requires_grad=False, device=device),\n",
    "            torch.tensor(y_test.astype(np.float32), requires_grad=False, device=device))\n",
    "\n",
    "#dataset_id = 44971  # Replace with the dataset ID you want\n",
    "dataset_id = 44971 #44970\n",
    "X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id, False, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import matplotlib.pyplot as plt\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# def get_activation(name, activations):\n",
    "#     def hook(model, input, output):\n",
    "#         activations[name] = output.detach()\n",
    "#     return hook\n",
    "\n",
    "\n",
    "# def register_hooks(model, activations):\n",
    "#     for name, layer in model.named_modules():\n",
    "#         print(name)\n",
    "#         if \".dense\" not in name:\n",
    "#             layer.register_forward_hook(get_activation(name, activations))\n",
    "\n",
    "\n",
    "\n",
    "# def neuron_distribution_for_each_layer(X_train, y_train, X_test):\n",
    "#     D = X_train.shape[1]\n",
    "#     n_layers = 2\n",
    "#     g1 = torch.Generator().manual_seed(0)\n",
    "#     model = SampledEulerODE(g1, D, 10*D, n_layers, upsample_module='sampled', sampling_method='gradient')\n",
    "#     #model = SampledResNet(g1, D, 10*D, 10*D, n_layers, upsample_module='sampled', sampling_method='gradient')\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     activations = {}\n",
    "#     register_hooks(model, activations)\n",
    "    \n",
    "#     # Forward pass\n",
    "#     model(X_test)\n",
    "    \n",
    "#     # Plot input data distribution\n",
    "#     fig = make_subplots(rows=1, cols=1)\n",
    "#     fig.add_trace(go.Histogram(x=X_train.flatten().cpu().numpy(), nbinsx=50, name='Train', histnorm='probability density', opacity=0.5))\n",
    "#     fig.add_trace(go.Histogram(x=X_test.flatten().cpu().numpy(), nbinsx=50, name='Test', histnorm='probability density', opacity=0.5))\n",
    "#     fig.update_layout(title_text='Input Data Distribution', xaxis_title='Input Feature Value', yaxis_title='Probability Density', barmode='overlay')\n",
    "#     fig.show()\n",
    "\n",
    "#     # Plot activations\n",
    "#     for name, activation in activations.items():\n",
    "#         fig = make_subplots(rows=1, cols=1)\n",
    "#         fig.add_trace(go.Histogram(x=activation.flatten().cpu().numpy(), nbinsx=50, name='Activation', histnorm='probability density', opacity=0.5))\n",
    "#         fig.update_layout(title_text=f'Activations at Layer: {name}', xaxis_title='Activation Value', yaxis_title='Probability Density', barmode='overlay')\n",
    "#         fig.show()\n",
    "\n",
    "\n",
    "# neuron_distribution_for_each_layer(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit on a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_allmodels_1dataset(\n",
    "        generator: torch.Generator,\n",
    "        X_train: Tensor,\n",
    "        y_train: Tensor,\n",
    "        X_test: Tensor,\n",
    "        y_test: Tensor,\n",
    "        ):\n",
    "    \n",
    "    D = X_train.shape[1]\n",
    "    hidden_size = 128\n",
    "    bottleneck_dim = hidden_size\n",
    "\n",
    "    # (name, model, kwargs). kwargs separate to save memory\n",
    "    model_list = [\n",
    "        [\"RidgeCV\", RidgeCVModule, {}],\n",
    "\n",
    "        [\"T=3 End2End\", E2EResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": bottleneck_dim,\n",
    "                \"out_dim\": 1,\n",
    "                \"n_blocks\": 2,\n",
    "                \"activation\": nn.ReLU(),\n",
    "                \"loss\": nn.MSELoss(),\n",
    "                \"lr\": 1e-3,\n",
    "                \"epochs\": 50,\n",
    "                \"batch_size\": 64,}\n",
    "                ],\n",
    "\n",
    "        [\"T=1 Dense\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                 \"in_dim\": D,\n",
    "                 \"hidden_size\": hidden_size,\n",
    "                 \"bottleneck_dim\": None,\n",
    "                 \"n_blocks\": 0,\n",
    "                 \"upsample_layer\": \"dense\",}\n",
    "                 ],\n",
    "\n",
    "        [\"T=1 SWIM Grad\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": None,\n",
    "                \"n_blocks\": 0,\n",
    "                \"upsample_layer\": \"SWIM\",}\n",
    "                ],\n",
    "        \n",
    "        [\"T=1 SWIM Unif\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": None,\n",
    "                \"n_blocks\": 0,\n",
    "                \"upsample_layer\": \"SWIM\",\n",
    "                \"sampling_method\": \"uniform\",}\n",
    "                ],\n",
    "    ]\n",
    "\n",
    "    for n_blocks in [2, 4]:\n",
    "        model_list += [\n",
    "        [f\"T={n_blocks+1} ResSWIM Grad-dense\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": bottleneck_dim,\n",
    "                \"n_blocks\": n_blocks,\n",
    "                \"upsample_layer\": \"SWIM\",\n",
    "                \"res_layer1\": \"SWIM\",\n",
    "                \"res_layer2\": \"dense\",}\n",
    "                ],\n",
    "\n",
    "        [f\"T={n_blocks+1} ResSWIM Grad-id\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": hidden_size,\n",
    "                \"n_blocks\": n_blocks,\n",
    "                \"upsample_layer\": \"SWIM\",\n",
    "                \"res_layer1\": \"SWIM\",\n",
    "                \"res_layer2\": \"identity\",}\n",
    "                ],\n",
    "                \n",
    "        [f\"T={n_blocks+1} ResDense\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": hidden_size,\n",
    "                \"n_blocks\": n_blocks,\n",
    "                \"upsample_layer\": \"dense\",\n",
    "                \"res_layer1\": \"dense\",\n",
    "                \"res_layer2\": \"identity\",}\n",
    "                ],\n",
    "        ]\n",
    "        \n",
    "    for n_layers in range(0, 50, 5):\n",
    "        model_list += [\n",
    "        [f\"StagewiseRandFeatBoost_{n_layers}\", StagewiseRandFeatBoostRegression,\n",
    "                {\"generator\": generator,\n",
    "                \"hidden_dim\": hidden_size,\n",
    "                \"bottleneck_dim\": bottleneck_dim,\n",
    "                \"out_dim\": 1,\n",
    "                \"n_layers\": n_layers,\n",
    "                \"activation\": nn.Tanh(),\n",
    "                \"l2_reg\": 1,  #TODO experiment with much higher l2reg than 0.01\n",
    "                \"feature_type\": \"SWIM\",\n",
    "                \"boost_lr\": 1.0,\n",
    "                \"upscale\": \"dense\",}\n",
    "                ],\n",
    "        \n",
    "        [f\"GradientRandFeatBoost_{n_layers}\", GradientRandFeatBoostRegression,\n",
    "                {\"generator\": generator,\n",
    "                \"hidden_dim\": hidden_size,\n",
    "                \"bottleneck_dim\": bottleneck_dim,\n",
    "                \"out_dim\": 1,\n",
    "                \"n_layers\": n_layers,\n",
    "                \"activation\": nn.Tanh(),\n",
    "                \"l2_reg\": 1,  #TODO experiment with much higher l2reg than 0.01\n",
    "                \"feature_type\": \"SWIM\",\n",
    "                \"boost_lr\": 1.0,\n",
    "                \"upscale\": \"dense\",}\n",
    "                ],\n",
    "        ]\n",
    "    \n",
    "    results = []\n",
    "    model_names = []\n",
    "    for name, model, model_args in model_list:\n",
    "        t0 = time.perf_counter()\n",
    "        model = model(**model_args).to(X_train.device)\n",
    "        pred_train, _ = model.fit(X_train, y_train)\n",
    "        t1 = time.perf_counter()\n",
    "        pred_test = model(X_test)\n",
    "        t2 = time.perf_counter()\n",
    "        rmse_train = root_mean_squared_error(y_train.cpu(), pred_train.cpu().detach()) \n",
    "        rmse_test = root_mean_squared_error(y_test.cpu(), pred_test.cpu().detach())\n",
    "\n",
    "        result = np.array( [rmse_train, rmse_test, t1-t0, t2-t1] )\n",
    "        results.append( result )\n",
    "        model_names.append( name )\n",
    "\n",
    "    return model_names, results\n",
    "\n",
    "\n",
    "\n",
    "def run_all_experiments(\n",
    "        dataset_ids: List,\n",
    "        name_save: str = \"PLACEHOLDER\",\n",
    "        device=\"cuda\",\n",
    "        ):\n",
    "    # Fetch and process each dataset\n",
    "    experiments = {}\n",
    "    for i, dataset_id in enumerate(dataset_ids):\n",
    "        X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id, split_seed=0, device=device)\n",
    "        generator = torch.Generator(device=device).manual_seed(999)\n",
    "        results = run_allmodels_1dataset(\n",
    "            generator, X_train, y_train, X_test, y_test, \n",
    "            )\n",
    "        experiments[dataset_id] = results\n",
    "        print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset_id}\")\n",
    "\n",
    "    # Save results\n",
    "    # Assuming experiments is a dict where keys are dataset names and values are tuples (model_names, results)\n",
    "    attributes = [\"RMSE_train\", \"RMSE_test\", \"t_fit\", \"t_feat\"]\n",
    "    data_list = []\n",
    "    # Process the data\n",
    "    for dataset_name, (model_names, results) in experiments.items():\n",
    "        dataset_data = {}\n",
    "        for attr_idx, attribute in enumerate(attributes):\n",
    "            for model_idx, model_name in enumerate(model_names):\n",
    "                dataset_data[(attribute, model_name)] = results[model_idx][attr_idx]\n",
    "        data_list.append(pd.DataFrame(dataset_data, index=[dataset_name]))\n",
    "\n",
    "    # Combine all datasets into a single DataFrame\n",
    "    df = pd.concat(data_list)\n",
    "    df = df.sort_index(axis=1)\n",
    "    print(df)\n",
    "    df.to_pickle(f\"OpenML_reg_{name_save}.pkl\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids_not_categorical = list(df_metadata.query(\"has_categorical == False\").index.values)\n",
    "dataset_ids_not_categorical = sorted([int(x) for x in dataset_ids_not_categorical])\n",
    "run_all_experiments(dataset_ids_not_categorical[0:3], name_save=\"FIRSTBOOST128TestingGradient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GradientRandFeatBoost_0</th>\n",
       "      <th>GradientRandFeatBoost_10</th>\n",
       "      <th>GradientRandFeatBoost_15</th>\n",
       "      <th>GradientRandFeatBoost_20</th>\n",
       "      <th>GradientRandFeatBoost_25</th>\n",
       "      <th>GradientRandFeatBoost_30</th>\n",
       "      <th>GradientRandFeatBoost_35</th>\n",
       "      <th>GradientRandFeatBoost_40</th>\n",
       "      <th>GradientRandFeatBoost_45</th>\n",
       "      <th>GradientRandFeatBoost_5</th>\n",
       "      <th>...</th>\n",
       "      <th>T=1 Dense</th>\n",
       "      <th>T=1 SWIM Grad</th>\n",
       "      <th>T=1 SWIM Unif</th>\n",
       "      <th>T=3 End2End</th>\n",
       "      <th>T=3 ResDense</th>\n",
       "      <th>T=3 ResSWIM Grad-dense</th>\n",
       "      <th>T=3 ResSWIM Grad-id</th>\n",
       "      <th>T=5 ResDense</th>\n",
       "      <th>T=5 ResSWIM Grad-dense</th>\n",
       "      <th>T=5 ResSWIM Grad-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44957</th>\n",
       "      <td>0.674485</td>\n",
       "      <td>0.437022</td>\n",
       "      <td>0.349125</td>\n",
       "      <td>0.417815</td>\n",
       "      <td>0.433439</td>\n",
       "      <td>0.374685</td>\n",
       "      <td>0.416047</td>\n",
       "      <td>0.396203</td>\n",
       "      <td>0.378156</td>\n",
       "      <td>0.418616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424680</td>\n",
       "      <td>0.476077</td>\n",
       "      <td>0.500399</td>\n",
       "      <td>0.344883</td>\n",
       "      <td>0.429560</td>\n",
       "      <td>0.347232</td>\n",
       "      <td>0.376446</td>\n",
       "      <td>0.421611</td>\n",
       "      <td>0.431505</td>\n",
       "      <td>0.373735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44959</th>\n",
       "      <td>0.542131</td>\n",
       "      <td>0.378737</td>\n",
       "      <td>0.364350</td>\n",
       "      <td>0.351177</td>\n",
       "      <td>0.358760</td>\n",
       "      <td>0.351232</td>\n",
       "      <td>0.375590</td>\n",
       "      <td>0.361841</td>\n",
       "      <td>0.368902</td>\n",
       "      <td>0.362432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377728</td>\n",
       "      <td>0.423298</td>\n",
       "      <td>0.446550</td>\n",
       "      <td>0.402130</td>\n",
       "      <td>0.415131</td>\n",
       "      <td>0.391737</td>\n",
       "      <td>0.379706</td>\n",
       "      <td>0.422805</td>\n",
       "      <td>0.354249</td>\n",
       "      <td>0.353861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44960</th>\n",
       "      <td>0.304226</td>\n",
       "      <td>0.223144</td>\n",
       "      <td>0.224409</td>\n",
       "      <td>0.170269</td>\n",
       "      <td>0.196235</td>\n",
       "      <td>0.161322</td>\n",
       "      <td>0.179944</td>\n",
       "      <td>0.160644</td>\n",
       "      <td>0.146851</td>\n",
       "      <td>0.235378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200248</td>\n",
       "      <td>0.259649</td>\n",
       "      <td>0.264216</td>\n",
       "      <td>0.261491</td>\n",
       "      <td>0.218697</td>\n",
       "      <td>0.235113</td>\n",
       "      <td>0.248284</td>\n",
       "      <td>0.228240</td>\n",
       "      <td>0.174280</td>\n",
       "      <td>0.235032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GradientRandFeatBoost_0  GradientRandFeatBoost_10  \\\n",
       "44957                 0.674485                  0.437022   \n",
       "44959                 0.542131                  0.378737   \n",
       "44960                 0.304226                  0.223144   \n",
       "\n",
       "       GradientRandFeatBoost_15  GradientRandFeatBoost_20  \\\n",
       "44957                  0.349125                  0.417815   \n",
       "44959                  0.364350                  0.351177   \n",
       "44960                  0.224409                  0.170269   \n",
       "\n",
       "       GradientRandFeatBoost_25  GradientRandFeatBoost_30  \\\n",
       "44957                  0.433439                  0.374685   \n",
       "44959                  0.358760                  0.351232   \n",
       "44960                  0.196235                  0.161322   \n",
       "\n",
       "       GradientRandFeatBoost_35  GradientRandFeatBoost_40  \\\n",
       "44957                  0.416047                  0.396203   \n",
       "44959                  0.375590                  0.361841   \n",
       "44960                  0.179944                  0.160644   \n",
       "\n",
       "       GradientRandFeatBoost_45  GradientRandFeatBoost_5  ...  T=1 Dense  \\\n",
       "44957                  0.378156                 0.418616  ...   0.424680   \n",
       "44959                  0.368902                 0.362432  ...   0.377728   \n",
       "44960                  0.146851                 0.235378  ...   0.200248   \n",
       "\n",
       "       T=1 SWIM Grad  T=1 SWIM Unif  T=3 End2End  T=3 ResDense  \\\n",
       "44957       0.476077       0.500399     0.344883      0.429560   \n",
       "44959       0.423298       0.446550     0.402130      0.415131   \n",
       "44960       0.259649       0.264216     0.261491      0.218697   \n",
       "\n",
       "       T=3 ResSWIM Grad-dense  T=3 ResSWIM Grad-id  T=5 ResDense  \\\n",
       "44957                0.347232             0.376446      0.421611   \n",
       "44959                0.391737             0.379706      0.422805   \n",
       "44960                0.235113             0.248284      0.228240   \n",
       "\n",
       "       T=5 ResSWIM Grad-dense  T=5 ResSWIM Grad-id  \n",
       "44957                0.431505             0.373735  \n",
       "44959                0.354249             0.353861  \n",
       "44960                0.174280             0.235032  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg = pd.read_pickle(\"OpenML_reg_FIRSTBOOST128TestingGradient.pkl\")\n",
    "df_reg[\"RMSE_test\"]#.mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"RMSE_test\"].rank(axis=1).mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"RMSE_train\"].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"RMSE_train\"].rank(axis=1).mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.read_pickle(\"OpenML_reg_FIRSTBOOST128.pkl\")\n",
    "df_reg[\"RMSE_test\"].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"RMSE_test\"].rank(axis=1).mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"RMSE_train\"].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"RMSE_train\"].rank(axis=1).mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.read_pickle(\"OpenML_reg_FIRSTBOOST512.pkl\")    # BAD TEST PERFORMANCE DUE TO REGULARIZATION ??\n",
    "df_reg[\"RMSE_test\"].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"RMSE_test\"].rank(axis=1).mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"RMSE_train\"].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"RMSE_train\"].rank(axis=1).mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.read_pickle(\"OpenML_reg_FIRSTBOOST512lambda1.pkl\")\n",
    "df_reg[\"RMSE_test\"].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"RMSE_test\"].rank(axis=1).mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"RMSE_train\"].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"RMSE_train\"].rank(axis=1).mean().sort_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
