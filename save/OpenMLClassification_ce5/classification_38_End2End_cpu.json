{
    "38": {
        "End2End_cpu": {
            "score_train": [
                -0.9956910610198975,
                -0.9963539838790894,
                -0.9893969297409058,
                -0.9956924915313721,
                -0.9946984648704529
            ],
            "score_test": [
                -0.9801324605941772,
                -0.9721854329109192,
                -0.9641909599304199,
                -0.9721485376358032,
                -0.9814323782920837
            ],
            "t_fit": [
                6.7611437030136585,
                19.042665548622608,
                7.741758309304714,
                8.25425872951746,
                2.8328491374850273
            ],
            "t_inference": [
                0.1018255464732647,
                0.45304106175899506,
                0.21484467759728432,
                0.17806537076830864,
                0.03843894600868225
            ],
            "hyperparams": [
                {
                    "in_dim": 53,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 140,
                    "lr": 0.005596199857569791,
                    "end_lr_factor": 0.22675150858921703,
                    "n_epochs": 16,
                    "weight_decay": 2.499592997509386e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 53,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 387,
                    "lr": 0.0017224029167054369,
                    "end_lr_factor": 0.3210216163459306,
                    "n_epochs": 13,
                    "weight_decay": 4.436786383545069e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 53,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 224,
                    "lr": 0.007041830285015997,
                    "end_lr_factor": 0.7321173243252596,
                    "n_epochs": 10,
                    "weight_decay": 1.306699123790696e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 53,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 244,
                    "lr": 0.005291702241868763,
                    "end_lr_factor": 0.22062557999765972,
                    "n_epochs": 19,
                    "weight_decay": 4.487221539476381e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 53,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 54,
                    "lr": 0.005645370405444329,
                    "end_lr_factor": 0.022600260222963027,
                    "n_epochs": 14,
                    "weight_decay": 3.4845368510123474e-05,
                    "batch_size": 128
                }
            ]
        }
    }
}