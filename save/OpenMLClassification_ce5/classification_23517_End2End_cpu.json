{
    "23517": {
        "End2End_cpu": {
            "score_train": [
                -0.5554999709129333,
                -0.5527499914169312,
                -0.5712500214576721,
                -0.5565000176429749,
                -0.5532500147819519
            ],
            "score_test": [
                -0.49000000953674316,
                -0.5,
                -0.5009999871253967,
                -0.5130000114440918,
                -0.5019999742507935
            ],
            "t_fit": [
                19.414408683776855,
                6.838275156915188,
                4.366548113524914,
                4.228883847594261,
                7.032156888395548
            ],
            "t_inference": [
                0.07375866174697876,
                0.04450297728180885,
                0.045476071536540985,
                0.028019875288009644,
                0.020399954169988632
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 18,
                    "lr": 8.665605811563105e-06,
                    "end_lr_factor": 0.01021502773978826,
                    "n_epochs": 38,
                    "weight_decay": 2.3638002725045744e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 34,
                    "lr": 2.582577784701748e-05,
                    "end_lr_factor": 0.03556515420372144,
                    "n_epochs": 22,
                    "weight_decay": 0.00010321121627209844,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 34,
                    "lr": 4.9607461685451223e-05,
                    "end_lr_factor": 0.023820176782732582,
                    "n_epochs": 22,
                    "weight_decay": 3.9742185434291234e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 30,
                    "lr": 2.134962240787932e-05,
                    "end_lr_factor": 0.308438581587028,
                    "n_epochs": 28,
                    "weight_decay": 1.3205801065109335e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 16,
                    "lr": 4.2084342201828125e-05,
                    "end_lr_factor": 0.03346192906720423,
                    "n_epochs": 40,
                    "weight_decay": 5.2943123726691854e-05,
                    "batch_size": 128
                }
            ]
        }
    }
}