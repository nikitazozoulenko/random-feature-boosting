{
    "1067": {
        "End2End_cpu": {
            "score_train": [
                -0.8713693022727966,
                -0.8903378844261169,
                -0.8778897523880005,
                -0.8796680569648743,
                -0.8678910136222839
            ],
            "score_test": [
                -0.8459715843200684,
                -0.8388625383377075,
                -0.8530805706977844,
                -0.879146933555603,
                -0.8622328042984009
            ],
            "t_fit": [
                2.1432019472122192,
                4.780478470027447,
                7.049195997416973,
                2.6094759553670883,
                5.494882524013519
            ],
            "t_inference": [
                0.05576173961162567,
                0.1830236092209816,
                0.14647489041090012,
                0.06693621724843979,
                0.16345352679491043
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 180,
                    "lr": 0.00975863397997576,
                    "end_lr_factor": 0.1425823891414629,
                    "n_epochs": 12,
                    "weight_decay": 2.0229054788359202e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 205,
                    "lr": 0.0021144930057191355,
                    "end_lr_factor": 0.044903736694868676,
                    "n_epochs": 11,
                    "weight_decay": 9.774761387570664e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 473,
                    "lr": 0.0071730361312205854,
                    "end_lr_factor": 0.05252230229592663,
                    "n_epochs": 19,
                    "weight_decay": 2.0560659393070405e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 111,
                    "lr": 0.004827065652419994,
                    "end_lr_factor": 0.22396317454911482,
                    "n_epochs": 14,
                    "weight_decay": 1.5453593643479413e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 165,
                    "lr": 0.009740765491173847,
                    "end_lr_factor": 0.24949731452106402,
                    "n_epochs": 15,
                    "weight_decay": 1.0462014278285746e-06,
                    "batch_size": 384
                }
            ]
        }
    }
}