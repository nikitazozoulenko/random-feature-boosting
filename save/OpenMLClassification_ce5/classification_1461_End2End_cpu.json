{
    "1461": {
        "End2End_cpu": {
            "score_train": [
                -0.953249990940094,
                -0.96875,
                -0.984499990940094,
                -0.9595000147819519,
                -0.9327499866485596
            ],
            "score_test": [
                -0.8960000276565552,
                -0.8799999952316284,
                -0.8980000019073486,
                -0.902999997138977,
                -0.8970000147819519
            ],
            "t_fit": [
                22.639623587951064,
                14.62099008820951,
                12.931782342493534,
                22.22742171958089,
                2.1209019124507904
            ],
            "t_inference": [
                1.0333783403038979,
                0.3969052769243717,
                0.25459347292780876,
                0.945726690813899,
                0.03454001620411873
            ],
            "hyperparams": [
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 282,
                    "lr": 0.007569728236281961,
                    "end_lr_factor": 0.4933799056481472,
                    "n_epochs": 10,
                    "weight_decay": 0.0001529743056346572,
                    "batch_size": 512
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 206,
                    "lr": 0.009463858974439247,
                    "end_lr_factor": 0.9954092520256412,
                    "n_epochs": 10,
                    "weight_decay": 1.0261131941550911e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 439,
                    "lr": 0.00021118005948978148,
                    "end_lr_factor": 0.11517367485380342,
                    "n_epochs": 20,
                    "weight_decay": 4.258767750199385e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 323,
                    "lr": 0.002623769706226226,
                    "end_lr_factor": 0.3458067804400432,
                    "n_epochs": 10,
                    "weight_decay": 2.400119793072907e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 23,
                    "lr": 0.005387426425965274,
                    "end_lr_factor": 0.1215967097815562,
                    "n_epochs": 10,
                    "weight_decay": 1.3284846887510624e-06,
                    "batch_size": 384
                }
            ]
        }
    }
}