{
    "23381": {
        "End2End_cpu": {
            "score_train": [
                -0.7149999737739563,
                -0.7275000214576721,
                -0.7275000214576721,
                -0.625,
                -0.5799999833106995
            ],
            "score_test": [
                -0.550000011920929,
                -0.5799999833106995,
                -0.44999998807907104,
                -0.5600000023841858,
                -0.6000000238418579
            ],
            "t_fit": [
                0.30240365862846375,
                1.682802814990282,
                0.5228725001215935,
                0.6928417384624481,
                0.8706363439559937
            ],
            "t_inference": [
                0.003463190048933029,
                0.022453993558883667,
                0.013494975864887238,
                0.006237436085939407,
                0.01021164283156395
            ],
            "hyperparams": [
                {
                    "in_dim": 156,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 27,
                    "lr": 0.00014594337268066473,
                    "end_lr_factor": 0.01966114746123373,
                    "n_epochs": 27,
                    "weight_decay": 2.2787072951260122e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 156,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 444,
                    "lr": 1.8630003253255134e-05,
                    "end_lr_factor": 0.32719147357778716,
                    "n_epochs": 39,
                    "weight_decay": 0.000523888397995593,
                    "batch_size": 256
                },
                {
                    "in_dim": 156,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 188,
                    "lr": 6.112067512799287e-05,
                    "end_lr_factor": 0.10690014510893395,
                    "n_epochs": 19,
                    "weight_decay": 5.0684391351771745e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 156,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 156,
                    "lr": 1.2042467825441224e-05,
                    "end_lr_factor": 0.6228649704405248,
                    "n_epochs": 42,
                    "weight_decay": 3.724958415483584e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 156,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 164,
                    "lr": 7.020801142507004e-07,
                    "end_lr_factor": 0.17481585047374837,
                    "n_epochs": 37,
                    "weight_decay": 1.2963147767839409e-05,
                    "batch_size": 256
                }
            ]
        }
    }
}