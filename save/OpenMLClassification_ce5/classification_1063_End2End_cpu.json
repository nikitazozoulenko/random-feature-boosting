{
    "1063": {
        "End2End_cpu": {
            "score_train": [
                -0.9064748287200928,
                -0.8992805480957031,
                -0.940191388130188,
                -0.8660287261009216,
                -0.8540669679641724
            ],
            "score_test": [
                -0.8571428656578064,
                -0.800000011920929,
                -0.807692289352417,
                -0.8365384340286255,
                -0.807692289352417
            ],
            "t_fit": [
                1.1642145961523056,
                0.554577648639679,
                1.4381904304027557,
                1.3418404906988144,
                0.4378020912408829
            ],
            "t_inference": [
                0.011309757828712463,
                0.0069627463817596436,
                0.010918602347373962,
                0.04216073453426361,
                0.010744690895080566
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 23,
                    "lr": 0.006872857683664231,
                    "end_lr_factor": 0.04231720179525468,
                    "n_epochs": 24,
                    "weight_decay": 4.777433867757023e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 18,
                    "lr": 0.008262579543831017,
                    "end_lr_factor": 0.12006470001746324,
                    "n_epochs": 15,
                    "weight_decay": 8.90269545704806e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 22,
                    "lr": 0.009690812277011974,
                    "end_lr_factor": 0.0322695495694654,
                    "n_epochs": 31,
                    "weight_decay": 2.1363567298804255e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 502,
                    "lr": 0.0032871548408982525,
                    "end_lr_factor": 0.9884157497089997,
                    "n_epochs": 11,
                    "weight_decay": 3.4218794844289387e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 20,
                    "lr": 0.008968599174790263,
                    "end_lr_factor": 0.027081097391983073,
                    "n_epochs": 19,
                    "weight_decay": 6.987007178648714e-06,
                    "batch_size": 256
                }
            ]
        }
    }
}