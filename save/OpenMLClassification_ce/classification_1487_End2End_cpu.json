{
    "1487": {
        "End2End_cpu": {
            "score_train": [
                -0.9620128273963928,
                -0.9748396873474121,
                -0.9555994272232056,
                -0.9546127319335938,
                -0.9531558156013489
            ],
            "score_test": [
                -0.9408283829689026,
                -0.9230769276618958,
                -0.9368836283683777,
                -0.9605522751808167,
                -0.9505928754806519
            ],
            "t_fit": [
                2.5251572746783495,
                2.9743340648710728,
                4.909694999456406,
                0.6512306444346905,
                1.559261403977871
            ],
            "t_inference": [
                0.09326021932065487,
                0.07909001968801022,
                0.2021377645432949,
                0.019624875858426094,
                0.04578469879925251
            ],
            "hyperparams": [
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 343,
                    "lr": 0.002356591734626829,
                    "end_lr_factor": 0.16379746266824446,
                    "n_epochs": 14,
                    "weight_decay": 2.8628409688062728e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 384,
                    "lr": 0.0024626066752633244,
                    "end_lr_factor": 0.2041665698062739,
                    "n_epochs": 13,
                    "weight_decay": 4.119908799475188e-05,
                    "batch_size": 384
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 434,
                    "lr": 0.005741128919760849,
                    "end_lr_factor": 0.18050279506304648,
                    "n_epochs": 13,
                    "weight_decay": 2.7519044647577167e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 142,
                    "lr": 0.006886441659952456,
                    "end_lr_factor": 0.5337458425512817,
                    "n_epochs": 13,
                    "weight_decay": 1.434378429822127e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 423,
                    "lr": 0.002478092159711725,
                    "end_lr_factor": 0.20942389202627915,
                    "n_epochs": 14,
                    "weight_decay": 6.010901856017489e-05,
                    "batch_size": 512
                }
            ]
        }
    }
}