{
    "1590": {
        "End2End": {
            "score_train": [
                -0.9082499742507935,
                -0.8799999952316284,
                -0.8852499723434448,
                -0.9024999737739563,
                -0.8884999752044678
            ],
            "score_test": [
                -0.8510000109672546,
                -0.8460000157356262,
                -0.8450000286102295,
                -0.8539999723434448,
                -0.8379999995231628
            ],
            "t_fit": [
                5.526565428823233,
                2.6584263909608126,
                9.336342338472605,
                5.542752459645271,
                6.122120041400194
            ],
            "t_inference": [
                0.1423873696476221,
                0.09529935196042061,
                0.39694536104798317,
                0.15827510878443718,
                0.2669702246785164
            ],
            "hyperparams": [
                {
                    "in_dim": 105,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 206,
                    "lr": 0.009463858974439247,
                    "end_lr_factor": 0.9954092520256412,
                    "n_epochs": 10,
                    "weight_decay": 1.0261131941550911e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 105,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 512,
                    "lr": 0.005379886940603703,
                    "end_lr_factor": 0.09035406384769393,
                    "n_epochs": 12,
                    "weight_decay": 3.6768977897391466e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 105,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 473,
                    "lr": 0.005328011761778827,
                    "end_lr_factor": 0.2206672400073423,
                    "n_epochs": 11,
                    "weight_decay": 2.0213243414543202e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 105,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 206,
                    "lr": 0.009463858974439247,
                    "end_lr_factor": 0.9954092520256412,
                    "n_epochs": 10,
                    "weight_decay": 1.0261131941550911e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 105,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 307,
                    "lr": 0.006075878073242489,
                    "end_lr_factor": 0.31756541427626367,
                    "n_epochs": 10,
                    "weight_decay": 6.359385836344312e-06,
                    "batch_size": 512
                }
            ]
        }
    }
}