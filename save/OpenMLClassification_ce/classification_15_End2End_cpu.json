{
    "15": {
        "End2End_cpu": {
            "score_train": [
                -0.9982110857963562,
                -0.9946332573890686,
                -0.9785330891609192,
                -0.9874776601791382,
                -0.9928571581840515
            ],
            "score_test": [
                -0.9642857313156128,
                -0.9642857313156128,
                -0.9785714149475098,
                -0.949999988079071,
                -0.9928057789802551
            ],
            "t_fit": [
                1.8491936642676592,
                0.5384765602648258,
                1.06395055167377,
                0.6235259789973497,
                3.4057977814227343
            ],
            "t_inference": [
                0.017354711890220642,
                0.011381007730960846,
                0.015424801036715508,
                0.019388608634471893,
                0.06353563442826271
            ],
            "hyperparams": [
                {
                    "in_dim": 9,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 429,
                    "lr": 0.00014616367460124023,
                    "end_lr_factor": 0.05316547075292591,
                    "n_epochs": 26,
                    "weight_decay": 1.3777630772823224e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 9,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 169,
                    "lr": 0.00031454627946541546,
                    "end_lr_factor": 0.25687615272793474,
                    "n_epochs": 15,
                    "weight_decay": 3.355118072893588e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 9,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 81,
                    "lr": 8.223989619494095e-05,
                    "end_lr_factor": 0.016961059229030594,
                    "n_epochs": 33,
                    "weight_decay": 5.041374477273884e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 9,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 183,
                    "lr": 0.009871706944607471,
                    "end_lr_factor": 0.6272469276392137,
                    "n_epochs": 11,
                    "weight_decay": 1.808240044604732e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 9,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 459,
                    "lr": 1.6684918980317623e-05,
                    "end_lr_factor": 0.32107788010212285,
                    "n_epochs": 18,
                    "weight_decay": 8.80152056025461e-06,
                    "batch_size": 128
                }
            ]
        }
    }
}