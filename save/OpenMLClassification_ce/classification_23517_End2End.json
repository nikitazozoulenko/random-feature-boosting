{
    "23517": {
        "End2End": {
            "score_train": [
                -0.5554999709129333,
                -0.5527499914169312,
                -0.5712500214576721,
                -0.5565000176429749,
                -0.5532500147819519
            ],
            "score_test": [
                -0.49000000953674316,
                -0.5,
                -0.5009999871253967,
                -0.5130000114440918,
                -0.5019999742507935
            ],
            "t_fit": [
                4.399121163412929,
                1.8515649959445,
                1.356108007952571,
                1.8806183561682701,
                2.9385352469980717
            ],
            "t_inference": [
                0.022485850378870964,
                0.012649619951844215,
                0.013278588652610779,
                0.013822691515088081,
                0.006700264289975166
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 18,
                    "lr": 8.665605811563105e-06,
                    "end_lr_factor": 0.01021502773978826,
                    "n_epochs": 38,
                    "weight_decay": 2.3638002725045744e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 34,
                    "lr": 2.582577784701748e-05,
                    "end_lr_factor": 0.03556515420372144,
                    "n_epochs": 22,
                    "weight_decay": 0.00010321121627209844,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 34,
                    "lr": 4.9607461685451223e-05,
                    "end_lr_factor": 0.023820176782732582,
                    "n_epochs": 22,
                    "weight_decay": 3.9742185434291234e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 30,
                    "lr": 2.134962240787932e-05,
                    "end_lr_factor": 0.308438581587028,
                    "n_epochs": 28,
                    "weight_decay": 1.3205801065109335e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 16,
                    "lr": 4.2084342201828125e-05,
                    "end_lr_factor": 0.03346192906720423,
                    "n_epochs": 40,
                    "weight_decay": 5.2943123726691854e-05,
                    "batch_size": 128
                }
            ]
        }
    }
}