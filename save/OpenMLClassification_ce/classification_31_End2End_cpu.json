{
    "31": {
        "End2End_cpu": {
            "score_train": [
                -0.8374999761581421,
                -0.8012499809265137,
                -0.7950000166893005,
                -0.7649999856948853,
                -0.8125
            ],
            "score_test": [
                -0.6650000214576721,
                -0.7850000262260437,
                -0.7099999785423279,
                -0.7599999904632568,
                -0.7250000238418579
            ],
            "t_fit": [
                1.034311018884182,
                1.9862221032381058,
                1.0435298345983028,
                1.560840219259262,
                1.1551272459328175
            ],
            "t_inference": [
                0.003939956426620483,
                0.007540583610534668,
                0.00847245380282402,
                0.00487760454416275,
                0.01088731363415718
            ],
            "hyperparams": [
                {
                    "in_dim": 63,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 34,
                    "lr": 0.00010349840115649271,
                    "end_lr_factor": 0.13509145321633328,
                    "n_epochs": 40,
                    "weight_decay": 4.321979960692149e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 63,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 34,
                    "lr": 0.00011144640296813431,
                    "end_lr_factor": 0.019756111259377436,
                    "n_epochs": 37,
                    "weight_decay": 2.068282731324016e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 63,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 54,
                    "lr": 8.801556750515267e-05,
                    "end_lr_factor": 0.02685951165627019,
                    "n_epochs": 17,
                    "weight_decay": 4.4015858042017515e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 63,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 26,
                    "lr": 6.425766822588106e-05,
                    "end_lr_factor": 0.015421858433089457,
                    "n_epochs": 39,
                    "weight_decay": 4.866000807696875e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 63,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 49,
                    "lr": 0.00012613987323556846,
                    "end_lr_factor": 0.017145446511547237,
                    "n_epochs": 21,
                    "weight_decay": 1.0105870062137303e-06,
                    "batch_size": 128
                }
            ]
        }
    }
}