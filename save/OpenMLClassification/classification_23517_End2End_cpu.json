{
    "23517": {
        "End2End_cpu": {
            "score_train": [
                -0.5295000076293945,
                -0.7754999995231628,
                -0.5292500257492065,
                -0.5295000076293945,
                -0.6602500081062317
            ],
            "score_test": [
                -0.5299999713897705,
                -0.4749999940395355,
                -0.49799999594688416,
                -0.5170000195503235,
                -0.5149999856948853
            ],
            "t_fit": [
                2.867239272221923,
                7.855686508119106,
                6.3795535285025835,
                3.2501796893775463,
                8.765181940048933
            ],
            "t_inference": [
                0.02100847288966179,
                0.08585052751004696,
                0.039289968088269234,
                0.022122452035546303,
                0.1293142084032297
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 43,
                    "lr": 6.7890532716984874e-06,
                    "end_lr_factor": 0.08168455894760163,
                    "n_epochs": 35,
                    "weight_decay": 3.972110727381911e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 30,
                    "lr": 5.610569954175871e-05,
                    "end_lr_factor": 0.19734691210112648,
                    "n_epochs": 29,
                    "weight_decay": 4.7198427505731835e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 39,
                    "lr": 7.771322896537152e-07,
                    "end_lr_factor": 0.29487236238425935,
                    "n_epochs": 45,
                    "weight_decay": 2.38073091839262e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 43,
                    "lr": 6.7890532716984874e-06,
                    "end_lr_factor": 0.08168455894760163,
                    "n_epochs": 35,
                    "weight_decay": 3.972110727381911e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 126,
                    "lr": 1.2560811327015675e-05,
                    "end_lr_factor": 0.1184738600583327,
                    "n_epochs": 22,
                    "weight_decay": 1.5568723397902253e-05,
                    "batch_size": 256
                }
            ]
        }
    }
}