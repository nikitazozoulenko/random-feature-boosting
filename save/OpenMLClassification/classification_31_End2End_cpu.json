{
    "31": {
        "End2End_cpu": {
            "score_train": [
                -0.9574999809265137,
                -0.9975000023841858,
                -0.8887500166893005,
                -0.8224999904632568,
                -0.9850000143051147
            ],
            "score_test": [
                -0.675000011920929,
                -0.7300000190734863,
                -0.75,
                -0.7900000214576721,
                -0.7699999809265137
            ],
            "t_fit": [
                15.668190032243729,
                5.119452059268951,
                1.1332528591156006,
                2.3146178126335144,
                1.5422333925962448
            ],
            "t_inference": [
                0.15012161433696747,
                0.07172441482543945,
                0.03052280843257904,
                0.08566002547740936,
                0.03999847173690796
            ],
            "hyperparams": [
                {
                    "in_dim": 63,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 325,
                    "lr": 0.04693368710353262,
                    "end_lr_factor": 0.1448372995001952,
                    "n_epochs": 40,
                    "weight_decay": 3.5619875347691735e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 63,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 155,
                    "lr": 0.0231574690570574,
                    "end_lr_factor": 0.2640370960760196,
                    "n_epochs": 26,
                    "weight_decay": 2.4090010172868964e-05,
                    "batch_size": 384
                },
                {
                    "in_dim": 63,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 190,
                    "lr": 0.02315943909154707,
                    "end_lr_factor": 0.16341665575013334,
                    "n_epochs": 13,
                    "weight_decay": 6.427866451896479e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 63,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 341,
                    "lr": 0.011421052065074686,
                    "end_lr_factor": 0.17743694265282858,
                    "n_epochs": 16,
                    "weight_decay": 2.0113857806650915e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 63,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 341,
                    "lr": 0.007590711534676563,
                    "end_lr_factor": 0.04423214826484754,
                    "n_epochs": 16,
                    "weight_decay": 5.132592385283824e-06,
                    "batch_size": 384
                }
            ]
        }
    }
}