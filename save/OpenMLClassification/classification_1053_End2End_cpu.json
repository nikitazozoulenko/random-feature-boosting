{
    "1053": {
        "End2End_cpu": {
            "score_train": [
                -0.8182500004768372,
                -0.8252500295639038,
                -0.8097500205039978,
                -0.8165000081062317,
                -0.8142499923706055
            ],
            "score_test": [
                -0.8059999942779541,
                -0.8059999942779541,
                -0.8209999799728394,
                -0.7929999828338623,
                -0.8230000138282776
            ],
            "t_fit": [
                7.55213076621294,
                40.45841134339571,
                4.372953165322542,
                1.7724655009806156,
                1.9039225205779076
            ],
            "t_inference": [
                0.1921388953924179,
                0.9988831281661987,
                0.1402510367333889,
                0.024499423801898956,
                0.0433630645275116
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 42,
                    "lr": 0.0544761188891818,
                    "end_lr_factor": 0.03059587537167688,
                    "n_epochs": 16,
                    "weight_decay": 0.00021859838067188073,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 408,
                    "lr": 0.0030192594536809975,
                    "end_lr_factor": 0.13401701200425134,
                    "n_epochs": 13,
                    "weight_decay": 0.0001286635568566186,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 69,
                    "lr": 0.03477087588865795,
                    "end_lr_factor": 0.07699061454360155,
                    "n_epochs": 13,
                    "weight_decay": 3.4076035759365937e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 19,
                    "lr": 0.09582128549086498,
                    "end_lr_factor": 0.11636613878930728,
                    "n_epochs": 15,
                    "weight_decay": 0.0006215464679232551,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 89,
                    "lr": 0.06359157650482442,
                    "end_lr_factor": 0.17331788636132678,
                    "n_epochs": 13,
                    "weight_decay": 2.1269456352695767e-06,
                    "batch_size": 384
                }
            ]
        }
    }
}