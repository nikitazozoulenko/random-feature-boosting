{
    "1053": {
        "End2End_cpu": {
            "score_train": [
                -0.8169999718666077,
                -0.8197500109672546,
                -0.8159999847412109,
                -0.824999988079071,
                -0.815500020980835
            ],
            "score_test": [
                -0.8109999895095825,
                -0.7960000038146973,
                -0.8180000185966492,
                -0.7990000247955322,
                -0.8240000009536743
            ],
            "t_fit": [
                13.6962900608778,
                4.28701451420784,
                1.8336133025586605,
                7.1364367343485355,
                3.9510821029543877
            ],
            "t_inference": [
                0.5571300275623798,
                0.11951163783669472,
                0.05675410479307175,
                0.16210297122597694,
                0.1393294297158718
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 335,
                    "lr": 0.0056634857863001415,
                    "end_lr_factor": 0.03512195086364842,
                    "n_epochs": 13,
                    "weight_decay": 6.692547322168576e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 238,
                    "lr": 0.009875816956945997,
                    "end_lr_factor": 0.033604578321501155,
                    "n_epochs": 13,
                    "weight_decay": 1.9645348863139427e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 103,
                    "lr": 0.009854782454568832,
                    "end_lr_factor": 0.04511815031433174,
                    "n_epochs": 10,
                    "weight_decay": 3.2703735335521716e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 473,
                    "lr": 0.0059386464158748065,
                    "end_lr_factor": 0.1592461362817094,
                    "n_epochs": 17,
                    "weight_decay": 1.0057387729382847e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 333,
                    "lr": 0.003953293610011774,
                    "end_lr_factor": 0.400763159498604,
                    "n_epochs": 11,
                    "weight_decay": 7.204421226270703e-06,
                    "batch_size": 512
                }
            ]
        }
    }
}