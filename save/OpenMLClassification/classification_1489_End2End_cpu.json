{
    "1489": {
        "End2End_cpu": {
            "score_train": [
                -0.9480000138282776,
                -0.9567499756813049,
                -0.9512500166893005,
                -0.9459999799728394,
                -0.9505000114440918
            ],
            "score_test": [
                -0.8889999985694885,
                -0.9020000100135803,
                -0.8960000276565552,
                -0.8930000066757202,
                -0.878000020980835
            ],
            "t_fit": [
                24.818623308092356,
                80.24524952098727,
                40.918638825416565,
                19.849345561116934,
                44.61772548034787
            ],
            "t_inference": [
                0.18214378505945206,
                0.6236298643052578,
                0.3325481228530407,
                0.11605819314718246,
                0.2652658708393574
            ],
            "hyperparams": [
                {
                    "in_dim": 5,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 79,
                    "lr": 0.00024129714235214024,
                    "end_lr_factor": 0.027068520413171208,
                    "n_epochs": 31,
                    "weight_decay": 2.0337590603296407e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 5,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 426,
                    "lr": 6.587879709995688e-05,
                    "end_lr_factor": 0.015297144142464998,
                    "n_epochs": 29,
                    "weight_decay": 5.133200446641748e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 5,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 232,
                    "lr": 7.985632262525457e-05,
                    "end_lr_factor": 0.035409333944940606,
                    "n_epochs": 38,
                    "weight_decay": 8.508368040129988e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 5,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 97,
                    "lr": 0.0002659550979781616,
                    "end_lr_factor": 0.03530955382080581,
                    "n_epochs": 37,
                    "weight_decay": 0.00016809392817131858,
                    "batch_size": 128
                },
                {
                    "in_dim": 5,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 354,
                    "lr": 5.691451693014569e-05,
                    "end_lr_factor": 0.05228597492073005,
                    "n_epochs": 39,
                    "weight_decay": 1.557327851537827e-05,
                    "batch_size": 128
                }
            ]
        }
    }
}