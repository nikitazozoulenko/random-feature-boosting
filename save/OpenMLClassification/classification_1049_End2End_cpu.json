{
    "1049": {
        "End2End_cpu": {
            "score_train": [
                -0.9433962106704712,
                -0.994854211807251,
                -0.989708423614502,
                -0.948586106300354,
                -0.973436176776886
            ],
            "score_test": [
                -0.9109588861465454,
                -0.9041095972061157,
                -0.8972602486610413,
                -0.9106529355049133,
                -0.9243986010551453
            ],
            "t_fit": [
                0.45412810519337654,
                3.406323553994298,
                1.2894960884004831,
                0.7259568311274052,
                1.5212728194892406
            ],
            "t_inference": [
                0.010179655626416206,
                0.03449912928044796,
                0.023513447493314743,
                0.013587899506092072,
                0.017466982826590538
            ],
            "hyperparams": [
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 120,
                    "lr": 0.004228706639490398,
                    "end_lr_factor": 0.07558249312200192,
                    "n_epochs": 15,
                    "weight_decay": 1.280392798735198e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 123,
                    "lr": 0.006999634239931157,
                    "end_lr_factor": 0.24048589595398062,
                    "n_epochs": 41,
                    "weight_decay": 4.5988366224266097e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 360,
                    "lr": 0.001022919413571952,
                    "end_lr_factor": 0.2940245415190487,
                    "n_epochs": 15,
                    "weight_decay": 2.6746031758130326e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 159,
                    "lr": 0.0026684220452018,
                    "end_lr_factor": 0.2166874734529366,
                    "n_epochs": 17,
                    "weight_decay": 7.235303442908175e-05,
                    "batch_size": 384
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 257,
                    "lr": 0.00792071204809178,
                    "end_lr_factor": 0.08656180922672158,
                    "n_epochs": 24,
                    "weight_decay": 7.03813993417286e-05,
                    "batch_size": 128
                }
            ]
        }
    }
}