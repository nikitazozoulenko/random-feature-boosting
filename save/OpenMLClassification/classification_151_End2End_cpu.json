{
    "151": {
        "End2End_cpu": {
            "score_train": [
                -0.8865000009536743,
                -0.8412500023841858,
                -0.8370000123977661,
                -0.8774999976158142,
                -0.8895000219345093
            ],
            "score_test": [
                -0.7870000004768372,
                -0.7929999828338623,
                -0.7770000100135803,
                -0.8019999861717224,
                -0.8019999861717224
            ],
            "t_fit": [
                17.3759907130152,
                6.357108689844608,
                10.023416012525558,
                9.072058027610183,
                12.25327599234879
            ],
            "t_inference": [
                0.27402362041175365,
                0.13100164383649826,
                0.27744542993605137,
                0.11669402942061424,
                0.2901126854121685
            ],
            "hyperparams": [
                {
                    "in_dim": 14,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 342,
                    "lr": 4.9402285801147294e-05,
                    "end_lr_factor": 0.014502893902574115,
                    "n_epochs": 28,
                    "weight_decay": 3.298406928814319e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 14,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 321,
                    "lr": 0.0007971721982352057,
                    "end_lr_factor": 0.17671036164593565,
                    "n_epochs": 13,
                    "weight_decay": 6.651049861726166e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 14,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 450,
                    "lr": 0.0009620804816215844,
                    "end_lr_factor": 0.06993222479033905,
                    "n_epochs": 11,
                    "weight_decay": 1.175815767463747e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 14,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 100,
                    "lr": 0.0018329906611937682,
                    "end_lr_factor": 0.03270639784471945,
                    "n_epochs": 21,
                    "weight_decay": 2.438138578056899e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 14,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 477,
                    "lr": 0.00014016620989668797,
                    "end_lr_factor": 0.12991553039786358,
                    "n_epochs": 16,
                    "weight_decay": 4.055503393220636e-06,
                    "batch_size": 256
                }
            ]
        }
    }
}