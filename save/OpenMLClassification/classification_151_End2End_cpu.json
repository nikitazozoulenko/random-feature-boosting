{
    "151": {
        "End2End_cpu": {
            "score_train": [
                -0.8117499947547913,
                -0.8080000281333923,
                -0.8237500190734863,
                -0.8345000147819519,
                -0.8442500233650208
            ],
            "score_test": [
                -0.7739999890327454,
                -0.7940000295639038,
                -0.765999972820282,
                -0.7950000166893005,
                -0.800000011920929
            ],
            "t_fit": [
                15.350896198302507,
                16.517699670046568,
                9.177598163485527,
                7.290479866787791,
                14.06595228239894
            ],
            "t_inference": [
                0.390100734308362,
                0.3889596089720726,
                0.27719138748943806,
                0.2598583325743675,
                0.25750438682734966
            ],
            "hyperparams": [
                {
                    "in_dim": 14,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 404,
                    "lr": 0.004480357327465685,
                    "end_lr_factor": 0.21632059545236804,
                    "n_epochs": 15,
                    "weight_decay": 5.5917069962271934e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 14,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 511,
                    "lr": 0.008307409356193889,
                    "end_lr_factor": 0.048161978107652825,
                    "n_epochs": 17,
                    "weight_decay": 8.874169564391564e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 14,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 473,
                    "lr": 0.002183038659308201,
                    "end_lr_factor": 0.14412284669391576,
                    "n_epochs": 10,
                    "weight_decay": 7.361626838652395e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 14,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 272,
                    "lr": 0.0007854778635305503,
                    "end_lr_factor": 0.012117343387345722,
                    "n_epochs": 12,
                    "weight_decay": 0.000503385130602683,
                    "batch_size": 512
                },
                {
                    "in_dim": 14,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 463,
                    "lr": 3.897688438862721e-05,
                    "end_lr_factor": 0.03063115696412437,
                    "n_epochs": 22,
                    "weight_decay": 3.6442504152344145e-06,
                    "batch_size": 512
                }
            ]
        }
    }
}