{
    "1486": {
        "End2End_cpu": {
            "score_train": [
                -0.9957500100135803,
                -0.9810000061988831,
                -0.9804999828338623,
                -0.9804999828338623,
                -0.9942499995231628
            ],
            "score_test": [
                -0.949999988079071,
                -0.9430000185966492,
                -0.9509999752044678,
                -0.9390000104904175,
                -0.9509999752044678
            ],
            "t_fit": [
                8.349404087290168,
                5.759197298437357,
                10.997785994783044,
                5.643055243417621,
                4.491100702434778
            ],
            "t_inference": [
                0.18062452785670757,
                0.13874139823019505,
                0.30666176974773407,
                0.12014508806169033,
                0.07972311787307262
            ],
            "hyperparams": [
                {
                    "in_dim": 174,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 397,
                    "lr": 0.00023452522399231392,
                    "end_lr_factor": 0.05506808341481733,
                    "n_epochs": 19,
                    "weight_decay": 2.8294294938104115e-05,
                    "batch_size": 384
                },
                {
                    "in_dim": 174,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 178,
                    "lr": 0.00472990318105029,
                    "end_lr_factor": 0.084794956160373,
                    "n_epochs": 15,
                    "weight_decay": 0.00022478217992939514,
                    "batch_size": 384
                },
                {
                    "in_dim": 174,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 388,
                    "lr": 0.0027433989969893025,
                    "end_lr_factor": 0.6579878298195126,
                    "n_epochs": 16,
                    "weight_decay": 8.326971542160074e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 174,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 117,
                    "lr": 0.003923287352678922,
                    "end_lr_factor": 0.3078208236219773,
                    "n_epochs": 15,
                    "weight_decay": 0.00018185037986744105,
                    "batch_size": 256
                },
                {
                    "in_dim": 174,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 340,
                    "lr": 0.0009358530503896641,
                    "end_lr_factor": 0.4794165486233873,
                    "n_epochs": 18,
                    "weight_decay": 3.370392487983901e-05,
                    "batch_size": 256
                }
            ]
        }
    }
}