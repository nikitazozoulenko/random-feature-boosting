{
    "1480": {
        "End2End": {
            "score_train": [
                -0.7682403326034546,
                -0.7961373329162598,
                -0.7553648352622986,
                -0.7730192542076111,
                -0.7537473440170288
            ],
            "score_test": [
                -0.6581196784973145,
                -0.6495726704597473,
                -0.7435897588729858,
                -0.7241379022598267,
                -0.7068965435028076
            ],
            "t_fit": [
                0.8137208446860313,
                0.29615190625190735,
                0.6878391206264496,
                0.44585756957530975,
                0.4316360652446747
            ],
            "t_inference": [
                0.016924187541007996,
                0.008417956531047821,
                0.017246440052986145,
                0.011205114424228668,
                0.012439705431461334
            ],
            "hyperparams": [
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 204,
                    "lr": 0.0072575496030337335,
                    "end_lr_factor": 0.03995505379249883,
                    "n_epochs": 12,
                    "weight_decay": 3.2759587103072747e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 110,
                    "lr": 0.005886337223672139,
                    "end_lr_factor": 0.2496815719567305,
                    "n_epochs": 10,
                    "weight_decay": 2.358409417052332e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 290,
                    "lr": 0.007869087673537436,
                    "end_lr_factor": 0.3799585156829591,
                    "n_epochs": 13,
                    "weight_decay": 1.215481733704087e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 170,
                    "lr": 0.005742910594337515,
                    "end_lr_factor": 0.23815054369146604,
                    "n_epochs": 12,
                    "weight_decay": 1.7973511851683078e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 299,
                    "lr": 0.0050975522594181545,
                    "end_lr_factor": 0.44607446491991415,
                    "n_epochs": 11,
                    "weight_decay": 2.4969239474043463e-06,
                    "batch_size": 128
                }
            ]
        }
    }
}