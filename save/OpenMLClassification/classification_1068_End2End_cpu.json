{
    "1068": {
        "End2End_cpu": {
            "score_train": [
                -0.9537767767906189,
                -0.9673055410385132,
                -0.9492672085762024,
                -0.9402480125427246,
                -0.9617117047309875
            ],
            "score_test": [
                -0.9234234094619751,
                -0.9144144058227539,
                -0.9414414167404175,
                -0.9369369149208069,
                -0.9140271544456482
            ],
            "t_fit": [
                5.743754707276821,
                5.168967466801405,
                2.7725497782230377,
                1.7744948454201221,
                4.909320805221796
            ],
            "t_inference": [
                0.054030176252126694,
                0.06406273320317268,
                0.034573085606098175,
                0.05411810055375099,
                0.050586748868227005
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 316,
                    "lr": 0.0039994978968533,
                    "end_lr_factor": 0.32186951450587414,
                    "n_epochs": 31,
                    "weight_decay": 7.719707660549653e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 158,
                    "lr": 0.006009299808853368,
                    "end_lr_factor": 0.8369934539457566,
                    "n_epochs": 32,
                    "weight_decay": 0.0005530411996970137,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 187,
                    "lr": 0.009913974010245793,
                    "end_lr_factor": 0.1495038412695633,
                    "n_epochs": 29,
                    "weight_decay": 0.0006154231505195977,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 324,
                    "lr": 0.004093200313810302,
                    "end_lr_factor": 0.08861269631710389,
                    "n_epochs": 10,
                    "weight_decay": 1.154403526684641e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 197,
                    "lr": 0.0048366335670322995,
                    "end_lr_factor": 0.344922025554986,
                    "n_epochs": 36,
                    "weight_decay": 1.9348020694956503e-05,
                    "batch_size": 384
                }
            ]
        }
    }
}