{
    "1068": {
        "End2End_cpu": {
            "score_train": [
                -0.9729425311088562,
                -0.9436302185058594,
                -0.9379932284355164,
                -0.9379932284355164,
                -0.9515765905380249
            ],
            "score_test": [
                -0.9189189076423645,
                -0.9234234094619751,
                -0.9369369149208069,
                -0.9414414167404175,
                -0.9140271544456482
            ],
            "t_fit": [
                1.5680725499987602,
                1.1322064064443111,
                1.7213777210563421,
                0.38076647371053696,
                1.2958346549421549
            ],
            "t_inference": [
                0.017215216532349586,
                0.028691010549664497,
                0.04750710353255272,
                0.011000018566846848,
                0.02848300337791443
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 137,
                    "lr": 0.005404454991168525,
                    "end_lr_factor": 0.23979957026161372,
                    "n_epochs": 32,
                    "weight_decay": 8.365086251831808e-05,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 181,
                    "lr": 0.004267452633998094,
                    "end_lr_factor": 0.7775937215614953,
                    "n_epochs": 22,
                    "weight_decay": 0.00039626042107865995,
                    "batch_size": 512
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 225,
                    "lr": 0.009366961546113899,
                    "end_lr_factor": 0.37476388980335157,
                    "n_epochs": 11,
                    "weight_decay": 1.4457501801512433e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 170,
                    "lr": 0.005733605838190998,
                    "end_lr_factor": 0.23356954545770178,
                    "n_epochs": 17,
                    "weight_decay": 3.409524520363027e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 63,
                    "lr": 0.006374445466262942,
                    "end_lr_factor": 0.19974167534882314,
                    "n_epochs": 17,
                    "weight_decay": 2.994503097649936e-05,
                    "batch_size": 256
                }
            ]
        }
    }
}