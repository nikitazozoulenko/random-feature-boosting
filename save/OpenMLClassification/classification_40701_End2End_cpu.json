{
    "40701": {
        "End2End_cpu": {
            "score_train": [
                -0.9667500257492065,
                -0.9887499809265137,
                -0.9542499780654907,
                -0.9882500171661377,
                -0.9942499995231628
            ],
            "score_test": [
                -0.9369999766349792,
                -0.9430000185966492,
                -0.9440000057220459,
                -0.925000011920929,
                -0.9200000166893005
            ],
            "t_fit": [
                6.470829628407955,
                4.17211477458477,
                2.361982509493828,
                6.589120231568813,
                11.06032095849514
            ],
            "t_inference": [
                0.27639613300561905,
                0.12249758839607239,
                0.10341836512088776,
                0.16851595789194107,
                0.17166032642126083
            ],
            "hyperparams": [
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 333,
                    "lr": 0.007508461241286562,
                    "end_lr_factor": 0.017654306397303983,
                    "n_epochs": 10,
                    "weight_decay": 9.706177816396615e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 243,
                    "lr": 0.0005843048877161198,
                    "end_lr_factor": 0.05408512439580009,
                    "n_epochs": 10,
                    "weight_decay": 3.8003033334366637e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 18,
                    "lr": 0.005238864766080836,
                    "end_lr_factor": 0.07832342658847996,
                    "n_epochs": 10,
                    "weight_decay": 1.8842765331909153e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 283,
                    "lr": 0.00021004256084311467,
                    "end_lr_factor": 0.2661745275496039,
                    "n_epochs": 11,
                    "weight_decay": 9.204227175251296e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 394,
                    "lr": 0.00019603195243682653,
                    "end_lr_factor": 0.18960318782162683,
                    "n_epochs": 28,
                    "weight_decay": 6.787171745279978e-06,
                    "batch_size": 512
                }
            ]
        }
    }
}