{
    "1464": {
        "End2End_cpu": {
            "score_train": [
                -0.7909699082374573,
                -0.8010033369064331,
                -0.8193979859352112,
                -0.8096827864646912,
                -0.8046744465827942
            ],
            "score_test": [
                -0.8333333134651184,
                -0.8266666531562805,
                -0.753333330154419,
                -0.7986577153205872,
                -0.7718120813369751
            ],
            "t_fit": [
                6.426510939374566,
                0.5711162518709898,
                1.1313403192907572,
                4.507728613913059,
                2.1416356042027473
            ],
            "t_inference": [
                0.11613930389285088,
                0.01351395808160305,
                0.023978646844625473,
                0.07382011227309704,
                0.07050600461661816
            ],
            "hyperparams": [
                {
                    "in_dim": 4,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 506,
                    "lr": 0.004474500439048292,
                    "end_lr_factor": 0.28696012799179355,
                    "n_epochs": 16,
                    "weight_decay": 1.9871782886417332e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 4,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 226,
                    "lr": 0.0016083855319303452,
                    "end_lr_factor": 0.03948829505634383,
                    "n_epochs": 11,
                    "weight_decay": 1.4727244879743038e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 4,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 208,
                    "lr": 0.006999634239931157,
                    "end_lr_factor": 0.6007094609225463,
                    "n_epochs": 13,
                    "weight_decay": 1.6706587249102768e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 4,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 397,
                    "lr": 0.004738308390473957,
                    "end_lr_factor": 0.05208959158226228,
                    "n_epochs": 21,
                    "weight_decay": 1.194707540995145e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 4,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 400,
                    "lr": 0.0058351470159748115,
                    "end_lr_factor": 0.34919534574724714,
                    "n_epochs": 11,
                    "weight_decay": 1.4425929135922804e-06,
                    "batch_size": 128
                }
            ]
        }
    }
}