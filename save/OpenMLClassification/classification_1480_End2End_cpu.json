{
    "1480": {
        "End2End_cpu": {
            "score_train": [
                -0.7682403326034546,
                -0.7961373329162598,
                -0.7553648352622986,
                -0.7730192542076111,
                -0.7537473440170288
            ],
            "score_test": [
                -0.6581196784973145,
                -0.6495726704597473,
                -0.7435897588729858,
                -0.7241379022598267,
                -0.7068965435028076
            ],
            "t_fit": [
                1.914433566853404,
                1.161924496293068,
                2.938528638333082,
                1.4642025120556355,
                1.5312417447566986
            ],
            "t_inference": [
                0.052687039598822594,
                0.0338747575879097,
                0.07716196961700916,
                0.037253087386488914,
                0.048027798533439636
            ],
            "hyperparams": [
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 204,
                    "lr": 0.0072575496030337335,
                    "end_lr_factor": 0.03995505379249883,
                    "n_epochs": 12,
                    "weight_decay": 3.2759587103072747e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 110,
                    "lr": 0.005886337223672139,
                    "end_lr_factor": 0.2496815719567305,
                    "n_epochs": 10,
                    "weight_decay": 2.358409417052332e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 290,
                    "lr": 0.007869087673537436,
                    "end_lr_factor": 0.3799585156829591,
                    "n_epochs": 13,
                    "weight_decay": 1.215481733704087e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 170,
                    "lr": 0.005742910594337515,
                    "end_lr_factor": 0.23815054369146604,
                    "n_epochs": 12,
                    "weight_decay": 1.7973511851683078e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 299,
                    "lr": 0.0050975522594181545,
                    "end_lr_factor": 0.44607446491991415,
                    "n_epochs": 11,
                    "weight_decay": 2.4969239474043463e-06,
                    "batch_size": 128
                }
            ]
        }
    }
}