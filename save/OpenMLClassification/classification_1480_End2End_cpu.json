{
    "1480": {
        "End2End_cpu": {
            "score_train": [
                -0.7961373329162598,
                -0.7532188892364502,
                -0.8755365014076233,
                -0.7965738773345947,
                -0.7901498675346375
            ],
            "score_test": [
                -0.6666666865348816,
                -0.7094017267227173,
                -0.692307710647583,
                -0.6724137663841248,
                -0.6120689511299133
            ],
            "t_fit": [
                1.151252169162035,
                1.0949822328984737,
                9.056106772273779,
                2.8087140657007694,
                4.4070423766970634
            ],
            "t_inference": [
                0.016183950006961823,
                0.03383360803127289,
                0.07352572679519653,
                0.02581101283431053,
                0.05030988156795502
            ],
            "hyperparams": [
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 47,
                    "lr": 0.022832873710419782,
                    "end_lr_factor": 0.27074403995409296,
                    "n_epochs": 20,
                    "weight_decay": 7.348332732640399e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 157,
                    "lr": 0.017572944713096263,
                    "end_lr_factor": 0.013236926536332004,
                    "n_epochs": 19,
                    "weight_decay": 1.0015581613631522e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 154,
                    "lr": 0.07041830285016017,
                    "end_lr_factor": 0.010862348973937114,
                    "n_epochs": 49,
                    "weight_decay": 0.0005284384205738843,
                    "batch_size": 128
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 85,
                    "lr": 0.016523469186338062,
                    "end_lr_factor": 0.01011124562891409,
                    "n_epochs": 26,
                    "weight_decay": 0.00012895780425791744,
                    "batch_size": 128
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 135,
                    "lr": 0.09390969638189317,
                    "end_lr_factor": 0.01020216764472249,
                    "n_epochs": 31,
                    "weight_decay": 0.00019599189276779888,
                    "batch_size": 128
                }
            ]
        }
    }
}