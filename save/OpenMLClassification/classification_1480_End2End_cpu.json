{
    "1480": {
        "End2End_cpu": {
            "score_train": [
                -0.774678111076355,
                -0.7424892783164978,
                -0.8154506683349609,
                -0.8008565306663513,
                -0.762312650680542
            ],
            "score_test": [
                -0.7435897588729858,
                -0.6752136945724487,
                -0.7179487347602844,
                -0.7068965435028076,
                -0.6896551847457886
            ],
            "t_fit": [
                0.5014367923140526,
                0.42541391029953957,
                0.5042954832315445,
                0.6537063829600811,
                1.0236435011029243
            ],
            "t_inference": [
                0.013687951490283012,
                0.02309829369187355,
                0.009243937209248543,
                0.007219601422548294,
                0.03084833361208439
            ],
            "hyperparams": [
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 143,
                    "lr": 0.008438553264335145,
                    "end_lr_factor": 0.5825808835935841,
                    "n_epochs": 12,
                    "weight_decay": 2.6080133988987184e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 352,
                    "lr": 0.004577793848833602,
                    "end_lr_factor": 0.1807397964345866,
                    "n_epochs": 11,
                    "weight_decay": 1.617330320139957e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 95,
                    "lr": 0.0023901013612692584,
                    "end_lr_factor": 0.2909160389651661,
                    "n_epochs": 16,
                    "weight_decay": 1.8945372006906036e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 289,
                    "lr": 0.006090011461455376,
                    "end_lr_factor": 0.771013070518667,
                    "n_epochs": 26,
                    "weight_decay": 6.97675723027801e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 11,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 435,
                    "lr": 0.006345988313880986,
                    "end_lr_factor": 0.3631579451644701,
                    "n_epochs": 12,
                    "weight_decay": 1.0363541671731319e-05,
                    "batch_size": 128
                }
            ]
        }
    }
}