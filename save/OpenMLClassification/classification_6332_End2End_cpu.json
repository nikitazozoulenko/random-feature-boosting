{
    "6332": {
        "End2End_cpu": {
            "score_train": [
                -0.9861111044883728,
                -0.9490740895271301,
                -0.9884259104728699,
                -1.0,
                -0.9305555820465088
            ],
            "score_test": [
                -0.7962962985038757,
                -0.7314814925193787,
                -0.7870370149612427,
                -0.7685185074806213,
                -0.7407407164573669
            ],
            "t_fit": [
                0.7737035900354385,
                0.7891854010522366,
                1.1024734787642956,
                0.7925023622810841,
                0.6459818184375763
            ],
            "t_inference": [
                0.009362965822219849,
                0.035022009164094925,
                0.025513947010040283,
                0.017426632344722748,
                0.022252779453992844
            ],
            "hyperparams": [
                {
                    "in_dim": 173,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 139,
                    "lr": 0.0002591471250719076,
                    "end_lr_factor": 0.12333133260756297,
                    "n_epochs": 19,
                    "weight_decay": 1.1576688477284446e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 173,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 317,
                    "lr": 0.00602705634636502,
                    "end_lr_factor": 0.2148940109327488,
                    "n_epochs": 13,
                    "weight_decay": 2.1827010096171076e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 173,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 220,
                    "lr": 0.00015311833878469625,
                    "end_lr_factor": 0.016984015505037642,
                    "n_epochs": 23,
                    "weight_decay": 2.3954293098253162e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 173,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 326,
                    "lr": 0.0002386104998861725,
                    "end_lr_factor": 0.6482560395466704,
                    "n_epochs": 13,
                    "weight_decay": 1.5336884781582415e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 173,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 356,
                    "lr": 0.0002467838336440104,
                    "end_lr_factor": 0.26174124976042973,
                    "n_epochs": 15,
                    "weight_decay": 0.0007755481487218477,
                    "batch_size": 256
                }
            ]
        }
    }
}