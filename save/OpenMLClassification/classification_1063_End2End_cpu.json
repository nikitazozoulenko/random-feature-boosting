{
    "1063": {
        "End2End_cpu": {
            "score_train": [
                -0.9664268493652344,
                -0.8585131764411926,
                -0.9258373379707336,
                -0.9449760913848877,
                -0.8851674795150757
            ],
            "score_test": [
                -0.8571428656578064,
                -0.8190476298332214,
                -0.7980769276618958,
                -0.8269230723381042,
                -0.817307710647583
            ],
            "t_fit": [
                55.106994446367025,
                12.158943947404623,
                20.8508514277637,
                25.864104092121124,
                5.818335376679897
            ],
            "t_inference": [
                0.008427593857049942,
                0.012546814978122711,
                0.013045921921730042,
                0.018093038350343704,
                0.0064513906836509705
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 66,
                    "lr": 0.00039651325556091675,
                    "end_lr_factor": 0.01818350935387702,
                    "n_epochs": 28,
                    "weight_decay": 0.000451942305277757,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 235,
                    "lr": 0.005931829093127339,
                    "end_lr_factor": 0.27100700292538504,
                    "n_epochs": 17,
                    "weight_decay": 2.1921154560928533e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 94,
                    "lr": 0.0024806951413902933,
                    "end_lr_factor": 0.4433767949515871,
                    "n_epochs": 10,
                    "weight_decay": 1.1468235069034277e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 71,
                    "lr": 0.00013388333519811555,
                    "end_lr_factor": 0.06444729238263033,
                    "n_epochs": 42,
                    "weight_decay": 0.0009928672890136935,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 99,
                    "lr": 0.0004014561330976699,
                    "end_lr_factor": 0.10774617024506003,
                    "n_epochs": 10,
                    "weight_decay": 3.4528766115297932e-06,
                    "batch_size": 256
                }
            ]
        }
    }
}