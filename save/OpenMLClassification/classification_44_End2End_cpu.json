{
    "44": {
        "End2End_cpu": {
            "score_train": [
                -0.979891300201416,
                -0.9722901582717896,
                -0.9915784001350403,
                -0.992121696472168,
                -0.9872317314147949
            ],
            "score_test": [
                -0.9500542879104614,
                -0.9445652365684509,
                -0.9434782862663269,
                -0.9402173757553101,
                -0.936956524848938
            ],
            "t_fit": [
                8.425245106220245,
                17.307670086622238,
                24.901206836104393,
                34.885534316301346,
                25.797516480088234
            ],
            "t_inference": [
                0.3486301898956299,
                0.5157445222139359,
                0.3586476892232895,
                0.5637480467557907,
                0.5378545522689819
            ],
            "hyperparams": [
                {
                    "in_dim": 57,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 510,
                    "lr": 0.00546660528510591,
                    "end_lr_factor": 0.06395022715590411,
                    "n_epochs": 13,
                    "weight_decay": 1.8626910375959294e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 57,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 304,
                    "lr": 0.009621160273637342,
                    "end_lr_factor": 0.1755865042785485,
                    "n_epochs": 14,
                    "weight_decay": 1.2116907018400698e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 57,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 331,
                    "lr": 5.0124586713921794e-05,
                    "end_lr_factor": 0.34547923698638844,
                    "n_epochs": 28,
                    "weight_decay": 1.9730558537600664e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 57,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 439,
                    "lr": 2.5485765761449033e-05,
                    "end_lr_factor": 0.752450165018719,
                    "n_epochs": 24,
                    "weight_decay": 4.4203089334128355e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 57,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 336,
                    "lr": 2.7774187618567863e-05,
                    "end_lr_factor": 0.4517193352566398,
                    "n_epochs": 19,
                    "weight_decay": 5.6237857206462905e-06,
                    "batch_size": 512
                }
            ]
        }
    }
}