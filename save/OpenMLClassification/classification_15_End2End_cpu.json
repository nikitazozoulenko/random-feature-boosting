{
    "15": {
        "End2End_cpu": {
            "score_train": [
                -0.9928443431854248,
                -0.9821109175682068,
                -0.9856887459754944,
                -0.9856887459754944,
                -1.0
            ],
            "score_test": [
                -0.949999988079071,
                -0.9642857313156128,
                -0.9785714149475098,
                -0.9285714030265808,
                -0.9784172773361206
            ],
            "t_fit": [
                3.4903219044208527,
                15.63645951449871,
                11.234887219965458,
                8.37844406068325,
                17.54232630878687
            ],
            "t_inference": [
                0.01803223043680191,
                0.030045248568058014,
                0.05217704176902771,
                0.04842077195644379,
                0.04889613389968872
            ],
            "hyperparams": [
                {
                    "in_dim": 9,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 146,
                    "lr": 0.002860190471111358,
                    "end_lr_factor": 0.07545260569576334,
                    "n_epochs": 10,
                    "weight_decay": 3.5747197509444e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 9,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 257,
                    "lr": 9.557332024862975e-05,
                    "end_lr_factor": 0.02269199780046211,
                    "n_epochs": 19,
                    "weight_decay": 0.0005667246084934361,
                    "batch_size": 256
                },
                {
                    "in_dim": 9,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 216,
                    "lr": 0.00013590241479828565,
                    "end_lr_factor": 0.05887056496896422,
                    "n_epochs": 14,
                    "weight_decay": 1.0324762190158618e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 9,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 203,
                    "lr": 0.00978012521909497,
                    "end_lr_factor": 0.05159339970264747,
                    "n_epochs": 11,
                    "weight_decay": 2.8862864243389374e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 9,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 237,
                    "lr": 0.00023746224425760795,
                    "end_lr_factor": 0.7171568728628447,
                    "n_epochs": 19,
                    "weight_decay": 4.224537265991121e-06,
                    "batch_size": 128
                }
            ]
        }
    }
}