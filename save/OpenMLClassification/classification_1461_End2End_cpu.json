{
    "1461": {
        "End2End_cpu": {
            "score_train": [
                -0.9647499918937683,
                -0.9384999871253967,
                -0.9492499828338623,
                -0.9207500219345093,
                -0.9355000257492065
            ],
            "score_test": [
                -0.8899999856948853,
                -0.8980000019073486,
                -0.8980000019073486,
                -0.9020000100135803,
                -0.9100000262260437
            ],
            "t_fit": [
                29.490100923925638,
                4.787808828055859,
                29.37118024751544,
                7.457818739116192,
                3.360997162759304
            ],
            "t_inference": [
                0.5587927401065826,
                0.12103414535522461,
                0.5404314696788788,
                0.32701167464256287,
                0.14486561343073845
            ],
            "hyperparams": [
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 194,
                    "lr": 0.07041830285016017,
                    "end_lr_factor": 0.8133545002715508,
                    "n_epochs": 28,
                    "weight_decay": 5.316480195825888e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 354,
                    "lr": 0.06642640700916837,
                    "end_lr_factor": 0.3472767449798701,
                    "n_epochs": 15,
                    "weight_decay": 2.7561646702258206e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 330,
                    "lr": 0.0590390219972749,
                    "end_lr_factor": 0.10960392366069656,
                    "n_epochs": 23,
                    "weight_decay": 1.4617103440225666e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 197,
                    "lr": 0.026025957327376104,
                    "end_lr_factor": 0.04102352956608573,
                    "n_epochs": 10,
                    "weight_decay": 1.3290513058357458e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 135,
                    "lr": 0.023381399169813633,
                    "end_lr_factor": 0.06358608056800875,
                    "n_epochs": 10,
                    "weight_decay": 2.5976863361920284e-06,
                    "batch_size": 512
                }
            ]
        }
    }
}