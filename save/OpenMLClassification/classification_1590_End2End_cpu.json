{
    "1590": {
        "End2End_cpu": {
            "score_train": [
                -0.9082499742507935,
                -0.8799999952316284,
                -0.8852499723434448,
                -0.9024999737739563,
                -0.8884999752044678
            ],
            "score_test": [
                -0.8510000109672546,
                -0.8460000157356262,
                -0.8450000286102295,
                -0.8539999723434448,
                -0.8379999995231628
            ],
            "t_fit": [
                11.693046532571316,
                5.990310937166214,
                20.95405387878418,
                11.192625768482685,
                14.985316298902035
            ],
            "t_inference": [
                0.3555392697453499,
                0.20832473784685135,
                0.8533936813473701,
                0.32303237169981003,
                0.6354187577962875
            ],
            "hyperparams": [
                {
                    "in_dim": 105,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 206,
                    "lr": 0.009463858974439247,
                    "end_lr_factor": 0.9954092520256412,
                    "n_epochs": 10,
                    "weight_decay": 1.0261131941550911e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 105,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 512,
                    "lr": 0.005379886940603703,
                    "end_lr_factor": 0.09035406384769393,
                    "n_epochs": 12,
                    "weight_decay": 3.6768977897391466e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 105,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 473,
                    "lr": 0.005328011761778827,
                    "end_lr_factor": 0.2206672400073423,
                    "n_epochs": 11,
                    "weight_decay": 2.0213243414543202e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 105,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 206,
                    "lr": 0.009463858974439247,
                    "end_lr_factor": 0.9954092520256412,
                    "n_epochs": 10,
                    "weight_decay": 1.0261131941550911e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 105,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 307,
                    "lr": 0.006075878073242489,
                    "end_lr_factor": 0.31756541427626367,
                    "n_epochs": 10,
                    "weight_decay": 6.359385836344312e-06,
                    "batch_size": 512
                }
            ]
        }
    }
}