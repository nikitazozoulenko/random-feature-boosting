{
    "29": {
        "End2End_cpu": {
            "score_train": [
                -0.9221014380455017,
                -0.9239130616188049,
                -0.9583333134651184,
                -0.9710144996643066,
                -0.9130434989929199
            ],
            "score_test": [
                -0.8478260636329651,
                -0.8623188138008118,
                -0.8550724387168884,
                -0.7898550629615784,
                -0.8623188138008118
            ],
            "t_fit": [
                24.251573514193296,
                30.06964847072959,
                24.826514545828104,
                34.460366781800985,
                12.214506451040506
            ],
            "t_inference": [
                0.03610607236623764,
                0.03287707269191742,
                0.019983965903520584,
                0.03265192359685898,
                0.010507393628358841
            ],
            "hyperparams": [
                {
                    "in_dim": 47,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 170,
                    "lr": 0.005016690891738067,
                    "end_lr_factor": 0.1610413410922333,
                    "n_epochs": 11,
                    "weight_decay": 2.9547689813432915e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 47,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 406,
                    "lr": 0.008089706301332445,
                    "end_lr_factor": 0.29046613601469856,
                    "n_epochs": 15,
                    "weight_decay": 2.1074885075604437e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 47,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 159,
                    "lr": 0.005199144516204364,
                    "end_lr_factor": 0.9726838780415789,
                    "n_epochs": 15,
                    "weight_decay": 1.075638242690606e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 47,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 464,
                    "lr": 0.007494571591936955,
                    "end_lr_factor": 0.4757605490195084,
                    "n_epochs": 19,
                    "weight_decay": 1.9812294524213865e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 47,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 179,
                    "lr": 0.007659446694858669,
                    "end_lr_factor": 0.9068089836447102,
                    "n_epochs": 12,
                    "weight_decay": 2.165394617364808e-06,
                    "batch_size": 384
                }
            ]
        }
    }
}