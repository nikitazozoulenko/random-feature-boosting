{
    "29": {
        "End2End_cpu": {
            "score_train": [
                -0.945652186870575,
                -0.9637681245803833,
                -0.8804348111152649,
                -0.9728260636329651,
                -0.8949275612831116
            ],
            "score_test": [
                -0.8260869383811951,
                -0.8623188138008118,
                -0.8623188138008118,
                -0.8188405632972717,
                -0.8913043737411499
            ],
            "t_fit": [
                1.3716650754213333,
                1.131166711449623,
                1.5924309343099594,
                1.1228326112031937,
                1.075024738907814
            ],
            "t_inference": [
                0.06001092493534088,
                0.037502750754356384,
                0.04236197471618652,
                0.017247527837753296,
                0.017754942178726196
            ],
            "hyperparams": [
                {
                    "in_dim": 47,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 183,
                    "lr": 0.0034476935563465655,
                    "end_lr_factor": 0.2368075303457944,
                    "n_epochs": 10,
                    "weight_decay": 3.065694351480324e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 47,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 118,
                    "lr": 0.0021887212553305647,
                    "end_lr_factor": 0.5143448632462241,
                    "n_epochs": 11,
                    "weight_decay": 2.27620926219257e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 47,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 9,
                    "hidden_dim": 81,
                    "lr": 0.04908727600061146,
                    "end_lr_factor": 0.09810013213939957,
                    "n_epochs": 22,
                    "weight_decay": 0.00037374102172242645,
                    "batch_size": 384
                },
                {
                    "in_dim": 47,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 415,
                    "lr": 0.010973216177446217,
                    "end_lr_factor": 0.07147212665041482,
                    "n_epochs": 17,
                    "weight_decay": 3.4701496521639175e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 47,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 467,
                    "lr": 3.904759159385627e-05,
                    "end_lr_factor": 0.16461151216951908,
                    "n_epochs": 15,
                    "weight_decay": 3.2620484306669965e-06,
                    "batch_size": 128
                }
            ]
        }
    }
}