{
    "1050": {
        "End2End_cpu": {
            "score_train": [
                -0.9064000248908997,
                -0.9175999760627747,
                -0.9160000085830688,
                -0.971222996711731,
                -0.9120703339576721
            ],
            "score_test": [
                -0.9041533470153809,
                -0.8913738131523132,
                -0.8753993511199951,
                -0.8653846383094788,
                -0.9038461446762085
            ],
            "t_fit": [
                1.0475097205489874,
                1.4900042433291674,
                2.89397562853992,
                5.5804671831429005,
                2.4472105018794537
            ],
            "t_inference": [
                0.030040569603443146,
                0.05083055980503559,
                0.07170284725725651,
                0.12717926502227783,
                0.028959613293409348
            ],
            "hyperparams": [
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 226,
                    "lr": 0.004393267538324932,
                    "end_lr_factor": 0.23495597392557024,
                    "n_epochs": 12,
                    "weight_decay": 9.405796912484204e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 136,
                    "lr": 0.00417713997715046,
                    "end_lr_factor": 0.5024935563520987,
                    "n_epochs": 12,
                    "weight_decay": 1.4481138639388317e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 224,
                    "lr": 0.006785768146417637,
                    "end_lr_factor": 0.03724146216886981,
                    "n_epochs": 16,
                    "weight_decay": 0.0005022250288689791,
                    "batch_size": 256
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 410,
                    "lr": 0.0008488315540659408,
                    "end_lr_factor": 0.11066192913808827,
                    "n_epochs": 19,
                    "weight_decay": 2.1556700251083964e-05,
                    "batch_size": 384
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 447,
                    "lr": 0.007232196135321827,
                    "end_lr_factor": 0.017219304722993836,
                    "n_epochs": 35,
                    "weight_decay": 1.632780300355846e-06,
                    "batch_size": 512
                }
            ]
        }
    }
}