{
    "1487": {
        "End2End_cpu": {
            "score_train": [
                -0.9565860629081726,
                -0.9585594534873962,
                -0.9570794105529785,
                -0.9491859674453735,
                -0.9511834383010864
            ],
            "score_test": [
                -0.9329388737678528,
                -0.9487179517745972,
                -0.9289940595626831,
                -0.9546350836753845,
                -0.9624505639076233
            ],
            "t_fit": [
                0.9849305301904678,
                6.757709847763181,
                1.0356063693761826,
                6.474091529846191,
                4.486166875809431
            ],
            "t_inference": [
                0.033281151205301285,
                0.21870310604572296,
                0.049908895045518875,
                0.2452497910708189,
                0.1710901539772749
            ],
            "hyperparams": [
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 129,
                    "lr": 0.0075681291337292185,
                    "end_lr_factor": 0.140107576977803,
                    "n_epochs": 13,
                    "weight_decay": 3.3109797145398497e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 445,
                    "lr": 0.0073558514793362366,
                    "end_lr_factor": 0.17021669285793756,
                    "n_epochs": 15,
                    "weight_decay": 6.214465123221479e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 122,
                    "lr": 0.006543139863981452,
                    "end_lr_factor": 0.10631344310077849,
                    "n_epochs": 10,
                    "weight_decay": 1.996432840160046e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 511,
                    "lr": 0.00994374709101001,
                    "end_lr_factor": 0.0733777522383864,
                    "n_epochs": 11,
                    "weight_decay": 5.674719087441588e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 442,
                    "lr": 0.007097784213935268,
                    "end_lr_factor": 0.06807174791784204,
                    "n_epochs": 14,
                    "weight_decay": 1.0063158890451636e-05,
                    "batch_size": 512
                }
            ]
        }
    }
}