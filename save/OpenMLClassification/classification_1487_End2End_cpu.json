{
    "1487": {
        "End2End_cpu": {
            "score_train": [
                -0.9605327844619751,
                -0.9679328799247742,
                -0.9580661058425903,
                -0.9516527056694031,
                -0.949211061000824
            ],
            "score_test": [
                -0.942800760269165,
                -0.9368836283683777,
                -0.9309664964675903,
                -0.9546350836753845,
                -0.9545454382896423
            ],
            "t_fit": [
                13.621605545282364,
                5.317140735685825,
                10.50728664174676,
                21.766686424613,
                7.100841026753187
            ],
            "t_inference": [
                0.40711362287402153,
                0.09631463512778282,
                0.3277303911745548,
                0.6422191374003887,
                0.2585686072707176
            ],
            "hyperparams": [
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 263,
                    "lr": 0.022414391417549112,
                    "end_lr_factor": 0.07931587069836687,
                    "n_epochs": 11,
                    "weight_decay": 0.00014313541133550902,
                    "batch_size": 128
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 350,
                    "lr": 0.02260431790373708,
                    "end_lr_factor": 0.15718858748263706,
                    "n_epochs": 19,
                    "weight_decay": 4.85333949586916e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 340,
                    "lr": 0.016244261831161105,
                    "end_lr_factor": 0.033739662416512904,
                    "n_epochs": 13,
                    "weight_decay": 0.00016893806027344123,
                    "batch_size": 256
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 9,
                    "hidden_dim": 438,
                    "lr": 0.0108572175307655,
                    "end_lr_factor": 0.354029497510362,
                    "n_epochs": 18,
                    "weight_decay": 1.9571340937055974e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 192,
                    "lr": 0.031319339162134065,
                    "end_lr_factor": 0.2554261214579338,
                    "n_epochs": 11,
                    "weight_decay": 6.76435392207543e-06,
                    "batch_size": 256
                }
            ]
        }
    }
}