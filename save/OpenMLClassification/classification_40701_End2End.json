{
    "40701": {
        "End2End": {
            "score_train": [
                -0.9667500257492065,
                -0.9887499809265137,
                -0.9542499780654907,
                -0.9882500171661377,
                -0.9942499995231628
            ],
            "score_test": [
                -0.9369999766349792,
                -0.9430000185966492,
                -0.9440000057220459,
                -0.925000011920929,
                -0.9200000166893005
            ],
            "t_fit": [
                3.001505747437477,
                1.5247574895620346,
                1.1148680597543716,
                2.3277863413095474,
                5.0388040244579315
            ],
            "t_inference": [
                0.1222836971282959,
                0.052220284938812256,
                0.04485227167606354,
                0.05878717452287674,
                0.0760192722082138
            ],
            "hyperparams": [
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 333,
                    "lr": 0.007508461241286562,
                    "end_lr_factor": 0.017654306397303983,
                    "n_epochs": 10,
                    "weight_decay": 9.706177816396615e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 243,
                    "lr": 0.0005843048877161198,
                    "end_lr_factor": 0.05408512439580009,
                    "n_epochs": 10,
                    "weight_decay": 3.8003033334366637e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 18,
                    "lr": 0.005238864766080836,
                    "end_lr_factor": 0.07832342658847996,
                    "n_epochs": 10,
                    "weight_decay": 1.8842765331909153e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 283,
                    "lr": 0.00021004256084311467,
                    "end_lr_factor": 0.2661745275496039,
                    "n_epochs": 11,
                    "weight_decay": 9.204227175251296e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 394,
                    "lr": 0.00019603195243682653,
                    "end_lr_factor": 0.18960318782162683,
                    "n_epochs": 28,
                    "weight_decay": 6.787171745279978e-06,
                    "batch_size": 512
                }
            ]
        }
    }
}