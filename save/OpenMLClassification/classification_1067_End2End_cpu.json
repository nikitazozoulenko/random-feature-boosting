{
    "1067": {
        "End2End_cpu": {
            "score_train": [
                -0.8725548386573792,
                -0.8873740434646606,
                -0.892708957195282,
                -0.8713693022727966,
                -0.8690758347511292
            ],
            "score_test": [
                -0.8388625383377075,
                -0.8388625383377075,
                -0.8601895570755005,
                -0.8744075894355774,
                -0.8646080493927002
            ],
            "t_fit": [
                6.556438658386469,
                1.9748867806047201,
                3.7204877510666847,
                1.3184818997979164,
                2.143927812576294
            ],
            "t_inference": [
                0.13749873638153076,
                0.07276171445846558,
                0.09074760042130947,
                0.050101472064852715,
                0.05251437798142433
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 295,
                    "lr": 0.00675239600489555,
                    "end_lr_factor": 0.10763383425032305,
                    "n_epochs": 21,
                    "weight_decay": 5.132831660489737e-05,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 127,
                    "lr": 0.002647058066140491,
                    "end_lr_factor": 0.28593628794516196,
                    "n_epochs": 11,
                    "weight_decay": 3.70056683628713e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 355,
                    "lr": 0.0022423535265390137,
                    "end_lr_factor": 0.14438093100830246,
                    "n_epochs": 12,
                    "weight_decay": 1.8853606447979774e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 123,
                    "lr": 0.0039037432052989084,
                    "end_lr_factor": 0.28804134111136487,
                    "n_epochs": 11,
                    "weight_decay": 1.0302197347131163e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 277,
                    "lr": 0.009932068160309244,
                    "end_lr_factor": 0.1682951950020493,
                    "n_epochs": 15,
                    "weight_decay": 3.20459395465151e-06,
                    "batch_size": 256
                }
            ]
        }
    }
}