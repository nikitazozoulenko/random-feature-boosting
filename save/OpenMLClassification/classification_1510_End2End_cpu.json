{
    "1510": {
        "End2End_cpu": {
            "score_train": [
                -0.9824175834655762,
                -0.9868131875991821,
                -0.9868131875991821,
                -0.9890109896659851,
                -0.9758771657943726
            ],
            "score_test": [
                -0.9298245906829834,
                -0.9824561476707458,
                -0.9736841917037964,
                -0.9824561476707458,
                -0.9380530714988708
            ],
            "t_fit": [
                1.5996039174497128,
                1.5192515216767788,
                3.253550823777914,
                6.5152403973042965,
                2.7546326890587807
            ],
            "t_inference": [
                0.041035886853933334,
                0.061933595687150955,
                0.08786580339074135,
                0.1626611016690731,
                0.1413508765399456
            ],
            "hyperparams": [
                {
                    "in_dim": 30,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 166,
                    "lr": 0.09805371253772195,
                    "end_lr_factor": 0.28696012799179355,
                    "n_epochs": 13,
                    "weight_decay": 5.3476572388546196e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 30,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 262,
                    "lr": 0.007623076645808588,
                    "end_lr_factor": 0.25856672498897315,
                    "n_epochs": 17,
                    "weight_decay": 5.473342953913952e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 30,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 431,
                    "lr": 0.004570563099801453,
                    "end_lr_factor": 0.15751320499779725,
                    "n_epochs": 12,
                    "weight_decay": 2.9375384576328313e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 30,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 500,
                    "lr": 0.012239061401119154,
                    "end_lr_factor": 0.3868205879720286,
                    "n_epochs": 14,
                    "weight_decay": 1.0133636952253747e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 30,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 482,
                    "lr": 0.07910830245963224,
                    "end_lr_factor": 0.39174531547929065,
                    "n_epochs": 12,
                    "weight_decay": 1.1430215363045427e-05,
                    "batch_size": 256
                }
            ]
        }
    }
}