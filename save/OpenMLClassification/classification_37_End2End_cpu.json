{
    "37": {
        "End2End_cpu": {
            "score_train": [
                -0.8094462752342224,
                -0.7947883009910583,
                -0.7996742725372314,
                -0.8162601590156555,
                -0.795121967792511
            ],
            "score_test": [
                -0.7727272510528564,
                -0.798701286315918,
                -0.7597402334213257,
                -0.7385621070861816,
                -0.7777777910232544
            ],
            "t_fit": [
                0.6785356607288122,
                0.3763335831463337,
                0.5731420312076807,
                0.8746393825858831,
                1.9933503735810518
            ],
            "t_inference": [
                0.011476550251245499,
                0.015681372955441475,
                0.018259670585393906,
                0.027726713567972183,
                0.07012001797556877
            ],
            "hyperparams": [
                {
                    "in_dim": 8,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 281,
                    "lr": 0.007017801056452959,
                    "end_lr_factor": 0.19679288845733767,
                    "n_epochs": 20,
                    "weight_decay": 1.3482532236073018e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 8,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 465,
                    "lr": 0.003658292794704842,
                    "end_lr_factor": 0.16059188920366851,
                    "n_epochs": 12,
                    "weight_decay": 2.343816110659332e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 8,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 63,
                    "lr": 0.007395735606947079,
                    "end_lr_factor": 0.5277252574901381,
                    "n_epochs": 12,
                    "weight_decay": 6.755265487607299e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 8,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 200,
                    "lr": 0.009013393237454046,
                    "end_lr_factor": 0.9733465643919335,
                    "n_epochs": 10,
                    "weight_decay": 1.075638242690606e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 8,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 459,
                    "lr": 0.008523976865537042,
                    "end_lr_factor": 0.22743150821402897,
                    "n_epochs": 11,
                    "weight_decay": 2.4424983954580052e-06,
                    "batch_size": 128
                }
            ]
        }
    }
}